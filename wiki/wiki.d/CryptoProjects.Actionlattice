version=pmwiki-2.2.133 ordered=1 urlencoded=1
author=
charset=UTF-8
csum=Safe and strong primes might have a benefit and avoid pollard p-1 algorithm [[https://www.sjoerdlangkemper.nl/2019/06/19/attacking-rsa/|#]] but may not be worth it at high bitlevels [[https://en.wikipedia.org/wiki/Safe_and_Sophie_Germain_primes#Cryptography|#]] but better safe than sorry. 
ctime=1664341422
name=CryptoProjects.Actionlattice
rev=563
targets=CryptoProjects.Blocklattice,CryptoProjects.CollectBit,NatureVault.DigitalCollectibleNetwork,CryptoProjects.BlockDAG,NatureVault.Solvum,NatureVault.Quantum,CryptoProjects.Dustyplasma,NatureVault.Transep,NatureVault.SocialMedia,CryptoProjects.Ravencoin,NatureVault.TEEFsLaw,CryptoProjects.Yespower,CryptoProjects.MoneroFork,CryptoProjects.Blockvault,CryptoProjects.ProportionalReward,CryptoProjects.Staticcoin,CryptoProjects.Ergon,CryptoProjects.PoH,Profiles.NatureHacker,CryptoProjects.OPoW,Category.Cryptics
text=(:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain (1D) or blockDAG (2D).  It scales to infinite free and private transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], mining pools aren't necessary for miners to get constant rewards, tx can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine. Consensus is reached by an army of ants, an atomic, democratic, vote of factoring power:)%0a(:Published:9/28/2022:)%0a(:Author:[[~GiverofMemory]]:)%0a(:License:[[https://en.m.wikipedia.org/wiki/Res_communis|Site License]]:)%0a(:Update::)%0a(:Maintainer:[[~GiverofMemory]]:)%0a(:Creator:[[]]:)%0a(:Categories:[[!Cryptics]]:)%0a(:Also:none:)%0a(:Archive:[[ https://archive.ph/R5sla |Archive.is]], [[ https://web.archive.org/web/20221001154854/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice |Archive.org]],  [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|OLDArchive.org]]:)%0a(:Download:[[{$FullName}?action=print|URL]],[[https://www.web2pdfconvert.com/|PDF from URL]]:)%0a%0aSee also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]], [[NatureVault/Solvum]], [[NatureVault/Quantum]], [[Dustyplasma]], [[NatureVault/transep]]%0a%0aBitcoin was the rough draft.  Actionlattice is the fulfilment of the technology. Having a non-reusable address for each and every satoshi would not have been feasible in 2008, but now with software wallets using HD key generation, we can have nearly infinite addresses at our fingertips - making actionlattice a reality. %0a%0aAn actionlattice is a new open source method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, encode tokens and NFT's, and issue rewards (cips). It replaces the blockchain.  You can think of it like a 3D blockchain, whereas a blockchain is 1D.  We have come a long way from [[https://en.wikipedia.org/wiki/History_of_writing#Recorded_history|clay tablets]]%0a%0aIt can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using actionlattice to craft items.  It can also be used as an accounting ledger for transferring real or fictional assets like NFT's and tokens.  It can even be used for voting, much more democratically than blockchain. AI devices will also be able to mine this.  It can also be used for [[NatureVault/Social media]] since the only bottleneck is the sync speed.%0a%0aThe smallest (and only) unit of account is the cip (dust - like a satoshi). The name is a convolution of "bit", "semiprime" maybe "cipher" or "sip".%0a%0aEvery transaction is free to propose, and then a miner (or you - if you mine your own tx) gets paid with a reward cip if they "activate" the proposed transaction using proof of semiprime (aka proof of sieve) ([[#posi|Posi]]) and point (connect) it to three other transactions that they validate and vouch for, preferably these three other transactions are near the "surface" but whose cip genesis is deep below the surface.  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", if it is not double spent or double mined, the transaction is valid, and if it is near the surface but the cip genesis is deep from the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a%0aThe mining reward for activating a transaction would mature by whether your transaction is confirmed by others linking their transactions to yours.  Some consensus on how "well connected" your transaction needs to be (how deep from the surface) in order for your mining reward to be valid.  I suppose you can try to spend them immediately and it is up to each miner whether they build on a transaction whose genesis isn't deep from the surface.  I suppose it would take a while for your spending transaction to be confirmed before miners feel it is valid.%0a%0aAttach:actionlattice.png | '''This is for a 2 bond version, 3 bond version (called xlattice) would look a bit more complex.'''%0a%0aIn addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original, probably with a new recognized cip every [[#diff|5 decimal digits {17-18 bits}]] of proof level.  The original transaction and cip is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot receive another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a%0aAll a cryptocurrency would need is an actionlattice.  Also a UTXO may be used, and will be helpful because of pruning.  The UTXO would simply carry a list of addresses with balance of 1 cip, and used addresses (that contain 0 cips) and these cannot be reused (this is done to maintain privacy and security since every cip is only signed for once and then it is destroyed).  That said UTXO omission could be a feature as it would mean transactions keep needing to be re-mined at current difficulty to not be purged (and effectively reversed).%0a%0aEach transaction is it's very own "block" and stands alone.  It can be broadcast with or without proof of semiprime [[#posi|Posi]].  If it is broadcast to the network with no proof, then a miner would need to activate and connect it wherever they want in the lattice (they will probably selfishly connect it to their own transactions to add confirmations).%0a%0aEach transaction can send cips from one public key to another.  Each public key can hold only 1 cip.  Think of each cip as a "bit".  Each bit is immutable and cannot be split or added to.  Each bit (cip) has one public and private key.%0a%0aMining any size transaction will require a certain (and probably the same) amount of proof of semiprime, lets say a 20 minute target.  This is set by each individual node and thus a pseudo-consenus would form about what is currently acceptable.  Perhaps a target of a few seconds can act as an initial confirmation and later a 20 min proof would be important to get all the nodes to accept it. In fact, there could be 2 lattices; alpha and beta.  The alpha fork could have few second confirmations for point of sale (pos) applications and then within 20 mins or so it would be confirmed on the beta network for more confidence. Perhaps there are even more networks for even higher proof levels the transactions could be added to.  There probably will be a new cross compatible [[#genesis|genesis fork]] everytime another level of [[#diff|difficulty]] is reached by at least 1 miner.%0a%0aEach transaction contains public addresses and signatures for each of the cips being sent and the public addresses for each cip to be received to, a cipbase address where a new cip is created and given to, and a message field that can be used for iterating nonces and including messages like love letters or encoding Tokens or NFT's like [[Ravencoin]] or Bitcoin's colored coins.%0a%0a!!Number of bonds%0a%0aIn the examples here we use 2 or preferably 3 bonds per transaction but this can be any number set by the network.  The more bonds you require the faster there will be consensus/convergence but also the more time it will take each miner to activate a transaction.  Also the number of levels down the miner verifies will also add to the time.  Somewhere between 2-10 bonds would probably be ideal and over time this number can even be increased as computers get faster at verifying transactions (due to moores law). I think I would pick 3 bonds.%0a%0aFor some context 2 bonds checking 8 layers/levels down would be 256 transactions to verify, 4 bonds checking 4 levels down would be 256 transactions. Three bonds checking 5 levels would be 243 transactions.  Three bonds checking 7 levels would be 2187 transactions to check which seems reasonable.  A reorganization (reorg) effecting over 2000 transactions would be rare.%0a%0a!!Consensus [[#consensus]]%0a%0aConsensus looks slightly different than Bitcoin, but it is even more rigorous. Bitcoin for one has to prevent double spending by using arbitrary timestamps. Actionlattice is more rigorous at preventing double spending (and privacy at the same time) by dictating that an address can only hold 1 bit and never be reused. Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain. In the same way nodes/miners need to verify the transactions in actionlattice and then accept the "heaviest" version (number of transactions x their bitlength weight = greatest). %0a%0aThat said someone could attempt a double spend on two different "sides" of the lattice at once, and the "each transaction confirms 3 others and 7 levels down" wouldn't necessarily catch it immediately, but it would eventually. Actionlattice basically asks for a continuous rolling vote. Lets look at these two duplicate transactions sending to different addresses (double spend; they are trying to duplicate their cips). Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 3 transactions and it would be invalid if they vouched for a double spend. Now whichever of the two double spends gets the most "confirmations" is the winner. The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead. Also, every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified.%0a%0aSo this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend or otherwise invalid tx, and go several layers down from the tx's they are vouching for there is no double spend there either. It doesn't hurt the person making the nullified but valid transaction that was linked to the "bad" one, as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward. So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser. It would be a "rolling consensus".%0a%0a!!!Hashsnaps (snaps/snapshots/epochs) [[#snaps]]%0a%0aThis is similar to [[NatureVault/transep]], which is the 1D blockchain equivalent.%0a%0aEvery certain amount of time the actionlattice should be hashed.  This should be done so that nodes can ping other nodes and by just comparing one number, they can see if their actionlattice is identical.  If the hashsnaps don't match, then the nodes can reconcile what is different.  The hashsnaps with the most voting weight are the accepted hashsnaps.  The reason there are 5 levels is that nodes can tell if they are correct with more granularity and can compensate and contest other hashsnaps faster.  For example if it was done every hour, if lots of nodes have different hourly hashsnaps, then they would have a lot of transactions to compare.  If there is a discrepancy at 7 second hashsnaps, they can compare a much smaller amount of transactions to see which lattice has a higher weight and accept that.%0a%0aThis might look like you get a confirmation every hashsnap.  Yes and no, yes in the sense that you now know the majority of nodes have your transaction saved, but also you can be watching the nodes in real time as connections, and thus confirmations are happening to your transaction(s) constantly.  So a good node would have high certainty a transaction has gone through even before the 7 second hashsnaps circulate the network.%0a%0aFor every number of seconds shown below (epoch), a node would broadcast the hash of the last hashsnap hashed with all the current transaction hashes XOR'd together so that the order the transactions are in doesn't matter [[https://stackoverflow.com/questions/19342846/is-there-a-c-sharp-method-of-hash-generation-where-the-order-of-the-values-doesn|#]] [[https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes|#]] (or even just adding all the hash values up! [[https://stackoverflow.com/questions/30734848/order-independent-hash-algorithm|#]]).  Obviously if there were double spending (duplicates) the later one(s) each node would just delete on their own.%0a%0aEach Level of epoch uses the hash of the last epoch plus all the hashes of the transactions in the current epoch.  So L1H's would only be concerned with previous L1H's, whereas L4H's would only use the hashsnap of the last L4H, and all the transactions since.  They do not rely on each other.  So a light node for example would only compare their actionlattice with L4H's for example so they don't have to constantly performing lots of calculations.%0a%0aEpoch's should be 1 behind.  So lets say we are currently sitting in epoch L1E2 right now, at the end of L1E2 your node should publish L1E1. This is because discrepancies can be fixed by each node so that consensus isn't constantly lagging.  Hashsnaps from the current epoch could be published, but more as a preliminary comparison, and 1 epoch behind is binding in the sense that the highest weighted actionlattice is the "winner" and shall be accepted by all the nodes.%0a%0aL1H's and L2H's are not multiples of eachother to prevent nodes from having to calculate both at the same time, which would be difficult for nodes.%0a%0a!!!!Level 1 hashsnaps (L1H)%0a%0aThese are done every 7 seconds%0a%0aEvery 7 seconds would be a new L1H epoch.  L1HE1, L1HE2, etc every 7 seconds%0a!!!!Level 2 hashsnaps (L2H)%0a%0aThese are done every minute (60 seconds)%0a%0aEvery 60 seconds would be a new L2H epoch.  L2HE1, L2HE2, etc every 60 seconds%0a%0a!!!!Level 3 hashsnaps (L3H)%0a%0aThese are done every 10 mins (600 seconds)%0a%0a!!!!Level 4 hashsnaps (L4H)%0a%0aThese are done every hour (3600 seconds)%0a%0a!!!!Level 5 hashsnaps (L5H)%0a%0aThese are done every day (86400 seconds)%0a%0a!!Address generation [[#address]]%0aWe will use [[https://en.wikipedia.org/wiki/Base64|base64]] address encoding since powers of 2 are best [[https://stackoverflow.com/questions/201479/what-is-base-64-encoding-used-for|#]].  Base58 was used in bitcoin to make addresses easily human recordable, but for actionlattice our addresses are not intended to be human usable since each piece of dust will have its own address so addresses will need a software wallet to manage.  That said it is not very difficult for a human to read/record base64.%0a%0aWe will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacrum]] [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529#Examples|accumulator]]) keys since they are widely supported, use basic math - factoring instead of elliptic curves (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a%0aWe only want addresses to be used once and never reused. So to enforce this the most obvious way is to keep a database of all previously used addresses and their balance.  But this means keeping a large database of all the empty addresses forever which would get huge, or search through the entire actionlattice to see if an address is there, which would take way too much time. %0a%0aWe considered [[#merkle|merkle tree proofs]], [[#schnorr|schnorr signatures]], and [[#moving|moving address requirements]], and moving address requirements was the only viable solution to this problem.  Newly proposed addresses (recipients of cips in transactions) must contain a specific suffix to be valid, and these acceptable suffixes will only be valid for 72 hours.  As long as they are the recipient of a transaction within that 72 hour window, they will be able to send forever, but can never receive again.  Nodes will either keep a list of all new addresses generated in the last 72 hours and compare each newly proposed address to this list and ensure there are no matches, or simply search the last 72 hours of the lattice to ensure no newly proposed addresses match.%0a%0a%0a!!!RSA considerations%0a%0aRSA signatures are [[https://en.wikipedia.org/wiki/Malleability_%2529cryptography%2529|malleable]] so messages being encrypted by them should be padded.%0a%0a!!!!e = 1073741827 (roughly 1 billion)%0a%0ae should be: [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529#Key_generation|#]] [[https://crypto.stackexchange.com/questions/13166/method-to-calculating-e-in-rsa|#]]%0a%0a[[https://www.wolframalpha.com/|Prime]].  It can't have the same factors of lambda(n) or be a factor of lambda(n), so prime is ideal.%0a%0aSmall hamming weight [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|#]].  The common e is 65537 (1+2^16) which has a hamming weight of 2 when paired with 00000.  2^16 (and seemingly every power of 2) has a hamming weight of 1 but probably isn't used because it has a lot of factors, whereas 1+2^16 is prime.%0a%0aBe greater than 50,000 [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529#Faulty_key_generation|#]] and less than 32 bits [[https://crypto.stackexchange.com/questions/62925/rsa-vulnerability-when-e-is-particularily-large|#]] [[https://stackoverflow.com/questions/27474550/is-there-a-limit-for-rsa-key-exponents-in-net|#]].  Needs to be smaller than lambda(n)%0a%0a262147 (2^18 + 3) or 8388617 (2^23 + 9) or 268435459 (2^28 + 3) or 1073741827 (2^30 + 3) or 9007199254740997 (2^53 + 5); all have a [[https://planetcalc.com/8985/|Hamming distance (via converting to binary and subtracting)]] of 3 (1 worse than 65537) and are prime.%0a%0a2147483659 (2^31 + 11) has a hamming distance of 4.%0a%0aI am selecting e to be %25green%25**1073741827 which is (2^30 + 3)**%25%25 because it is below the 32 bit limit imposed by some software, is prime, has a low hamming distance of 3, and is as large as possible to avoid insufficient padding attacks.%0a%0a!!!!Primes%0a%0aSafe and strong primes might have a benefit and avoid pollard p-1 algorithm [[https://www.sjoerdlangkemper.nl/2019/06/19/attacking-rsa/|#]] but may not be worth it at high bitlevels [[https://en.wikipedia.org/wiki/Safe_and_Sophie_Germain_primes#Cryptography|#]] but better safe than sorry.%0a%0aAccumulators require rigid numbers, product of 2 safe primes [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529#Examples|#]] [[https://link.springer.com/content/pdf/10.1007%252F3-540-48285-7_24.pdf|#]]%0a%0a!!!Moving address requirements [[#moving]]%0a%0aWe will have the last 4 digits of base64 addresses (suffix) determined by the trimmed hash of 3 daily hashshaps concatenated.  So you concatenate 3 daily hashsnaps ordered from oldest to newest, hash them together, and trim off all but the last 4 digits.  This gives about 17 million addresses to search to find one that has the correct last 4 digits.%0a%0aEach suffix is good for 72 hours for newly proposed addresses (even though a new suffix is generated daily).  This means the 3 hashsnaps you concatenate and hash are the three newest daily hashsnaps you are aware of, and if you are doing a long proof you may want to start your attempts as soon as the daily hashsnap is published. However if you just want to factor a large challenge so you can upload a lot of data to your transaction (say a picture or video) then you don't have to have any recipient cips, therefore the 72 hour window doesn't apply.%0a%0a!!!!Explanation%0a%0aWe could require that public key addresses have a new prefix or suffix every certain amount of time.  So addresses could be required to start with xdgh... For example.  Then a month from now they could be required to start with kdne...  These leading strings could be generated randomly via [[#snaps|hashsnaps]].  The problem with this is it would take a lot longer to generate addresses, which really shouldn't be too big of a deal because already vanity address generators exist that can do this.  The big problem is collisions, the algorithm could easily generate the same prefix twice so old addresses made with a certain prefix can be reused at a future date.  This could be fixed by making the prefix longer, but then address generation time also increases significantly.  %0a%0aTo implement this we would need to specify how often the address prefix changes.  Lets say its daily.  Then to test transaction validity nodes would only need to scan back a day to make sure that address wasn't used before.%0a%0aCan we tolerate address reuse that is limited to very long time periods apart?  Is this good enough to really disincentive address reuse?  It might be, especially if we can combine it with another technique. Another thing we could do is keep a list of all prefixes and what hashsnaps they correspond to so if we do get a repeat it could be rehashed.  But then we are stick with maintaining a list of all prefixes, which certainly is a much smaller dataset then all addresses ever used... The problem with that though is you would eventially run out of prefixes.  Lets say the addresses were numbers and the first 4 digits are the prefix.  That means 10*10*10*10 prefixes would be possible which would only last 10,000 days before all were used, which is about 30 years.%0a%0a%0aExample: I created a [[https://www.smartscanner.cash/address/0x7eeeef82e6b1042dc809f4d6385198b315cfcdf6|  vanity address]] in several minutes I believe that had a prefix of 6 hexadecimal characters which is 16^6 attempts (16.8 million attempts).  If we reduced that to 5 characters it should take just a few seconds (1 million attempts), that would give us enough unique prefixes for about 2,800 years, which should be sufficient, and if we are still around we could increase the requirement to 6 digits at that time (or at any time really).%0a%0aA very fast cpu can do 1/2 million attempts per second, a bank of 8 fast gpu's can do 2.5 million attempts per second [[https://smith-mcf.medium.com/solana-vanity-address-using-gpus-5a68ad94d1d4|#]]%0a!!!Merkle tree [[#merkle]]%0a%0aMerkle tree cannot help us create a public key that is provably new because you can't sign for the high level hash.%0a%0a!!!!Notes (deprecated)%0a%0aMerkle tree proofs should work to allow addresses to be generated using a recent Hashsnap so that we know an address is newly generated that you are sending a cip to [[https://www.reddit.com/r/cryptography/comments/z1hvc5/comment/ixb4qjj/?utm_source=share&utm_medium=web2x&context=3|#]] [[https://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5|#]] You would take the most recent daily hashsnap and hash it with a brand new public key (that you have the private key for).  Now you have a new cip address that did not exist before. In reality it proves the address is new but it does not prove the public key is new so this does not work for us.%0a%0a!!!Schnorr [[#schnorr]]%0a%0aSchnorr signatures should not be allowed because they can make fake public keys that can be signed for with old private keys.  We want only new keys to be allowed with no fakes.%0a%0a!!!!Notes (deprecated)%0a%0aSchnorr signatures might allow timestamping keys [[https://youtu.be/XKatSGCZ-gE?t=563|#]] 'pay to contract' allows to embed and old public key with data to make a new public key that can be signed with the old private key.  This is good to make cips linkable to a user but unlinkable for external observers of the lattice.  However by revealing the old public key then cips could be linked.  Optional privacy doesn't really work because it ruins fungibility for everyone when someone chooses to reveal a link on chain.%0a%0aSchnorr signature lecture [[https://crypto.stanford.edu/cs355/19sp/lec5.pdf|#]]%0a%0aGood explanation of how exactly signatures work including schnorr [[https://medium.com/bitbees/what-the-heck-is-schnorr-52ef5dba289f|#]]%0a%0aBitcoin wiki on schnorr [[https://en.bitcoin.it/wiki/Schnorr|#]]%0a%0aBip340 [[https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki|#]]%0a%0aSignatures are 64 bytes and public keys are 32 bytes [[https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki#Motivation|#]]%0a!!Comparisons%0a%0a!!!Nano (blocklattice)[[#nano]]%0a%0aNano uses a block-lattice and DAG and since the words are similar it is good to compare and contrast it with actionlattice.%0a%0a!!!!Transactions validate 2 others%0a%0aThis is about the only similarity between block-lattice and actionlattice.  I wasn't aware this is what nano did prior to designing actionlattice so this confirms it is a good choice and resembles what is done in nature.  Actionlattice however will probably have each transaction to verify 3 others and you also check 7 levels down, 3^7 transactions you check which is around 2,000.  In Nano, you really only check 2.%0a%0aHow it differs: in nano you only have to verify those transactions are valid.  In actionlattice you need to verify around 7 levels down, so 128 transactions.  If any transaction below you connected to you is invalid you risk your transaction reverting as well.  So the miner of the transaction (which can be you) incentivized to validate as far down as possible because the validity of their reward counts on it.  The person who made the transaction does not need to care very much because if it does get removed it can just be added back and there is no loss, nor theft, nor double spending because of the design of actionlattice.%0a%0a!!!!Two party transactions%0a%0aIn nano both parties have to sign for a transaction.  Actionlattice only the sender has to sign, just like standard blockchain. This is important because signing gives up security. Actionlattice goes above standard Blockchain security and ensures an address "breaks" after it signs and cannot be reused in order to preserve 100%25 maximum security.%0a%0a!!!!Individual blockchains%0a%0aIn Nano they achieve double spending protection by each address having it's own blockchain.  In actionlattice there is a global "blockchain" and we achieve double spending protection by having each address only able to hold 1 bit and once it is sent the address can no longer be used (destroyed), and nodes simply reject the latter duplicate transaction(s).%0a%0a!!!!Double spending%0a%0aNano has representative staked node voting [[https://youtu.be/IDEQE8lmaqs|#]]%0a%0a!!!Bitlattice%0a%0a!!!Blockchain%0a%0a!!Process [[#process]]%0a!!!Transactor side - create "transaction block" [[#transaction]]%0a%0a#"Sending Public Addresses" (SPA's) of each bit (cip) being sent.%0a%0a#Signatures (proves private key ownership) for the addresses (SPAs) for each bit (cip) being sent.%0a%0a#"Receiving Public Addresses" (RPA's) - One brand new address for each bit (cip) being received.%0a%0a#Internal Message (IM) which can be anything, including encoding tokens and NFT's.%0a%0a#Completed transaction signature (CTS) - Signs over the whole transaction using one (or more) of the SPA's done by the sender.  This prevents man in the middle (MITM) attack.%0a----%0a!!!Miner's side - "activation" of transaction block [[#act]]%0a%0a#Proof of Proven Sieve ([[#props|Props]]) - Completed transaction signature (CTS), number to factor (NTF), two equal digit-length factors, and nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, hashsnaps, Miners message, and then hashed to create the new NTF).%0a%0aOr 1 factor to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable and not require caching.%0a%0a**Peer blocks - 3 peer blocks NTFs (PNTFs, pronounced 'pontiffs') within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These three NTFs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a%0a**Latest [[#snaps|Hashsnaps]] of each of the five levels, which acts as a vote for the correct network snapshots.  These votes are not needed for nodes to select the fully valid hashsnaps with the most weight, but it should help clear up any supposed discrepancies.  Doing this will also act as a pretty accurate timestamp for the transactions it links to (but not necessarily for itself, as it could have taken days to factor the NTF).%0a%0a**Bitbase address (aka cipbase address) which is the Miners public address (MPA) where the bitbase is sent.%0a%0a**Miner message (MM) - anything the miner wants to write within say 100 characters (needs to be limited because there are no checks & balances over the size, without a set limit).%0a%0aThe reason why all of this data was hashed into the Number to Factor (NTF) is because the factor acts as a seal preventing a Man in the middle (MITM) attack that changes the cipbase address, miner message, or peer blocks.%0a%0aThis miner can provide a proof of semiprime which can be done on any transaction of any size for the same factoring cost.  Solve a 396 bit (or higher) challenge and you get to pick where the 3 bonds (prior art transactions) are directed.%0a%0aNow another miner can also do the same exact challenge and add the same transaction to the lattice however the challenge has to be harder, say a 400 bit number instead of 396.  This means multiple miners can mine the same transactions, they are all in the lattice but since each transaction is a non-reversible change (since by definition each address can only hold 1 bit, no more no less, once it sends its bit (cip) it can never receive another, its worn out.  this solves the double spending problem.  Each address is one and done.  It either doesn't exist, holds a bit, or is spent.  So a transaction from one specific address to another can only ever happen once and never be reversed.  We solve double spending to not allow any address to make more than one transaction ever.  And we achieve this by allowing infinite addresses.  That also gives privacy.%0a----%0a!!!Node settings%0a%0a#Max transaction size of transactions you save (not everyone has to save every transaction). Set to 0 for no pruning.%0a%0a#Minimum factored number bitlength you will accept (I would suggest 120 (396 bits) digits as of now) this should be increased over time, but not too fast as to create orphans of old transactions.%0a%0a!!!Node considerations%0a%0aThe actionlattice can be thought of like a database where each transaction is a new line.  Just like a blockchain, an actionlattice is append-only.%0a%0aHowever nodes can prune their lattice to only include transactions under a certain size or that have a sufficient proof of semiprime.  Say the Posi starts at 120 digit number factorization, when the node moves to require 130 digit all the 120 digit proven transactions need to be remined at 130 digit proof.  Every re-mining to increase the proof level produces a new cip, and a higher value cip in fact.%0a%0aSince you don't want the transactions your transaction is connected to to dissapear due to node pruning, you are going to want your transaction to be connected to small transactions that have a high proof level.  Transactions closest to the surface will have the most up-to-date proof level so are good candidates to connect to.  One nice thing is that if the transaction size is acceptable to most of the nodes now, chances are it will continue to be in the future because as hard drives grow due to moores law, storage capacity increases and likely nodes will allow bigger transactions over time because they can and it supports the network.%0a%0a!!Number to Factor (NTF) [[#ntf]]%0a!!Proof of Semiprime/sieve (Posi) [[#posi]]%0a%0aSee [[NatureVault/Digital Collectible Network#mine]]%0a%0a!!!Data standard bitlevels [[#datasize]]%0a%0aSee also [[#data|data]]%0a%0aThis is initial levels, as each bitlevel within each of these groups can hold double the last. For example a 55 digit [[#ntf|NTF]] can hold 64 bytes of transaction data, whereas a 60 digit number can hold 128 bytes. Each new bitlevel doubles the size allowed of the former and every 6 bitlevels (bepoch) it goes up 64x.  The numbers to factor to achieve these storage capacities will go up by 5 digits every 2 years, butthe amount of storage space allowed will not go up without a vote.  For example right now factoring a 145 digit number allows you to store 17 mb, in 2 years that would require factoring a 150 digit number to store the same 17 mb.%0a%0a#%25red%25Alpha 64 bytes%0a%0a#%25orange%25Beta 4092 bytes (4.1 kb)%0a%0a#%25green%25Gamma 262144 bytes (262 kb)%0a%0a#%25purple%25Delta 16777216 bytes (17 mb) - max 536870912 bytes (537 mb)%0a%0a!!!!Notes%0a%0a32 byte is the smallest known signature size [[https://stackoverflow.com/a/14955292|#]]%0a%0aBitcoin public keys are 33 bytes compressed and public key hashes are 20 bytes [[https://bitcoin.stackexchange.com/a/2014|#]]%0a%0aHow 20 byte bitcoin address is made [[https://bitcoin.stackexchange.com/a/64686|#]], 25 byte total after checksum [[https://bitcoin.stackexchange.com/a/64693|#]]%0a%0aThis max datasize does not automatically go up every 2 years like the digitlength, but only increases if a vote decides it should, perhaps every 7 years.%0a%0a!!!Time standard bitlevels (based on year 2022) [[#time]]%0a%0aSee also [[#diff|difficulty]]%0a%0a%25purple%25170 digit is 4 months%0a%0a%25purple%25165 digit is 2 months%0a%0a%25purple%25160 digit is 1 month%0a%0a%25purple%25155 digit is 2 week%0a%0a%25purple%25150 digit is 1 week%0a%0a%25purple%25Delta: 145 digit is 60 hour%0a%0a%25green%25140 digit is 30 hour%0a%0a%25green%25135 digit is 15 hour%0a%0a%25green%25130 digit is 8 hour%0a%0a%25green%25125 digit is 4 hour%0a%0a%25green%25120 digit is 2 hour%0a%0a%25green%25Gamma: 115 digit is 1 hour%0a%0a%25orange%25110 digit is 30 mins%0a%0a%25orange%25105 digit is 15 mins%0a%0a%25orange%25100 digit is 8 mins%0a%0a%25orange%2595 digit is 4 mins%0a%0a%25orange%2590 digits is 2 mins%0a%0a%25orange%25Beta: 85 digits is 1 min%0a%0a%25red%2580 digits is 30 sec%0a%0a%25red%2575 digits is 15 seconds%0a%0a%25red%2570 digits is 8 seconds%0a%0a%25red%2565 digits is 4 seconds%0a%0a%25red%2560 digits is 2 seconds%0a%0a%25red%25Alpha: 55 digits is 1 second%0a%0aThis can all be on one lattice%0a%0aPurple is the Delta difficulty%0a%0aGreen is the Gamma difficulty%0a%0aYellow is the Beta difficulty%0a%0aRed is the Alpha difficulty%0a%0a!!!!Explanation%0a%0aTargeting the [[#weightconstant|72 hour mark (and higher)]] is ideal as it pretty safely sets CPU as the fastest hardware (while also benefitting from an auxillary GPU) and also it makes you wait 3 days before sending the payment, which waiting 3 days to think about making a purchase helps one weed out unnecessary spending.%0a%0aThe digitlength for each level goes up one rung every 2 years to compensate for moore's law, however the [[#datasize|datasize limit]] does not - without a vote.  The vote can be held every 7 years or something.%0a%0aThese are not hard and fast rules just rough categories of difficulty.  Light nodes would probably save delta and gamma, fast strong nodes would save all of the transactions including alpha. As the times to complete a given challenge become faster, lower bitlevel proofs can be pruned (which would need to be re-mined at a higher bitlevel to not disappear) and/or future proofs will need to be a higher bitlevel.%0a%0aIf it is in the lattice and is spent, it cannot be reused.  If the network as a whole forgets it then it can be reused.%0a%0aThese bitlevels chosen by the miner do affect [[#consensus|consensus]] because transactions ruled invalid or connected to invalid blocks will be deleted.  They will need to be reactivated (remined) in order to add back to the lattice so they lost all the proof they provided so are incentivized to be especially careful where they connect.  The voting [[#weight|weight]] determined by the digit-length of the [[#ntf|NTF]] is what determines their voting power.%0a!!!Notes%0a%0aThis is how long it takes to factor a base-2 brilliant number at each bitlevel.  In reality it would take many attempts at factoring nearly base-2 brilliant numbers so it will probably take 10x as long as this to find one that fulfills the challenge, and the higher the bitlevel, likely the more attempts needed.%0a%0aPrime factorization on optical (photonic) computers [[https://iopscience.iop.org/article/10.1143/JJAP.48.09LA02/meta|#]]%0a%0aQuantum computers would need to use shor's algorithm.%0a%0aCPU's are favored for challenges with over roughly 140 digits.%0a%0aGPU's can ECM up to around 140 digits.%0a%0aSNFS numbers should not be allowed [[https://www.mersenneforum.org/showthread.php?t=26852|#]]%0a%0a!!Proof of proven sieve/semiprime (Props) [[#props]]%0a%0aSee also [[#act|transaction activation]]%0a%0a!!Cips%0a%0a!!!Use case%0a%0aCip's don't need to have value, they vcan simply be placeholders for tokens whose value is based on something else.%0a%0aHowever we could (and probably should) allow proposing a transaction to be able to use a little [[#contract|smart contract]] to pledge an amount of Cip's to be given to the sucessful miner of your transaction.  This could buy you a fast and strong initial confirmation, which will lead to faster subsequent confirmations, and thus a faster completed transaction.%0a%0a!!!Value%0a%0aEach cip will have a proof level (like 70 digit or 155 digit or whatever) and a hashsnap it was included in, which is basically a timestamp.  You can value them whatever you want to.  None of them will be perfectly identical, and people can design schemes to value them.  I am guessing that for example any 155 digit proof performed in the same year will likely have identical or similar value.%0a%0aA cip is a digital collectible, not a currency persay.  That said collectibles often are used like currencies, such as coins or even dollar bills.  Each coin or bill is unique.%0a!!Smart contracts [[#contract]]%0a%0aThe first contract type is pledging coins to the [[#act|miner]] of a transaction.%0a%0a!!Data [[#data]]%0a%0aSee also [[#datasize|datasize]]%0a%0a%0aA certain amount of data can be stored in a transaction.  Since as many txn's as desired can be added to the Actionlattice in parallel,a size limitation does not effects number of transactions per second the network can handle, which is in theory, infinite and limited only by bandwidth and processing speed.%0a%0aMaybe 1024 bits would be reasonable which is enough for 4x 256 bit signatures.%0a%0aAlso it depends on how difficult the number to factor is.  If it takes 1 min on an average computer to factor perhaps it would allow less data to be stored than a [[#ntf|number to factor]] that takes 1 hour on a average computer.%0a%0a!!!Censorship%0a%0aActionlattice is very censorship resistant.  However lets say you live in a jurisdiction where holding or serving certain types of data is illegal.  The only part of a transaction that can hold unlimited types of data is the message portion.  So you can prune the message out of the transaction you save and just replace it with the hash of the message, this way no transactions are censored but the message can be censored at a nodes discretion.  Pruning out the message and replacing it with the message hash can also be done as standard practice for light nodes.%0a%0aAs long as some node somewhere is keeping the actual message, it could easily be appended into someone elses private actionlattice by matching the message with the message hash.%0a!!Genesis [[#genesis]]%0a%0aThe genesis, called lattigenesis, requires number of bonds + 1 transactions (in the case of 2 bonds - a trinity) to begin that cross reference (connect) to each other. Three transactions is the minimum genesis for a 2 bond system, and more could be used which would make the surface that would need to be attacked larger, and thus a larger genesis is more resistant to attack.  But using the minimum viable genesis (MVG) of a trinity for 2 bonds is preferable to keep "fake" transactions to a minimum.  Genesis transactions should not have a cipbase (no new coins should be generated).  Later transactions can just be blank with no cip movement in order to collect cipbase cips.%0a%0aThe genesis seeds the crystallization of the lattice.%0a%0aAttach:lattigenesis.png | '''2 bond version gives a 3 transaction genesis'''%0a%0aAttach:3genesis.png | '''In the 3 bond case there would be a 4 transaction genesis.'''%0a%0a!!Difficulty [[#diff]]%0a%0aSee also [[#time|time standard]]%0a%0aMoore's law shows that every 5 more decimal digits you double the difficulty [[https://mersenneforum.org/showthread.php?t=19171&highlight=Moore|#]] [[https://mersenneforum.org/showthread.php?t=23078|#]] or 17-18 bits [[https://www.mersenneforum.org/showpost.php?p=606655&postcount=28|#]], which may happen every 3 years.  So the ease of factoring a 110 digit today will be what its like to mine a 115 digit number 3 years from now.%0a%0aThe nodes set the minimum difficulty they will accept, which should probably take at least 1 second to complete.  This should be raised based on basically what is the minimum difficulty proof that is present in the network.  Since miners get rewarded to re-mine old transactions at higher difficulty, the network autocompensates for moore's law.  The result of this is old rewards would slowly loose value over time, at about the rate that a PC depreciates.  That could be quite fast, value might decline with moore's law for old cips. However you can keep mining fresh new cips with high value constantly.  [[NatureVault/Digital Collectible Network]] doesn't have the value loss problem though.  Neither does Fact0rn.%0a%0aValue depreciation could be prevented by raising the digit-length of the [[#ntf|NTF]] by 5 every 2.6 years (koomey's law) but then the network would no longer auto regulate itself and this central planning will eventually cause the network to fail when koomey's law deviates in doubling time and the network fails to adapt properly.  I would rather trade value proposition for long term health of the network.%0a%0aPreviously I had thought of requiring that the smallest of the two factors of the semiprime being 40%25 (0.4x) of the bitlength to mostly preclude GPU's and ECM asics but only require 1 GNFS sieve to activate the transaction.  Now however (after contemplating Fact0rn) I think I will make it both factors have to be the same number of bits.  This will mean a couple dozen GNFS' will have to be done in order to activate the transaction.  The reason for doing this is to make it if multiple people are working on the same transaction that their is a more random chance of who wins it.  Also so that we don't have to worry about GPU's being able to ECM farther or the like and I don't want to ever have to change this setting.%0a%0a!!Voting weight [[#weight]]%0a%0avoting weight = y = (2^(digitlength/15)/(12.7))*((2^(digitlength/5))/2048)%0a%0aGPU ECM is 10x faster than CPU, which is compensated by the [[#weightconstant|weighting constant]].%0a%0aThere should also be weight based on how new the peer transactions are (the transactions your transaction is connecting to) in order to incentivize people to stay on the chain-tip as much as possible adding confirmations to new transactions instead of old ones.  Perhaps a compounding 5%25 reduction for every extra day old the oldest peer transaction is that you are connecting to.  So confirming a 1 day old transaction would yield you 95%25 of the reward, a 2 day old transaction would be 95%25*95%25=90.25%25 reward, 3 day old would be 85.74%25 etc.  This also creates a [[#price|price stabilization]] effect because if transactions slow down to a crawl and there are only a few transactions per month, reward for transactions would be smaller due to this factor  and thus emission reduces so price can trend upwards.%0a%0a!!!Weighting function%0a%0a!!!!output:%0a%0aVoting weight = y%0a%0a!!!!inputs:%0a%0adigitlength = x%0a%0a!!!!Initial Equation%0a%0af(x) = a (1 + r)^x%0a%0ay = initial (1+proportion growth per digit added)^(number of digits added)%0a%0a%25green%25**y = (2)^(x/5)**%25%25%0a%0a!!!!!Examples%0a%0a55 digitlength%0a%0ay = (2)^(55/5) = 2048%0a%0a56 digitlength%0a%0ay = (2)^(56/5) = 2352.5%0a%0a60 digitlength%0a%0ay = 2^(60/5) = 4096%0a%0a100 digitlength%0a%0ay = 2^(100/5) = 1048576%0a%0a!!!!Intermediate equation%0a%0aNow we want to normalize based on the current smallest accepted digitlength.%0a%0aSo currently we accept 55 digit length minimum, which has a difficulty rating of 2048.  Thus we divide everything by 2048 to find relative difficulty%0a%0aRelative difficulty = difficulty/min difficulty%0a%0aRelative voting weight = (2^(digitlength/5))/(2^(mindigitlength/5))%0a%0acurrently with 55 digitlength min, equation would be:%0a%0a%25green%25**y = (2^(x/5))/2048**%25%25%0a%0aThis shows for ever ~17 digitlength increase, we have 10x the voting weight.%0a%0a!!!!!Examples%0a%0a55 digitlength%0a%0ay = (2^(55/5))/2048 => 1%0a%0a56 digitlength%0a%0ay = (2^(56/5))/2048 => 1.15%0a%0a60 digitlength%0a%0ay = (2^(60/5))/2048 => 2%0a%0a63 digitlength%0a%0ay = (2^(63/5))/2048 => 3%0a%0a65 digitlength%0a%0ay = (2^(65/5))/2048 => 4%0a%0a70 digitlength%0a%0ay = (2^(70/5))/2048 => 8%0a%0a72 digitlength%0a%0ay = (2^(72/5))/2048 => 10.6%0a%0a80 digitlength%0a%0ay = (2^(80/5))/2048 => 32%0a%0a100 digitlength%0a%0ay = (2^(100/5))/2048 => 512%0a%0a105 digitlength%0a%0ay = (2^(105/5))/2048 => 1024%0a%0a140 digitlength%0a%0ay = (2^(140/5))/2048 => 131072%0a%0a!!!!Final equation [[#weightconstant]]%0a%0aFor the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits [[#test|(*)]], which is about 10x extra voting weight for every additional 50 digits, so using CPU's to factor larger numbers would be a better option [[#test|(*)]] than using GPU's for lots of small numbers.%0a%0a[[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. When we graph the total voting weight on the actionlattice with respect to digitlength, we should see a reasonably flat, smooth, bell curve with its maximum centered around the [[#time|72 hour mark]] (currently around 146-147 digitlength) and incentives (voting weight) should be tuned to achieve this bell curve.**%0a%0avoting weight = (weighting constant)(2^(digitlength/5))/2048%0a%0aweighting constant (c) = 2^(digitlength/15)/(2^(55/15))%0a%0aweighting constant (c) = 2^(digitlength/15)/(12.6992084157)%0a%0avoting weight = y = (2^(digitlength/15)/(12.7))*((2^(digitlength/5))/2048)%0a%0a!!!!!Examples%0a%0aAttach:votingweight.ods%0a%0a55 digitlength%0a%0ay = (2^(55/15)/(12.7))*((2^(55/5))/2048) = 1%0a%0a60 digitlength%0a%0ay = (2^(60/15)/(12.7))*((2^(60/5))/2048) = 2.52%0a%0a65 digitlength%0a%0ay = (2^(65/15)/(12.7))*((2^(65/5))/2048) = 6.35%0a%0a70 digitlength%0a%0ay = (2^(70/15)/(12.7))*((2^(70/5))/2048) = 16%0a%0a100 digitlength%0a%0ay = (2^(100/15)/(12.7))*((2^(100/5))/2048) = 4096%0a%0a105 digitlength%0a%0ay = (2^(105/15)/(12.7))*((2^(105/5))/2048) = 10321%0a%0a140 digitlength%0a%0ay = (2^(140/15)/(12.7))*((2^(140/5))/2048) = 6658043%0a%0a!!!!Notes%0a%0aEach transaction's vote is weighted by the digit-length of the NTF.%0a%0aevery 5 digit length is double the weight.  So a 105 digit [[#ntf|ntf]] is twice the weight as a 100 digit ntf.%0a%0a!!Price [[#price]]%0a%0a!!Software design%0a%0a!!!Miner%0a%0aMiner software will need:%0a%0a!!!!Find unconfirmed transaction%0a%0a!!!!Create activation block attached to transaction%0a%0a!!!!Iterate nonce and hash the block to give random numbers%0a%0a!!!!Run ECM on candidate numbers and eliminate non acceptable%0a%0a!!!!Run GNFS on candidates to find a base-2 brilliant number%0a!!!Node%0a%0a!!Attacks [[#attacks]]%0a%0a!!!Opsonization [[https://en.wikipedia.org/wiki/Antibody_opsonization|#]] AKA 99.9%25 attack hard fork%0a%0aA fully successful opsonization attack causes a destructive hardfork in the network.  But new [[#genesis|genesi]] can be created and rebuild the network if it happens.  These new genesi can later be reconnected together as the threat subsides.%0a%0aOpsonization in this context means cover the entire surface of the actionlattice with fraudulent transactions in order to force new transactions to confirm fraudulent ones.%0a%0aSurface area to volume is 3/R [[https://van.physics.illinois.edu/ask/listing/791|#]]  So surface area is directly proportional to volume.  This means that as the size of the actionlattice grows, so does the difficulty in performing the opsonization attack.%0a%0aThe reason this is nicknamed the "99.9%25" attack is because you would literally need to flood the lattice with enough transactions to literally cover the entire surface, except for 1 single transaction.  Since a new transaction needs 2 old transactions to connect, you would literally have to connect to all other transactions in the lattice except one in order to force new transactions to confirm the fradulent ones.  %0a%0aNow practically speaking you might get less rigorous miners to confirm some of your fradulent transactions if they aren't willing to check the validity of everything, but this should never happen, a miner should always check validity of the transactions it is connecting to, but some may decide not to, leading to the downfall of the network.  Miners not being rigorous would make them "bad" and a part of the attack.  "Good" miners will always check validity.  Only very few good miners are needed to nullify an attack and have the network recover.%0a%0aIf the 99.9%25 attack only achieves 99.8%25 for example (fudging numbers here for illustration) then new transactions can find the "hole" and connect only to the good transactions and this would create what amounts to a "genetic bottleneck" and basically would grow out through this opening and slowly move out of the prison created by the opsonization attack.%0a%0aEven in the case of a successful opsonization attack that totally nullifies the surface with fraudulent transactions, someone can create a new [[#genesis|genesis]] (hardfork) by creating 3 crosslinking transactions and all the old good transactions can be re-mined onto this new genesis.  Preferably many of these new genesi would be created so that the attacker would have to attack them all at once.%0a%0a!!!Tumor attack soft fork%0a%0aA tumor attack causes a benign softfork in the network.%0a%0aA tumor attack is similar to how a traditional 51%25 attack works, but it does not cause a hardfork like it does in a blockchain.  Basically a bad miner starts confirming their own transactions with more fraudulent transactions.  Basically nodes would need to figure this out and excise the tumor of fraudulent transactions (and any transactions connected to them above them) from their ledger.  This way the confirmations don't matter.  However if this attack is done quickly after a transaction, some nodes might be fooled into saying the transaction was confirmed if they were not checking validity.  Nodes must be checking validity before adding transactions to their ledger.%0a%0a!!!ASIC%0a%0aAn ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million each (this isn't just a one-time development cost), and it also would only work for one specific bitlength number without physical reconfiguration, in the case of the SHARK paper it was designed for 1024 bit numbers.  More discussion here: [[https://www.reddit.com/r/Monero/comments/grms1c/comment/fs0ofio/?utm_source=share&utm_medium=web2x&context=3|#]]%0a%0aThere is a proposed ECM ASIC which means we need to go up probably to 0.47x bitlength for smallest factor to try to avoid these [[https://cr.yp.to/conferences/2006-sharcs/www.ruhr-uni-bochum.de/itsc/tanja/SHARCS/talks/ecm_paper.pdf|#]] but currently it only works up to 200 bits, which is like a 70 digit number or less than that.%0a%0a!!!GPU%0a%0aGpu's can ECM a number looking for factors up to around 0.37x of the bitlength of the number in the same time it takes a CPU to use GNFS to find all factors.  What this means is that the stength of factors required would mean that there should be no factors smaller than 0.37x of the bitlength.  Preferably 0.4x. the farther we go over around 0.32x requirement the more "useless" sieves we will have to do due to finding decently strong semiprimes but they are not strong enough.  Due to risks of ECM asics though my current thought is require semistrong semiprimes with factors no smaller than 0.47x of the bitlength.  If you put the requirement at around 0.37x then you can balance GPU's with CPU's if you want something like that otherwise at around 0.4x and above GPU can ECM up to 0.34-0.37x and then pass it to the CPU in order to do the GNFS sieve and find the factors.%0a%0a!!!Quantum computers [[#quantum]]%0a%0aQuantum computers can do 2 things against something like actionlattice.  First they can potentially crack keys, reverse the private key from the public key.  I believe such a process would use grover's algorithm which isn't exceptionally fast so that provides some security.  Also we can use quantum resistant addresses which is no problem (although it would bloat transaction size for us especially).%0a%0aThe next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.  For a quantum computer to factor a 150 digit (496 bit) number would take [[ https://www.reddit.com/r/Monero/comments/grms1c/a_holy_grail_pow_for_monero_outlined_gnfs/|994 clean logical qubits]]. Shors algorithm as of 2020 could still only factor 2 digit numbers [[https://crypto.stackexchange.com/a/59796|#]].  Quantum computers have been around for 54 years now [[https://en.wikipedia.org/wiki/Timeline_of_quantum_computing_and_communication|#]] and certainly don't have over 54 clean logical qubits (qubits that can run shor's algorithm).  [[NatureVault/TEEFs law]] states that at best 1 logical qubit will get added per year, since adding one clean logical qubit is probably twice as hard as the last added.  This places us at least a couple hundred years before quantum computers can do what a ryzen processor can do today.  And in a couple hundred years ryzens will be orders of magnitude more capable then they are today.%0a%0aClassical computers gain about 5 bits in factoring ability per year.  Every clean logical qubit added to a quantum computer gains it 1/2 of a bit.  That means for quantum computers to keep up with classical computers for factoring, they would need to gain 10 clean logical qubits per year.  According to the 50 year history of quantum computers, that has never happened nor ever come close.  If anything we seem to be on track for 1 clean logical qubit every 3 years which means quantum computers will progress 30 times slower than classical computers when it comes to factoring large numbers. If this is true, quantum computers will literally never be a threat to GNFS or RSA.%0a%0a!!!SNFS%0a%0aGreatest common denominator (GCD) can be run reasonably quickly (seconds-minutes) on a candidate number to see if it is of a special form where SNFS can be run faster than GNFS [[https://www.mersenneforum.org/showpost.php?p=614588&postcount=16|#]] [[https://www.mersenneforum.org/showpost.php?p=614600&postcount=17|#]].  The only question is how common are these numbers where looking for SNFS-able numbers and bypassing GNFS would be viable.  One workaround to prevent this is to have the nodes simply reject any special forms, which can be somewhat easily checked - and known even faster after the number is factored (since the possible 'greatest common denominator' is now simply checked to match the factors).%0a%0a%0a!!!Node collusion%0a%0aAnyone can be a node.  The people who want to know if a transaction is confirmed would either rely on their own node, or a trusted node to see if their transaction was confirmed.  Eventually over time the nodes should reach consensus on the ledger, as everything can be verified and nodes that condone fraudulent transactions would be eliminated from the network of nodes.%0a%0a!!!Types of invalid transactions%0a%0a!!!!Sending cips that don't exist%0a%0aCips are all created in a cipbase transaction.  So when adding a new transaction to the ledger a node must validate that the cipbase transaction exists that gave a cip to the address that is now trying to send it.  Maintaining a UTXO may help make this process quicker.  It will take a long time to check if a huge transaction sending say 1000 cips all check out, and this is why nodes can rightfully limit the transaction size they are willing to save.%0a%0a!!!!Duplicate transaction%0a%0aDuplicate transactions are allowed as long as they contain a different (usually higher) bitlevel proof.  If they have the same bitlevel proof then the latter one would be discarded by the node and should not be built on by other transactions.  This is also dis-incentivized because the loosing cipbase reward would be lost forever, and the work done lost.%0a%0a!!!!Double spend%0a%0aThe same cipbase addresses as another transaction are sent to different addresses, attempting to duplicate the original coins.  New transactions would vote for which they thought happened first, and the one with the most votes wins, the other looses and is deleted along with all the transactions that connected to (voted for) the bad transaction.  So they are incentivized to vote correctly (which is valid and which is not).%0a%0a!!!!Double mine%0a%0aThe same transaction block, was mined twice with two different proofs.  This would never be done intentionally but we still face the possibility it happens. New transactions vote for which one happened first by bonding to them.  Once there is consensus then the looser and everyone that bonded to it is deleted.  This incentivizes new transactions to vote correctly (about which is valid).%0a%0a!!!!Non-standard bitlevel proof%0a%0aThe [[#diff|difficulty]] aka 'bitlevel proof' is standardized to certain 'activation levels'.  These are 5 digit levels which is around every 17-18 bits.%0a%0aIf the miner proposes an NTF that is not a multiple of 5 decimal digits, it should be discarded or the reward rounded down to the nearest accepted bitlevel and thus standard cip type (aka cip397)%0a%0a!!!!Invalid signatures or proof of semiprime%0a%0aBasic stuff here, make sure the signatures match the addresses, make sure the proof of semiprime is valid, etc.%0a%0a!!!!Connected to an invalid transaction%0a%0aThere is a reason why each transaction can only be connected to two others and not more, because 2 gives good functionality while not overcomplicating how many transactions are checked.  Each node would want to check the validity of several layers down from the transaction to make sure the transactions it is confirming are valid.  If you go down 1 level you verify the two transactions it is confirming are valid. Two levels down you are verifying 4 transactions.  Three levels verifies 8 transactions and so on, each node needs to verify 2^n transactions for every new transaction, where n is the number of levels you go down.  Nodes might be set for n=7 default which is 128 transactions.  Lighter nodes can set this lower, but each node should be transparent of their setting so people connecting to them or merchants using their services can know how sure they are.  If any transaction is invalid, all transactions that are connected to them are also rendered invalid and all are removed from the ledger of the node and no longer exist.%0a%0a!!!!Double spend%0a%0a!!Downsides%0a%0aBasically everything written is upsides so upsides don't need a section.%0a%0a#Fungibility: The main downside I can see so far is the value of certain bitlength cips will decrease over time (Edit: we actually do timestamp now, called [[#snaps|hashsnaps]]), perhaps at a rate of moore's law, so halving in value every 3 years, so basically the value will depreciate like a PC value does. I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  If we timestamped the transactions and increased the digit-length requirement of the [[#ntf|NTF]] by 5 every 2.6 years then 1 cip = 1 cip forever, but I tend to not want to make a rigid difficulty curve which would eventually break.  I would rather sacrifice value proposition for flexibility, so that the network can act as a sensor of koomey's law rather than a subject of it. Also I would rather not rely on arbitrary timestamps.%0a%0a**Another way to improve this is to have different genesi lattices, Alpha for low bitlength proof, Beta for medium bitlength proof, Gamma for high bitlength proof.  so a gamma cip would always hold the same value, as would a beta or alpha cip.  The downside to this solution is there isn't infinitely variable bitlength that can be rewarded so we really wouldn't know how high a proof level could be without trying it.  So in this example alpha might start at 80 digit proof, then next year might be 82 digit proof, next year 84 digit proof etc.  So one alpha cip will always equal 1 alpha cip.  Problem is we don't know how fast we can raise that bitlevel proof requirement (which is set by each individual node) since there is no incentive for miners to go above and beyond.%0a%0a#Consensus: See also [[#consensus|consensus]]. It is a rolling consensus instead of a block based consensus. What this means is the nodes can watch a transaction gain more confirmations in real time (while watching for double spends) to decide when a transaction is complete, instead of waiting for arbitrary block-times to confirm it (like a blockchain). %0a%0a#Size: Having no transaction size limit is a downside because different nodes will have different requirements, but GRIN also uses a similar method for node settings which is more democratic and less centrally planned.%0a%0a!!Inspiration%0a%0aInspiration for this idea came mostly from my work on [[CollectBit]] and [[NatureVault/Digital collectible network]].  I hit a wall not knowing what to do next. %0aI started shifting into ASIC resistance by hashing the entire blockchain like in [[blockvault]] (which still is a good concept for saving useful data) and then later making my own algorithm, basically [[yespower#fork|forking Yescrypt]] and/or [[Monero fork|RandomX]] and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  I was also interested in [[proportional reward]] from [[staticcoin]]s like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it [[ https://www.reddit.com/r/Monero/comments/grms1c/comment/fs03cis/?utm_source=share&utm_medium=web2x&context=3| can't really work in a 1D blockchain]].%0a%0aThen learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would make it a 3D blockchain.  This 3D blockchain design, actionlattice, also provides a proportional reward for miners which is awesome.  Its funny and fitting that all the limitations that 1D blockchain has (51%25 attack, unfair reward, mining pools, asics, etc) can be overcome by moving into 3D.  We do live in a 3D world after all.%0a%0aDoing research further on mersennes forum I also ran into Fact0rn post and how they wanted to use factoring in a 1D blockchain.  I explained to them why it wouldn't work as designed in their discord and here [[https://www.mersenneforum.org/showpost.php?p=614575&postcount=87|#]] and offered them my help and potential solutions.  That said their requirement of "strong semiprimes" actually was an improvement for 1D blockchain over my "semistrong semiprimes" and realizing why their solution was better led me to my advice on how to make it better still (in the link above). %0a%0aI chose semistrong semiprimes because in my collectbit database people can submit individual proofs to mine and I wanted every GNFS sieve, after ECM, to yield a solution - therefore proving GNFS was done but not requiring extra effort after that.%0a%0aI still think 3D blockchain is the best current implementation for GNFS solely because multiple people can submit proofs at the same time and even back in time slightly (allowing mining offline).  Also the 3D method will inherently scale to much much greater transactions per second (TPS) than a 1D or 2D can achieve.%0a%0a!!Prior art [[#prior]]%0a%0a!!!Anders%0aAnders 2014 proposal for integer factorization proof of work [[https://bitcointalk.org/index.php?topic=783110.0|#]]%0a%0aAnders post Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] [[ https://bitcointalk.org/index.php?topic=738297.msg8352090#msg8352090|#]] bitcoin can enter a time warp creating the next dark age where large of chunks of history are forgotten. [[PoH]] may be a potential solution. Actionlattice doesn't need to worry about timestamps to dictate the "earliest transaction" because every unit can only be sent once so any version of that transaction is valid.%0a%0aAnders also came up with unique coin ID's similar to actionlattice idea to prevent double spending [[https://bitcointalk.org/index.php?topic=781967.0|#]]%0a%0a!!!Nature%0a%0a2017 proposal [[https://bitcointalk.org/index.php?topic=2575256.0|#]] ~[[~NatureHacker]]%0a%0aOriginal mersennes proposal [[https://www.mersenneforum.org/showthread.php?t=26659|#]]%0a%0aOriginal proposal to Monero [[https://www.reddit.com/r/Monero/comments/grms1c/a_holy_grail_pow_for_monero_outlined_gnfs/|#]]%0a%0aToppling the blockchain [[https://www.naturehacker.org/2021/01/toppling-blockchain-prime-factorization.html|#]]%0a%0aBitcoin vs DCC [[https://www.naturehacker.org/2021/01/bitcoin-vs-digital-collectible-currency.html|#]]%0a%0a[[NatureVault/Digital collectible network#mine]]%0a%0a[[CollectBit]]%0a!!!Fact0rn%0a%0aFact0rn came up with the requirement to require base-2 brilliant numbers which increases randomness of winning a challenge to democratize it slightly for a 1D (traditional) blockchain. However, this only allows up to a maximum of a couple dozen miners/mining pools while staying fair.  Right now they use bitlength of the number adjustment to adjust difficulty.  What they need to do to create fairness is let the difficulty be set by moores law (gain 5 decimal digits (17-18 bits) every 2-3 years and then adjust difficulty with requiring a certain number of "leading 9's" [[ https://www.mersenneforum.org/showpost.php?p=614575&postcount=87|#]] on one or both factors to adjust the blocktime to 20 minutes for a rise or fall of blocktime (change in number of miners).%0a%0aFactorn integer factorization proof of work [[https://github.com/FACT0RN/FACT0RN|#]] [[https://www.mersenneforum.org/showthread.php?t=27807|#]] [[https://www.coinbase.com/blog/fact0rn-blockchain-integer-factorization-as-proof-of-work-pow|#]] initial commit to merge bitcoin code [[https://github.com/FACT0RN/FACT0RN/commit/08a870f0cce99ed5fe496a0f5f76f03aa2a65140|#]]%0a%0aFactorn whitepaper [[https://fact0rn.io/FACT0RN_whitepaper.pdf|#]] takes them 200 semiprimes to find a valid semiprime (has a factor of exactly half the bitlength) about 1 in 20 for reasonably strong semiprimes.  This means my finding that 1 in 300 numbers is semiprime, 1 in 6,000 numbers is a strong (base-2 brilliant) semiprime.%0a%0a!!!Nano%0a%0aSee [[#nano|nano comparisions]]%0a%0aGood rundown of nano [[https://www.youtube.com/watch?v=qZJyT-B9QDc|#]]%0a%0aNano shares almost nothing with actionlattice besides the "lattice" name, nano calls theirs a blocklattice.  However understanding how it works and the design decisions made can help in understanding the benefits to actionlattice.%0a%0a!!Notes [[#note]]%0a%0aOne way accumulators potentially usable in timestamping [[https://link.springer.com/content/pdf/10.1007%252F3-540-48285-7_24.pdf|#]] pretty much if we could have an RSA algorithm that accepted 3 large primes instead of 2 then we could have 1 of the primes known, which is the timestamp.%0a%0aIf possible prove that every address is randomly generated so you can never send to the same address twice. merkle tree proofs should work [[https://www.reddit.com/r/cryptography/comments/z1hvc5/comment/ixb4qjj/?utm_source=share&utm_medium=web2x&context=3|#]] [[https://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5|#]]%0a%0aUnderstanding encryption and signatures [[https://security.stackexchange.com/questions/68822/trying-to-understand-rsa-and-its-terminology/68836#68836|#]]%0a%0aBitcoin op_return is 80 bytes but nodes can set their own limits [[https://bitcoin.stackexchange.com/questions/78572/op-return-max-bytes-clarification|#]]%0a%0aAnders Rule 30 as a hash function [[https://bitcointalk.org/index.php?topic=698460.0|#]]%0a%0aAnders tail emission [[https://bitcointalk.org/index.php?topic=725427.0|#]]%0a%0aAnders bitcoin price will stabilize over time due to arbitrage [[https://bitcointalk.org/index.php?topic=737671.0|#]]%0a%0aStrong semiprimes called base-2 brilliant numbers [[https://www.mersenneforum.org/showpost.php?p=606643&postcount=25|#]]%0a%0aBitlattice tries to go 5D [[https://bitlattice.org/|#]] why??%0a%0aMatrix vector multiplication on GPU [[https://www.mersenneforum.org/showthread.php?t=24862|#]] also [[oPoW]] uses this.%0a%0aECM depth on 150 digit number [[https://www.mersenneforum.org/showthread.php?t=26707|#]]%0a%0aResuming factoring [[https://www.mersenneforum.org/showthread.php?t=26664|#]]%0a%0aSimple explanation of GNFS [[https://www.mersenneforum.org/showthread.php?t=26984|#]] [[https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.219.2389&rep=rep1&type=pdf|#]]%0a%0aWhat length numbers do people ECM the most [[https://www.mersenneforum.org/showthread.php?t=25115|#]]%0a%0aLattice sieving on a GPU [[https://www.mersenneforum.org/showthread.php?t=27515|#]]%0a%0aprobably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] probably with QT [[https://pypi.org/project/QtPy/|#]] (choose xml or json [[https://stackoverflow.com/questions/2843552/restful-interface-for-c-qt|#]]). Go and especially Rust are good [[https://qr.ae/pvBAu3|#]]
time=1669255420
author:1669255420=
diff:1669255420:1669255207:=126c126%0a%3c Safe and strong primes might have a benefit and avoid pollard p-1 algorithm [[https://www.sjoerdlangkemper.nl/2019/06/19/attacking-rsa/|#]] but may not be worth it at high bitlevels [[https://en.wikipedia.org/wiki/Safe_and_Sophie_Germain_primes#Cryptography|#]] but better safe than sorry.%0a---%0a> Safe and strong primes might have a benefit and avoid pollard p-1 algorithm but may not be worth it at high bitlevels [[https://en.wikipedia.org/wiki/Safe_and_Sophie_Germain_primes#Cryptography|#]]%0a
author:1669255207=
diff:1669255207:1669254667:=752c752%0a%3c One way accumulators potentially usable in timestamping [[https://link.springer.com/content/pdf/10.1007%252F3-540-48285-7_24.pdf|#]] pretty much if we could have an RSA algorithm that accepted 3 large primes instead of 2 then we could have 1 of the primes known, which is the timestamp.%0a---%0a> One way accumulators potentially usable in timestamping [[https://link.springer.com/content/pdf/10.1007%252F3-540-48285-7_24.pdf|#]]%0a
author:1669254667=
diff:1669254667:1669254290:=751,752d750%0a%3c %0a%3c One way accumulators potentially usable in timestamping [[https://link.springer.com/content/pdf/10.1007%252F3-540-48285-7_24.pdf|#]]%0a
author:1669254290=
diff:1669254290:1669253990:=128c128%0a%3c Accumulators require rigid numbers, product of 2 safe primes [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529#Examples|#]] [[https://link.springer.com/content/pdf/10.1007%252F3-540-48285-7_24.pdf|#]]%0a---%0a> Accumulators require rigid numbers, product of 2 safe primes [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529#Examples|#]]%0a
author:1669253990=
diff:1669253990:1669253880:=127,128d126%0a%3c %0a%3c Accumulators require rigid numbers, product of 2 safe primes [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529#Examples|#]]%0a
author:1669253880=
diff:1669253880:1669253829:=124c124%0a%3c !!!!Primes%0a---%0a> !!!Primes%0a
author:1669253829=
diff:1669253829:1669227682:=123,126d122%0a%3c %0a%3c !!!Primes%0a%3c %0a%3c Safe and strong primes might have a benefit and avoid pollard p-1 algorithm but may not be worth it at high bitlevels [[https://en.wikipedia.org/wiki/Safe_and_Sophie_Germain_primes#Cryptography|#]]%0a
author:1669227682=
diff:1669227682:1669227641:=108c108%0a%3c !!!!e = 1073741827 (roughly 1 billion)%0a---%0a> !!!!e%0a
author:1669227641=
diff:1669227641:1669227608:=107,108d106%0a%3c %0a%3c !!!!e%0a
author:1669227608=
diff:1669227608:1669227218:=116,120c116,118%0a%3c 262147 (2^18 + 3) or 8388617 (2^23 + 9) or 268435459 (2^28 + 3) or 1073741827 (2^30 + 3) or 9007199254740997 (2^53 + 5); all have a [[https://planetcalc.com/8985/|Hamming distance (via converting to binary and subtracting)]] of 3 (1 worse than 65537) and are prime.%0a%3c %0a%3c 2147483659 (2^31 + 11) has a hamming distance of 4.%0a%3c %0a%3c I am selecting e to be %25green%25**1073741827 which is (2^30 + 3)**%25%25 because it is below the 32 bit limit imposed by some software, is prime, has a low hamming distance of 3, and is as large as possible to avoid insufficient padding attacks.%0a---%0a> 262147 (2^18 + 3) or 8388617 (2^23 + 9) or 268435459 (2^28 + 3) or 1073741827 (2^30 + 3) or 2147483659 (2^31 + 11); all have a [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|Hamming distance]] of 3 (1 worse than 65537) and are prime.%0a> %0a> 9007199254740997 (2^53 + 5) has a hamming distance of 1 and is prime.%0a
author:1669227218=
diff:1669227218:1669226356:=114,116c114,116%0a%3c Be greater than 50,000 [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529#Faulty_key_generation|#]] and less than 32 bits [[https://crypto.stackexchange.com/questions/62925/rsa-vulnerability-when-e-is-particularily-large|#]] [[https://stackoverflow.com/questions/27474550/is-there-a-limit-for-rsa-key-exponents-in-net|#]].  Needs to be smaller than lambda(n)%0a%3c %0a%3c 262147 (2^18 + 3) or 8388617 (2^23 + 9) or 268435459 (2^28 + 3) or 1073741827 (2^30 + 3) or 2147483659 (2^31 + 11); all have a [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|Hamming distance]] of 3 (1 worse than 65537) and are prime.%0a---%0a> Be greater than 50,000 [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529#Faulty_key_generation|#]] and as small as possible while having small hamming distance.  Needs to be smaller than lambda(n)%0a> %0a> 262147 (2^18 + 3) or 8388617 (2^23 + 9) or 268435459 (2^28 + 3) or 1073741827 (2^30 + 3); all have a [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|Hamming distance]] of 3 (1 worse than 65537) and are prime.%0a
author:1669226356=
diff:1669226356:1669224810:=108,109c108,109%0a%3c e should be: [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529#Key_generation|#]] [[https://crypto.stackexchange.com/questions/13166/method-to-calculating-e-in-rsa|#]]%0a%3c %0a---%0a> e should be: [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529#Key_generation|#]]%0a> %0a114,115c114,115%0a%3c Be greater than 50,000 [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529#Faulty_key_generation|#]] and as small as possible while having small hamming distance.  Needs to be smaller than lambda(n)%0a%3c %0a---%0a> Be between roughly 50,000 [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529#Faulty_key_generation|#]] and 1 billion, should be small but not too small.  Needs to be smaller than lambda(n)%0a> %0a117,118d116%0a%3c %0a%3c 9007199254740997 (2^53 + 5) has a hamming distance of 1 and is prime.%0a
author:1669224810=
diff:1669224810:1669224698:=116c116%0a%3c 262147 (2^18 + 3) or 8388617 (2^23 + 9) or 268435459 (2^28 + 3) or 1073741827 (2^30 + 3); all have a [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|Hamming distance]] of 3 (1 worse than 65537) and are prime.%0a---%0a> 262147 (2^18 + 3) or 8388617 (2^23 + 9) or 268435459 (2^28 + 3); all have a [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|Hamming distance]] of 3 (1 worse than 65537) and are prime.%0a
author:1669224698=
diff:1669224698:1669224373:=114,116c114,116%0a%3c Be between roughly 50,000 [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529#Faulty_key_generation|#]] and 1 billion, should be small but not too small.  Needs to be smaller than lambda(n)%0a%3c %0a%3c 262147 (2^18 + 3) or 8388617 (2^23 + 9) or 268435459 (2^28 + 3); all have a [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|Hamming distance]] of 3 (1 worse than 65537) and are prime.%0a---%0a> Be between roughly 50,000 and 1 million, should be small but not too small.  Needfs to be smaller than lambda(n)%0a> %0a> 262147 (2^18 + 3) or 8388617 (2^23 + 9); both have a [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|Hamming distance]] of 3 (1 worse than 65537) and are prime.%0a
author:1669224373=
diff:1669224373:1669223357:=115,116d114%0a%3c %0a%3c 262147 (2^18 + 3) or 8388617 (2^23 + 9); both have a [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|Hamming distance]] of 3 (1 worse than 65537) and are prime.%0a
author:1669223357=
diff:1669223357:1669218771:=108,114c108,114%0a%3c e should be: [[https://en.wikipedia.org/wiki/RSA_%2528cryptosystem%2529#Key_generation|#]]%0a%3c %0a%3c [[https://www.wolframalpha.com/|Prime]].  It can't have the same factors of lambda(n) or be a factor of lambda(n), so prime is ideal.%0a%3c %0a%3c Small hamming weight [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|#]].  The common e is 65537 (1+2^16) which has a hamming weight of 2 when paired with 00000.  2^16 (and seemingly every power of 2) has a hamming weight of 1 but probably isn't used because it has a lot of factors, whereas 1+2^16 is prime.%0a%3c %0a%3c Be between roughly 50,000 and 1 million, should be small but not too small.  Needfs to be smaller than lambda(n)%0a---%0a> e should be:%0a> %0a> Prime.  It can't have the same factors of n or be a factor of n, so prime is ideal.%0a> %0a> Small hamming weight [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|#]].  The common e is 65537 (1+2^16) which has a hamming weight of 2 when paired with 00000.  2^16 has a hamming weight of 1 but probably isn't used because it has a lot of factors, whereas 1+2^16 is prime.%0a> %0a> Be between roughly 50,000 and 1 million, should be small but not too small.%0a
author:1669218771=
diff:1669218771:1669217270:=108,114c108%0a%3c e should be:%0a%3c %0a%3c Prime.  It can't have the same factors of n or be a factor of n, so prime is ideal.%0a%3c %0a%3c Small hamming weight [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|#]].  The common e is 65537 (1+2^16) which has a hamming weight of 2 when paired with 00000.  2^16 has a hamming weight of 1 but probably isn't used because it has a lot of factors, whereas 1+2^16 is prime.%0a%3c %0a%3c Be between roughly 50,000 and 1 million, should be small but not too small.%0a---%0a> e should be a small hamming weight [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|#]] and not too big.  The common e is 65537 (1+2^16) which has a hamming weight of 2.  2^16 has a hamming weight of 1 but probably isn't used because it has a lot of factors.%0a
author:1669217270=
diff:1669217270:1669211651:=102,108d101%0a%3c %0a%3c %0a%3c !!!RSA considerations%0a%3c %0a%3c RSA signatures are [[https://en.wikipedia.org/wiki/Malleability_%2529cryptography%2529|malleable]] so messages being encrypted by them should be padded.%0a%3c %0a%3c e should be a small hamming weight [[https://www.hacksparrow.com/tools/calculators/hamming-distance.html|#]] and not too big.  The common e is 65537 (1+2^16) which has a hamming weight of 2.  2^16 has a hamming weight of 1 but probably isn't used because it has a lot of factors.%0a
author:1669211651=
diff:1669211651:1669211526:=371c371%0a%3c Actionlattice is very censorship resistant.  However lets say you live in a jurisdiction where holding or serving certain types of data is illegal.  The only part of a transaction that can hold unlimited types of data is the message portion.  So you can prune the message out of the transaction you save and just replace it with the hash of the message, this way no transactions are censored but the message can be censored at a nodes discretion.  Pruning out the message and replacing it with the message hash can also be done as standard practice for light nodes.%0a---%0a> Actionlattice is very censorship resistant.  However lets say you live in a jurisdiction where holding or serving certain types of data is illegal.  The only part of a transaction that can hold unlimited types of data is the message portion.  So you can prune the message out of the transaction you save and just replace it with the hash of the message, this way no transactions are censored but the message can be censored at a nodes discretion.%0a
author:1669211526=
diff:1669211526:1669211108:=367,373c367%0a%3c Also it depends on how difficult the number to factor is.  If it takes 1 min on an average computer to factor perhaps it would allow less data to be stored than a [[#ntf|number to factor]] that takes 1 hour on a average computer.%0a%3c %0a%3c !!!Censorship%0a%3c %0a%3c Actionlattice is very censorship resistant.  However lets say you live in a jurisdiction where holding or serving certain types of data is illegal.  The only part of a transaction that can hold unlimited types of data is the message portion.  So you can prune the message out of the transaction you save and just replace it with the hash of the message, this way no transactions are censored but the message can be censored at a nodes discretion.%0a%3c %0a%3c As long as some node somewhere is keeping the actual message, it could easily be appended into someone elses private actionlattice by matching the message with the message hash.%0a---%0a> Also it depends on how difficult the number to factor is.  If it takes 1 min on an average computer to factor perhaps it would allow less data to be stored than a [[#ntf|number to factor]] that takes 1 hour on a average computer. %0a
author:1669211108=
diff:1669211108:1669210496:=101,102c101,102%0a%3c We considered [[#merkle|merkle tree proofs]], [[#schnorr|schnorr signatures]], and [[#moving|moving address requirements]], and moving address requirements was the only viable solution to this problem.  Newly proposed addresses (recipients of cips in transactions) must contain a specific suffix to be valid, and these acceptable suffixes will only be valid for 72 hours.  As long as they are the recipient of a transaction within that 72 hour window, they will be able to send forever, but can never receive again.  Nodes will either keep a list of all new addresses generated in the last 72 hours and compare each newly proposed address to this list and ensure there are no matches, or simply search the last 72 hours of the lattice to ensure no newly proposed addresses match.%0a%3c %0a---%0a> We considered [[#merkle|merkle tree proofs]], [[#schnorr|schnorr signatures]], and [[#moving|moving address requirements]], and moving address requirements was the only viable solution to this problem.  Newly proposed addresses (recipients of cips in transactions) must contain a specific suffix to be valid, and these acceptable suffixes will only be valid for 72 hours.  As long as they are the recipient of a transaction within that 72 hour window, they will be able to send forever,but can never receive again.  Nodes will either keep a list of all new addresses generated in the last 72 hours and compare each newly proposed address to this list and ensure there are no matches, or simply search the last 72 hours of the lattice to ensure no newly proposed addresses match.%0a> %0a107c107%0a%3c Each suffix is good for 72 hours for newly proposed addresses (even though a new suffix is generated daily).  This means the 3 hashsnaps you concatenate and hash are the three newest daily hashsnaps you are aware of, and if you are doing a long proof you may want to start your attempts as soon as the daily hashsnap is published. However if you just want to factor a large challenge so you can upload a lot of data to your transaction (say a picture or video) then you don't have to have any recipient cips, therefore the 72 hour window doesn't apply.%0a---%0a> Each suffix is good for 72 hours for newly proposed addresses (even though a new suffix is generated daily).  This means the 3 hashsnaps you concatenate and hash are the three newest daily hashsnaps you are aware of, and if you are doing a long proof you may want to start your attempts as soon as the daily hashsnap is published. %0a
author:1669210496=
diff:1669210496:1669210420:=15c15%0a%3c Bitcoin was the rough draft.  Actionlattice is the fulfilment of the technology. Having a non-reusable address for each and every satoshi would not have been feasible in 2008, but now with software wallets using HD key generation, we can have nearly infinite addresses at our fingertips - making actionlattice a reality. %0a---%0a> Bitcoin was the rough draft.  Actionlattice is the fulfilment of the technology. Having a non-reusable address for each and every satoshi could not have been done in 2008, but now with software wallets using HD key generation, we can have nearly infinite addresses at our fingertips - making actionlattice a reality. %0a
author:1669210420=
diff:1669210420:1669210249:=27c27%0a%3c Attach:actionlattice.png | '''This is for a 2 bond version, 3 bond version (called xlattice) would look a bit more complex.'''%0a---%0a> Attach:actionlattice.png | '''This is for a 2 bond version, 3 bond version would look a bit more complex.'''%0a
author:1669210249=
diff:1669210249:1669209711:=43c43%0a%3c In the examples here we use 2 or preferably 3 bonds per transaction but this can be any number set by the network.  The more bonds you require the faster there will be consensus/convergence but also the more time it will take each miner to activate a transaction.  Also the number of levels down the miner verifies will also add to the time.  Somewhere between 2-10 bonds would probably be ideal and over time this number can even be increased as computers get faster at verifying transactions (due to moores law). I think I would pick 3 bonds.%0a---%0a> In the examples here we use 2 bonds per transaction but this can be any number set by the network.  The more bonds you require the faster there will be consensus/convergence but also the more time it will take each miner to activate a transaction.  Also the number of levels down the miner verifies will also add to the time.  Somewhere between 2-10 bonds would probably be ideal and over time this number can even be increased as computers get faster at verifying transactions (due to moores law). I think I would pick 3 bonds.%0a
author:1669209711=
diff:1669209711:1669209650:=103,104c103,104%0a%3c !!!Moving address requirements [[#moving]]%0a%3c %0a---%0a> !!!Moving address requirements%0a> %0a121,122c121,122%0a%3c !!!Merkle tree [[#merkle]]%0a%3c %0a---%0a> !!!Merkle tree%0a> %0a129c129%0a%3c !!!Schnorr [[#schnorr]]%0a---%0a> !!!Schnorr%0a
author:1669209650=
diff:1669209650:1669209251:=97,98c97,98%0a%3c We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacrum]] [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529#Examples|accumulator]]) keys since they are widely supported, use basic math - factoring instead of elliptic curves (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a%3c %0a---%0a> We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacrum]] [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529#Examples|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a> %0a101c101%0a%3c We considered [[#merkle|merkle tree proofs]], [[#schnorr|schnorr signatures]], and [[#moving|moving address requirements]], and moving address requirements was the only viable solution to this problem.  Newly proposed addresses (recipients of cips in transactions) must contain a specific suffix to be valid, and these acceptable suffixes will only be valid for 72 hours.  As long as they are the recipient of a transaction within that 72 hour window, they will be able to send forever,but can never receive again.  Nodes will either keep a list of all new addresses generated in the last 72 hours and compare each newly proposed address to this list and ensure there are no matches, or simply search the last 72 hours of the lattice to ensure no newly proposed addresses match.%0a---%0a> We considered merkle tree proofs, schnorr signatures, and moving address requirements, and moving address requirements was the only viable solution to this problem.  Newly proposed addresses (recipients of cips in transactions) must contain a specific suffix to be valid, and these acceptable suffixes will only be valid for 72 hours.  As long as they are the recipient of a transaction within that 72 hour window, they will be able to send forever,but can never receive again.  Nodes will either keep a list of all new addresses generated in the last 72 hours and compare each newly proposed address to this list and ensure there are no matches, or simply search the last 72 hours of the lattice to ensure no newly proposed addresses match.%0a
author:1669209251=
diff:1669209251:1669208940:=97c97%0a%3c We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacrum]] [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529#Examples|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a---%0a> We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacra]] [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529#Examples|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a
author:1669208940=
diff:1669208940:1669208904:=97c97%0a%3c We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacra]] [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529#Examples|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a---%0a> We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacra]] [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a
author:1669208904=
diff:1669208904:1669208783:=97c97%0a%3c We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacra]] [[https://en.wikipedia.org/wiki/Accumulator_%2528cryptography%2529|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a---%0a> We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacra]] [[https://en.wikipedia.org/wiki/Accumulator_(cryptography)|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a
author:1669208783=
diff:1669208783:1669208506:=97c97%0a%3c We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacra]] [[https://en.wikipedia.org/wiki/Accumulator_(cryptography)|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a---%0a> We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacra]] [[https://en.wikipedia.org/wiki/Accumulator_(cryptography)#Examples|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a
author:1669208506=
diff:1669208506:1669208486:=97c97%0a%3c We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation|simulacra]] [[https://en.wikipedia.org/wiki/Accumulator_(cryptography)#Examples|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a---%0a> We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation||simulacra]] [[https://en.wikipedia.org/wiki/Accumulator_(cryptography)#Examples|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a
author:1669208486=
diff:1669208486:1669208180:=97c97%0a%3c We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Simulacra_and_Simulation||simulacra]] [[https://en.wikipedia.org/wiki/Accumulator_(cryptography)#Examples|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a---%0a> We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] simulacra [[https://en.wikipedia.org/wiki/Accumulator_(cryptography)#Examples|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a
author:1669208180=
diff:1669208180:1669207357:=97c97%0a%3c We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] simulacra [[https://en.wikipedia.org/wiki/Accumulator_(cryptography)#Examples|accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a---%0a> We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Accumulator_(cryptography)#Examples| accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a
author:1669207357=
diff:1669207357:1669176337:=97c97%0a%3c We will use RSA (renamed [[https://www.reddit.com/r/math/comments/7v02i6/comparison_between_5000_and_50000_prime_numbers/|radial]] [[https://en.wikipedia.org/wiki/Accumulator_(cryptography)#Examples| accumulator]]) keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a---%0a> We will use RSA keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a
author:1669176337=
diff:1669176337:1669176217:=656c656%0a%3c #Fungibility: The main downside I can see so far is the value of certain bitlength cips will decrease over time (Edit: we actually do timestamp now, called [[#snaps|hashsnaps]]), perhaps at a rate of moore's law, so halving in value every 3 years, so basically the value will depreciate like a PC value does. I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  If we timestamped the transactions and increased the digit-length requirement of the [[#ntf|NTF]] by 5 every 2.6 years then 1 cip = 1 cip forever, but I tend to not want to make a rigid difficulty curve which would eventually break.  I would rather sacrifice value proposition for flexibility, so that the network can act as a sensor of koomey's law rather than a subject of it. Also I would rather not rely on arbitrary timestamps.%0a---%0a> #Fungibility: The main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years, so basically the value will depreciate like a PC value does. I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  If we timestamped the transactions and increased the digit-length requirement of the [[#ntf|NTF]] by 5 every 2.6 years then 1 cip = 1 cip forever, but I tend to not want to make a rigid difficulty curve which would eventually break.  I would rather sacrifice value proposition for flexibility, so that the network can act as a sensor of koomey's law rather than a subject of it. Also I would rather not rely on arbitrary timestamps.%0a
author:1669176217=
diff:1669176217:1669176004:=351,353c351%0a%3c Each cip will have a proof level (like 70 digit or 155 digit or whatever) and a hashsnap it was included in, which is basically a timestamp.  You can value them whatever you want to.  None of them will be perfectly identical, and people can design schemes to value them.  I am guessing that for example any 155 digit proof performed in the same year will likely have identical or similar value.%0a%3c %0a%3c A cip is a digital collectible, not a currency persay.  That said collectibles often are used like currencies, such as coins or even dollar bills.  Each coin or bill is unique.%0a---%0a> Each cip will have a proof level (like 70 digit or 155 digit or whatever) and a hashsnap it was included in, which is basically a timestamp.  You can value them whatever you want to.  None of them will be identical, and people can design schemes to value them.  I am guessing that for example any 155 digit proof performed in the same year will likely have identical or similar value.%0a
author:1669176004=
diff:1669176004:1669175808:=349,351d348%0a%3c !!!Value%0a%3c %0a%3c Each cip will have a proof level (like 70 digit or 155 digit or whatever) and a hashsnap it was included in, which is basically a timestamp.  You can value them whatever you want to.  None of them will be identical, and people can design schemes to value them.  I am guessing that for example any 155 digit proof performed in the same year will likely have identical or similar value.%0a
author:1669175808=
diff:1669175808:1669175314:=15c15%0a%3c Bitcoin was the rough draft.  Actionlattice is the fulfilment of the technology. Having a non-reusable address for each and every satoshi could not have been done in 2008, but now with software wallets using HD key generation, we can have nearly infinite addresses at our fingertips - making actionlattice a reality. %0a---%0a> Bitcoin was the rough draft.  Actionlattice is the fulfilment of the technology.%0a
author:1669175314=
diff:1669175314:1669175056:=101c101%0a%3c We considered merkle tree proofs, schnorr signatures, and moving address requirements, and moving address requirements was the only viable solution to this problem.  Newly proposed addresses (recipients of cips in transactions) must contain a specific suffix to be valid, and these acceptable suffixes will only be valid for 72 hours.  As long as they are the recipient of a transaction within that 72 hour window, they will be able to send forever,but can never receive again.  Nodes will either keep a list of all new addresses generated in the last 72 hours and compare each newly proposed address to this list and ensure there are no matches, or simply search the last 72 hours of the lattice to ensure no newly proposed addresses match.%0a---%0a> We considered merkle tree proofs, schnorr signatures, and moving address requirements, and moving address requirements was the only viable solution to this problem.  Nodes will either keep a list of all new addresses generated in the last 72 hours and compare each newly proposed address to this list and ensure there are no matches, or simply search the last 72 hours of the lattice to ensure no newly proposed addresses match.%0a
author:1669175056=
diff:1669175056:1669174518:=97c97%0a%3c We will use RSA keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.  Also the process of mining will generate large primes that can be used to make RSA addresses.%0a---%0a> We will use RSA keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.%0a
author:1669174518=
diff:1669174518:1669174431:=97c97%0a%3c We will use RSA keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe than ECDSA [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.  We cannot use schnorr signatures since they allow you to use hidden secrets in addresses which could be used to break our fungibility by secretly recycling old public keys.%0a---%0a> We will use RSA keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.%0a
author:1669174431=
diff:1669174431:1669174403:=95c95%0a%3c We will use [[https://en.wikipedia.org/wiki/Base64|base64]] address encoding since powers of 2 are best [[https://stackoverflow.com/questions/201479/what-is-base-64-encoding-used-for|#]].  Base58 was used in bitcoin to make addresses easily human recordable, but for actionlattice our addresses are not intended to be human usable since each piece of dust will have its own address so addresses will need a software wallet to manage.  That said it is not very difficult for a human to read/record base64.%0a---%0a> We will use [[https://en.wikipedia.org/wiki/Base64|base64]] since powers of 2 are best [[https://stackoverflow.com/questions/201479/what-is-base-64-encoding-used-for|#]].  Base58 was used in bitcoin to make addresses easily human recordable, but for actionlattice our addresses are not intended to be human usable since each piece of dust will have its own address so addresses will need a software wallet to manage.  That said it is not very difficult for a human to read/record base64.%0a
author:1669174403=
diff:1669174403:1669173431:=96,97d95%0a%3c %0a%3c We will use RSA keys since they are widely supported, use more basic math (which is important if society collapses), and are more quantum safe [[https://www.ssl.com/article/comparing-ecdsa-vs-rsa/|#]].  Also we will have a good guage on how safe our addresses are since our miners will be showing us what they can do with large number factorization, thus providing us an early warning sign.%0a
author:1669173431=
diff:1669173431:1669173241:=97,99c97%0a%3c We only want addresses to be used once and never reused. So to enforce this the most obvious way is to keep a database of all previously used addresses and their balance.  But this means keeping a large database of all the empty addresses forever which would get huge, or search through the entire actionlattice to see if an address is there, which would take way too much time. %0a%3c %0a%3c We considered merkle tree proofs, schnorr signatures, and moving address requirements, and moving address requirements was the only viable solution to this problem.  Nodes will either keep a list of all new addresses generated in the last 72 hours and compare each newly proposed address to this list and ensure there are no matches, or simply search the last 72 hours of the lattice to ensure no newly proposed addresses match.%0a---%0a> We only want addresses to be used once and never reused. So to enforce this the most obvious way is to keep a database of all previously used addresses and their balance.  But this means keeping a large database of all the empty addresses forever which would get huge, or search through the entire actionlattice to see if an address is there, which would take way too much time.%0a
author:1669173241=
diff:1669173241:1669173138:=95,96c95%0a%3c We will use [[https://en.wikipedia.org/wiki/Base64|base64]] since powers of 2 are best [[https://stackoverflow.com/questions/201479/what-is-base-64-encoding-used-for|#]].  Base58 was used in bitcoin to make addresses easily human recordable, but for actionlattice our addresses are not intended to be human usable since each piece of dust will have its own address so addresses will need a software wallet to manage.  That said it is not very difficult for a human to read/record base64.%0a%3c %0a---%0a> %0a97a97,98%0a> %0a> We will use [[https://en.wikipedia.org/wiki/Base64|base64]] since powers of 2 are best [[https://stackoverflow.com/questions/201479/what-is-base-64-encoding-used-for|#]].  Base58 was used in bitcoin to make addresses easily human recordable, but for actionlattice our addresses are not intended to be human usable since each piece of dust will have its own address so addresses will need a software wallet to manage.  That said it is not very difficult for a human to read/record base64. %0a
author:1669173138=
diff:1669173138:1669172278:=98,99c98,99%0a%3c We will use [[https://en.wikipedia.org/wiki/Base64|base64]] since powers of 2 are best [[https://stackoverflow.com/questions/201479/what-is-base-64-encoding-used-for|#]].  Base58 was used in bitcoin to make addresses easily human recordable, but for actionlattice our addresses are not intended to be human usable since each piece of dust will have its own address so addresses will need a software wallet to manage.  That said it is not very difficult for a human to read/record base64. %0a%3c %0a---%0a> We will use [[https://en.wikipedia.org/wiki/Base64|base64]] since powers of 2 are best [[https://stackoverflow.com/questions/201479/what-is-base-64-encoding-used-for|#]].  Base58 was used in bitcoin to make addresses easily human recordable, but for actionlattice our addresses are not intended to be human usable since each piece of dust will have its own address.  That said it is not very difficult for a human to read/record base64. %0a> %0a102,108c102,104%0a%3c We will have the last 4 digits of base64 addresses (suffix) determined by the trimmed hash of 3 daily hashshaps concatenated.  So you concatenate 3 daily hashsnaps ordered from oldest to newest, hash them together, and trim off all but the last 4 digits.  This gives about 17 million addresses to search to find one that has the correct last 4 digits.%0a%3c %0a%3c Each suffix is good for 72 hours for newly proposed addresses (even though a new suffix is generated daily).  This means the 3 hashsnaps you concatenate and hash are the three newest daily hashsnaps you are aware of, and if you are doing a long proof you may want to start your attempts as soon as the daily hashsnap is published. %0a%3c %0a%3c !!!!Explanation%0a%3c %0a%3c We could require that public key addresses have a new prefix or suffix every certain amount of time.  So addresses could be required to start with xdgh... For example.  Then a month from now they could be required to start with kdne...  These leading strings could be generated randomly via [[#snaps|hashsnaps]].  The problem with this is it would take a lot longer to generate addresses, which really shouldn't be too big of a deal because already vanity address generators exist that can do this.  The big problem is collisions, the algorithm could easily generate the same prefix twice so old addresses made with a certain prefix can be reused at a future date.  This could be fixed by making the prefix longer, but then address generation time also increases significantly.  %0a---%0a> We will have the last 4 digits of base64 addresses (suffix) determined by the trimmed hash of the last 3 daily hashshaps concatenated.  So you concatenate last 3 daily hashsnaps ordered from oldest to newest, hash them together, and trim off all but the last 4 digits.  This gives about 17 million addresses to search to find one that has the correct last 4 digits.%0a> %0a> We could require that public key addresses have a new starting string (prefix) every certain amount of time.  So addresses could be required to start with xdgh... For example.  Then a month from now they could be required to start with kdne...  These leading strings could be generated randomly via [[#snaps|hashsnaps]].  The problem with this is it would take a lot longer to generate addresses, which really shouldn't be too big of a deal because already vanity address generators exist that can do this.  The big problem is collisions, the algorithm could easily generate the same prefix twice so old addresses made with a certain prefix can be reused at a future date.  This could be fixed by making the prefix longer, but then address generation time also increases significantly.  %0a
author:1669172278=
diff:1669172278:1669171730:=102c102%0a%3c We will have the last 4 digits of base64 addresses (suffix) determined by the trimmed hash of the last 3 daily hashshaps concatenated.  So you concatenate last 3 daily hashsnaps ordered from oldest to newest, hash them together, and trim off all but the last 4 digits.  This gives about 17 million addresses to search to find one that has the correct last 4 digits.%0a---%0a> We will have the last 4 digits of base64 addresses (suffix) determined by the hash of the last 3 daily hashshaps concatenated.  This gives about 17 million addresses to search %0a
author:1669171730=
diff:1669171730:1669171439:=98,99c98,99%0a%3c We will use [[https://en.wikipedia.org/wiki/Base64|base64]] since powers of 2 are best [[https://stackoverflow.com/questions/201479/what-is-base-64-encoding-used-for|#]].  Base58 was used in bitcoin to make addresses easily human recordable, but for actionlattice our addresses are not intended to be human usable since each piece of dust will have its own address.  That said it is not very difficult for a human to read/record base64. %0a%3c %0a---%0a> We will use [[https://en.wikipedia.org/wiki/Base64|base64]] since powers of 2 are best [[https://stackoverflow.com/questions/201479/what-is-base-64-encoding-used-for|#]]%0a> %0a101,102d100%0a%3c %0a%3c We will have the last 4 digits of base64 addresses (suffix) determined by the hash of the last 3 daily hashshaps concatenated.  This gives about 17 million addresses to search %0a
author:1669171439=
diff:1669171439:1669170661:=97,98d96%0a%3c %0a%3c We will use [[https://en.wikipedia.org/wiki/Base64|base64]] since powers of 2 are best [[https://stackoverflow.com/questions/201479/what-is-base-64-encoding-used-for|#]]%0a
author:1669170661=
diff:1669170661:1669170300:=107,109c107,109%0a%3c Example: I created a [[https://www.smartscanner.cash/address/0x7eeeef82e6b1042dc809f4d6385198b315cfcdf6|  vanity address]] in several minutes I believe that had a prefix of 6 hexadecimal characters which is 16^6 attempts (16.8 million attempts).  If we reduced that to 5 characters it should take just a few seconds (1 million attempts), that would give us enough unique prefixes for about 2,800 years, which should be sufficient, and if we are still around we could increase the requirement to 6 digits at that time (or at any time really).%0a%3c %0a%3c A very fast cpu can do 1/2 million attempts per second, a bank of 8 fast gpu's can do 2.5 million attempts per second [[https://smith-mcf.medium.com/solana-vanity-address-using-gpus-5a68ad94d1d4|#]]%0a---%0a> Example: I created a [[https://www.smartscanner.cash/address/0x7eeeef82e6b1042dc809f4d6385198b315cfcdf6|  vanity address]] in several hours I believe that had a prefix of 6 hexadecimal characters.  If we reduced that to 5 characters it should take just a few moments, that would give us enough unique prefixes for about 2,800 years, which should be sufficient,and if we are still around we could increase the requirement to 6 digits at that time.%0a> %0a> A very fast cpu can do 1/2 million attempts per second, a bank of 8 fast gou's can do 2.5 million attempts per second [[https://smith-mcf.medium.com/solana-vanity-address-using-gpus-5a68ad94d1d4|#]]%0a
author:1669170300=
diff:1669170300:1669170101:=109c109%0a%3c A very fast cpu can do 1/2 million attempts per second, a bank of 8 fast gou's can do 2.5 million attempts per second [[https://smith-mcf.medium.com/solana-vanity-address-using-gpus-5a68ad94d1d4|#]]%0a---%0a> A very fast cou can do 1/2 million attempts per second [[https://smith-mcf.medium.com/solana-vanity-address-using-gpus-5a68ad94d1d4|#]]%0a
author:1669170101=
diff:1669170101:1669169393:=108,109d107%0a%3c %0a%3c A very fast cou can do 1/2 million attempts per second [[https://smith-mcf.medium.com/solana-vanity-address-using-gpus-5a68ad94d1d4|#]]%0a
author:1669169393=
diff:1669169393:1669168686:=106,107d105%0a%3c %0a%3c Example: I created a [[https://www.smartscanner.cash/address/0x7eeeef82e6b1042dc809f4d6385198b315cfcdf6|  vanity address]] in several hours I believe that had a prefix of 6 hexadecimal characters.  If we reduced that to 5 characters it should take just a few moments, that would give us enough unique prefixes for about 2,800 years, which should be sufficient,and if we are still around we could increase the requirement to 6 digits at that time.%0a
author:1669168686=
diff:1669168686:1669168540:=104c104%0a%3c Can we tolerate address reuse that is limited to very long time periods apart?  Is this good enough to really disincentive address reuse?  It might be, especially if we can combine it with another technique. Another thing we could do is keep a list of all prefixes and what hashsnaps they correspond to so if we do get a repeat it could be rehashed.  But then we are stick with maintaining a list of all prefixes, which certainly is a much smaller dataset then all addresses ever used... The problem with that though is you would eventially run out of prefixes.  Lets say the addresses were numbers and the first 4 digits are the prefix.  That means 10*10*10*10 prefixes would be possible which would only last 10,000 days before all were used, which is about 30 years.%0a---%0a> Can we tolerate address reuse that is limited to very long time periods apart?  Is this good enough to really disincentive address reuse?  It might be, especially if we can combine it with another technique. Another thing we could do is keep a list of all prefixes and what hashsnaps they correspond to so if we do get a repeat it could be rehashed.  But then we are stick with maintaining a list of all prefixes, which certainly is a much smaller dataset then all addresses ever used...%0a
author:1669168540=
diff:1669168540:1669168415:=104c104%0a%3c Can we tolerate address reuse that is limited to very long time periods apart?  Is this good enough to really disincentive address reuse?  It might be, especially if we can combine it with another technique. Another thing we could do is keep a list of all prefixes and what hashsnaps they correspond to so if we do get a repeat it could be rehashed.  But then we are stick with maintaining a list of all prefixes, which certainly is a much smaller dataset then all addresses ever used...%0a---%0a> Can we tolerate address reuse that is limited to very long time periods apart?  Is this good enough to really disincentive address reuse?  It might be, especially if we can combine it with another technique.%0a
author:1669168415=
diff:1669168415:1669167959:=100,104c100%0a%3c We could require that public key addresses have a new starting string (prefix) every certain amount of time.  So addresses could be required to start with xdgh... For example.  Then a month from now they could be required to start with kdne...  These leading strings could be generated randomly via [[#snaps|hashsnaps]].  The problem with this is it would take a lot longer to generate addresses, which really shouldn't be too big of a deal because already vanity address generators exist that can do this.  The big problem is collisions, the algorithm could easily generate the same prefix twice so old addresses made with a certain prefix can be reused at a future date.  This could be fixed by making the prefix longer, but then address generation time also increases significantly.  %0a%3c %0a%3c To implement this we would need to specify how often the address prefix changes.  Lets say its daily.  Then to test transaction validity nodes would only need to scan back a day to make sure that address wasn't used before.%0a%3c %0a%3c Can we tolerate address reuse that is limited to very long time periods apart?  Is this good enough to really disincentive address reuse?  It might be, especially if we can combine it with another technique.%0a---%0a> We could require that public key addresses have a new starting string every certain amount of time.  So addresses could be required to start with xdgh... For example.  Then a month from now they could be required to start with kdne...  These leading strings could be generated randomly via [[#snaps|hashsnaps]].  The problem with this is %0a
author:1669167959=
diff:1669167959:1669167741:=97,100d96%0a%3c %0a%3c !!!Moving address requirements%0a%3c %0a%3c We could require that public key addresses have a new starting string every certain amount of time.  So addresses could be required to start with xdgh... For example.  Then a month from now they could be required to start with kdne...  These leading strings could be generated randomly via [[#snaps|hashsnaps]].  The problem with this is %0a
author:1669167741=
diff:1669167741:1669167561:=97,102d96%0a%3c %0a%3c !!!Merkle tree%0a%3c %0a%3c Merkle tree cannot help us create a public key that is provably new because you can't sign for the high level hash.%0a%3c %0a%3c !!!!Notes (deprecated)%0a
author:1669167561=
diff:1669167561:1669165819:=101,104d100%0a%3c %0a%3c Schnorr signatures should not be allowed because they can make fake public keys that can be signed for with old private keys.  We want only new keys to be allowed with no fakes.%0a%3c %0a%3c !!!!Notes (deprecated)%0a
author:1669165819=
diff:1669165819:1669165160:=102c102%0a%3c Schnorr signatures might allow timestamping keys [[https://youtu.be/XKatSGCZ-gE?t=563|#]] 'pay to contract' allows to embed and old public key with data to make a new public key that can be signed with the old private key.  This is good to make cips linkable to a user but unlinkable for external observers of the lattice.  However by revealing the old public key then cips could be linked.  Optional privacy doesn't really work because it ruins fungibility for everyone when someone chooses to reveal a link on chain.%0a---%0a> Schnorr signatures might allow timestamping keys [[https://youtu.be/XKatSGCZ-gE?t=563|#]]%0a
author:1669165160=
diff:1669165160:1669157746:=102c102%0a%3c Schnorr signatures might allow timestamping keys [[https://youtu.be/XKatSGCZ-gE?t=563|#]]%0a---%0a> Schnorr signatures might allow timestamping keys [[https://www.youtube.com/watch?v=XKatSGCZ-gE|#]]%0a
author:1669157746=
diff:1669157746:1669156739:=100,101d99%0a%3c !!!Schnorr%0a%3c %0a111,112d108%0a%3c %0a%3c Signatures are 64 bytes and public keys are 32 bytes [[https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki#Motivation|#]]%0a
author:1669156739=
diff:1669156739:1669156384:=105,108d104%0a%3c %0a%3c Bitcoin wiki on schnorr [[https://en.bitcoin.it/wiki/Schnorr|#]]%0a%3c %0a%3c Bip340 [[https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki|#]]%0a
author:1669156384=
diff:1669156384:1669141955:=103,104d102%0a%3c %0a%3c Good explanation of how exactly signatures work including schnorr [[https://medium.com/bitbees/what-the-heck-is-schnorr-52ef5dba289f|#]]%0a
author:1669141955=
diff:1669141955:1669140173:=101,102d100%0a%3c %0a%3c Schnorr signature lecture [[https://crypto.stanford.edu/cs355/19sp/lec5.pdf|#]]%0a
author:1669140173=
diff:1669140173:1669135160:=98c98,102%0a%3c Merkle tree proofs should work to allow addresses to be generated using a recent Hashsnap so that we know an address is newly generated that you are sending a cip to [[https://www.reddit.com/r/cryptography/comments/z1hvc5/comment/ixb4qjj/?utm_source=share&utm_medium=web2x&context=3|#]] [[https://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5|#]] You would take the most recent daily hashsnap and hash it with a brand new public key (that you have the private key for).  Now you have a new cip address that did not exist before. In reality it proves the address is new but it does not prove the public key is new so this does not work for us.%0a---%0a> Merkle tree proofs should work to allow addresses to be generated using a recent Hashsnap so that we know an address is newly generated that you are sending a cip to [[https://www.reddit.com/r/cryptography/comments/z1hvc5/comment/ixb4qjj/?utm_source=share&utm_medium=web2x&context=3|#]] [[https://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5|#]], in reality it proves the address is new but it does not prove the public key is new so this does not work for us.%0a> %0a> Here is how it would work.  You take the most recent daily hashsnap and hash it with a brand new public key (that you have the private key for).  Now you have a new cip address that did not exist before.%0a> %0a> The problem is that how do we know that public key hasn't been used before?  We are back to square one.%0a
author:1669135160=
diff:1669135160:1669134918:=98,99c98,99%0a%3c Merkle tree proofs should work to allow addresses to be generated using a recent Hashsnap so that we know an address is newly generated that you are sending a cip to [[https://www.reddit.com/r/cryptography/comments/z1hvc5/comment/ixb4qjj/?utm_source=share&utm_medium=web2x&context=3|#]] [[https://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5|#]], in reality it proves the address is new but it does not prove the public key is new so this does not work for us.%0a%3c %0a---%0a> Merkle tree proofs should work to allow addresses to be generated using a recent Hashsnap so that we know an address is newly generated that you are sending a cip to [[https://www.reddit.com/r/cryptography/comments/z1hvc5/comment/ixb4qjj/?utm_source=share&utm_medium=web2x&context=3|#]] [[https://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5|#]]%0a> %0a102c102%0a%3c The problem is that how do we know that public key hasn't been used before?  We are back to square one.%0a---%0a> The problem is that how do we know that public key hasn't been used before?  Perhaps we embrace this and modify our algorithm in [[#linking|linking]] cips.%0a
author:1669134918=
diff:1669134918:1669134867:=94,95c94,95%0a%3c !!Address generation [[#address]]%0a%3c %0a---%0a> !!!Address generation [[#address]]%0a> %0a102a103,104%0a> %0a> !!!Address generation%0a
author:1669134867=
diff:1669134867:1669090998:=104,106c104,107%0a%3c !!!Address generation%0a%3c %0a%3c Schnorr signatures might allow timestamping keys [[https://www.youtube.com/watch?v=XKatSGCZ-gE|#]]%0a---%0a> !!!Linking cips to main account [[#linking]]%0a> %0a> First of all I want to be very clear that cips must be unlinkable to an observer.  However with our [[#address|address generation]] method it is possible to privately link cips to a main account.%0a> %0a
author:1669090998=
diff:1669090998:1669090973:=104c104%0a%3c !!!Linking cips to main account [[#linking]]%0a---%0a> !!!Linking cips to main account%0a
author:1669090973=
diff:1669090973:1669087245:=94,95c94,95%0a%3c !!!Address generation [[#address]]%0a%3c %0a---%0a> !!!Address generation%0a> %0a99,106d98%0a%3c %0a%3c Here is how it would work.  You take the most recent daily hashsnap and hash it with a brand new public key (that you have the private key for).  Now you have a new cip address that did not exist before.%0a%3c %0a%3c The problem is that how do we know that public key hasn't been used before?  Perhaps we embrace this and modify our algorithm in [[#linking|linking]] cips.%0a%3c %0a%3c !!!Linking cips to main account%0a%3c %0a%3c First of all I want to be very clear that cips must be unlinkable to an observer.  However with our [[#address|address generation]] method it is possible to privately link cips to a main account.%0a
author:1669087245=
diff:1669087245:1669087124:=96c96%0a%3c We only want addresses to be used once and never reused. So to enforce this the most obvious way is to keep a database of all previously used addresses and their balance.  But this means keeping a large database of all the empty addresses forever which would get huge, or search through the entire actionlattice to see if an address is there, which would take way too much time.%0a---%0a> We only want addresses to be used once and never reused. So to enforce this the most obvious way is to keep a database of all previoously used addresses and thier balance.  But this means keeping a large database of all empty addresses forever which would get huge.%0a
author:1669087124=
diff:1669087124:1669086932:=93,98d92%0a%3c %0a%3c !!!Address generation%0a%3c %0a%3c We only want addresses to be used once and never reused. So to enforce this the most obvious way is to keep a database of all previoously used addresses and thier balance.  But this means keeping a large database of all empty addresses forever which would get huge.%0a%3c %0a%3c Merkle tree proofs should work to allow addresses to be generated using a recent Hashsnap so that we know an address is newly generated that you are sending a cip to [[https://www.reddit.com/r/cryptography/comments/z1hvc5/comment/ixb4qjj/?utm_source=share&utm_medium=web2x&context=3|#]] [[https://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5|#]]%0a
author:1669086932=
diff:1669086932:1669083209:=662c662%0a%3c If possible prove that every address is randomly generated so you can never send to the same address twice. merkle tree proofs should work [[https://www.reddit.com/r/cryptography/comments/z1hvc5/comment/ixb4qjj/?utm_source=share&utm_medium=web2x&context=3|#]] [[https://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5|#]]%0a---%0a> If possible prove that every address is randomly generated so you can never send to the same address twice.%0a
author:1669083209=
diff:1669083209:1669079694:=663,664d662%0a%3c %0a%3c Understanding encryption and signatures [[https://security.stackexchange.com/questions/68822/trying-to-understand-rsa-and-its-terminology/68836#68836|#]]%0a
author:1669079694=
diff:1669079694:1668964137:=661,662d660%0a%3c %0a%3c If possible prove that every address is randomly generated so you can never send to the same address twice.%0a
author:1668964137=
diff:1668964137:1668958136:=115,116d114%0a%3c %0a%3c Nano has representative staked node voting [[https://youtu.be/IDEQE8lmaqs|#]]%0a
author:1668958136=
diff:1668958136:1668958103:=176c176%0a%3c This is initial levels, as each bitlevel within each of these groups can hold double the last. For example a 55 digit [[#ntf|NTF]] can hold 64 bytes of transaction data, whereas a 60 digit number can hold 128 bytes. Each new bitlevel doubles the size allowed of the former and every 6 bitlevels (bepoch) it goes up 64x.  The numbers to factor to achieve these storage capacities will go up by 5 digits every 2 years, butthe amount of storage space allowed will not go up without a vote.  For example right now factoring a 145 digit number allows you to store 17 mb, in 2 years that would require factoring a 150 digit number to store the same 17 mb.%0a---%0a> This is initial levels, as each bitlevel within each of these groups can hold double the last. For example a 55 digit [[#ntf|NTF]] can hold 64 bytes of transaction data, whereas a 60 digit number can hold 128 bytes. Each new bitlevel doubles the size allowed of the former and every 6 bitlevels (bepoch) it goes up 64x.  The numbers to factor to achieve these storage capacities will go up by 5 digits every 2 years, butthe amount of storage space allowed will not go up without a vote.  For example right now factoring a 140 digit number allows you to store 17 mb, in 2 years that would require factoring a 145 digit number to store the same 17 mb.%0a
author:1668958103=
diff:1668958103:1668957779:=176c176%0a%3c This is initial levels, as each bitlevel within each of these groups can hold double the last. For example a 55 digit [[#ntf|NTF]] can hold 64 bytes of transaction data, whereas a 60 digit number can hold 128 bytes. Each new bitlevel doubles the size allowed of the former and every 6 bitlevels (bepoch) it goes up 64x.  The numbers to factor to achieve these storage capacities will go up by 5 digits every 2 years, butthe amount of storage space allowed will not go up without a vote.  For example right now factoring a 140 digit number allows you to store 17 mb, in 2 years that would require factoring a 145 digit number to store the same 17 mb.%0a---%0a> This is initial levels, as each bitlevel within each of these groups can hold double the last. For example a 55 digit [[#ntf|NTF]] can hold 64 bytes of transaction data, whereas a 60 digit number can hold 128 bytes. Each new bitlevel doubles the size allowed of the former and every 6 bitlevels (bepoch) it goes up 64x%0a
author:1668957779=
diff:1668957779:1668957509:=176c176%0a%3c This is initial levels, as each bitlevel within each of these groups can hold double the last. For example a 55 digit [[#ntf|NTF]] can hold 64 bytes of transaction data, whereas a 60 digit number can hold 128 bytes. Each new bitlevel doubles the size allowed of the former and every 6 bitlevels (bepoch) it goes up 64x%0a---%0a> This is starting levels, as each bitlevel is retired and replaced so is this. Each new bitlevel doubles the size allowed of the former and every 6 bitlevels (bepoch) it goes up 64x%0a
author:1668957509=
diff:1668957509:1668957480:=262c262%0a%3c The digitlength for each level goes up one rung every 2 years to compensate for moore's law, however the [[#datasize|datasize limit]] does not - without a vote.  The vote can be held every 7 years or something.%0a---%0a> The digitlength for each level goes up one rung every 2 years to compensate for moore's law, however the [[#data|datasize limit]] does not - without a vote.  The vote can be held every 7 years or something.%0a
author:1668957480=
diff:1668957480:1668957459:=300,302d299%0a%3c %0a%3c See also [[#datasize|datasize]]%0a%3c %0a
author:1668957459=
diff:1668957459:1668957439:=172c172%0a%3c !!!Data standard bitlevels [[#datasize]]%0a---%0a> !!!Data standard bitlevels [[#datastandards]]%0a
author:1668957439=
diff:1668957439:1668957356:=172,174c172%0a%3c !!!Data standard bitlevels [[#datastandards]]%0a%3c %0a%3c See also [[#data|data]]%0a---%0a> !!!Data standard bitlevels%0a
author:1668957356=
diff:1668957356:1668956965:=260c260%0a%3c The digitlength for each level goes up one rung every 2 years to compensate for moore's law, however the [[#data|datasize limit]] does not - without a vote.  The vote can be held every 7 years or something.%0a---%0a> The digitlength for each level goes up one rung every 2 years to compensate for moore's law, however the datasize limit does not - without a vote.  The vote can be held every 7 years or something.%0a
author:1668956965=
diff:1668956965:1668956890:=477a478,483%0a> %0a> %0a> %0a> %0a> %0a> %0a483,484d488%0a%3c %0a%3c !!Price [[#price]]%0a
author:1668956890=
diff:1668956890:1668956167:=331,332d330%0a%3c %0a%3c There should also be weight based on how new the peer transactions are (the transactions your transaction is connecting to) in order to incentivize people to stay on the chain-tip as much as possible adding confirmations to new transactions instead of old ones.  Perhaps a compounding 5%25 reduction for every extra day old the oldest peer transaction is that you are connecting to.  So confirming a 1 day old transaction would yield you 95%25 of the reward, a 2 day old transaction would be 95%25*95%25=90.25%25 reward, 3 day old would be 85.74%25 etc.  This also creates a [[#price|price stabilization]] effect because if transactions slow down to a crawl and there are only a few transactions per month, reward for transactions would be smaller due to this factor  and thus emission reduces so price can trend upwards.%0a
author:1668956167=
diff:1668956167:1668955590:=135,136c135,136%0a%3c #Proof of Proven Sieve ([[#props|Props]]) - Completed transaction signature (CTS), number to factor (NTF), two equal digit-length factors, and nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, hashsnaps, Miners message, and then hashed to create the new NTF).%0a%3c %0a---%0a> #Proof of Proven Sieve ([[#props|Props]]) - Completed transaction signature (CTS), number to factor (NTF), two equal digit-length factors, and nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, Miners message, and then hashed to create the new NTF).%0a> %0a139,141c139,141%0a%3c **Peer blocks - 3 peer blocks NTFs (PNTFs, pronounced 'pontiffs') within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These three NTFs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a%3c %0a%3c **Latest [[#snaps|Hashsnaps]] of each of the five levels, which acts as a vote for the correct network snapshots.  These votes are not needed for nodes to select the fully valid hashsnaps with the most weight, but it should help clear up any supposed discrepancies.  Doing this will also act as a pretty accurate timestamp for the transactions it links to (but not necessarily for itself, as it could have taken days to factor the NTF).%0a---%0a> **Peer blocks - 3 peer blocks NTFs (PNTFs, pronounced 'pontiffs') within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These two NTFs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a> %0a> **Latest [[#snaps|Hashsnaps]] of each of the five levels, which acts as a vote for the correct network snapshots.  These votes are not needed for nodes to select the fully valid hashsnaps with the most weight, but it should help clear up any supposed discrepancies.  Doing this will also act as a pretty accurate timestamp for the transaction.%0a
author:1668955590=
diff:1668955590:1668955268:=140,141d139%0a%3c %0a%3c **Latest [[#snaps|Hashsnaps]] of each of the five levels, which acts as a vote for the correct network snapshots.  These votes are not needed for nodes to select the fully valid hashsnaps with the most weight, but it should help clear up any supposed discrepancies.  Doing this will also act as a pretty accurate timestamp for the transaction.%0a
author:1668955268=
diff:1668955268:1668954910:=55c55%0a%3c !!!Hashsnaps (snaps/snapshots/epochs) [[#snaps]]%0a---%0a> !!!Hashsnaps (snapshots/epochs)%0a
author:1668954910=
diff:1668954910:1668954849:=56,57d55%0a%3c %0a%3c This is similar to [[NatureVault/transep]], which is the 1D blockchain equivalent.%0a
author:1668954849=
diff:1668954849:1668954794:=13c13%0a%3c See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]], [[NatureVault/Solvum]], [[NatureVault/Quantum]], [[Dustyplasma]], [[NatureVault/transep]]%0a---%0a> See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]], [[NatureVault/Solvum]], [[NatureVault/Quantum]], [[Dustyplasma]], [[transep]]%0a
author:1668954794=
diff:1668954794:1668954676:=13c13%0a%3c See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]], [[NatureVault/Solvum]], [[NatureVault/Quantum]], [[Dustyplasma]], [[transep]]%0a---%0a> See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]], [[NatureVault/Solvum]], [[NatureVault/Quantum]], [[Dustyplasma]]%0a
author:1668954676=
diff:1668954676:1668954601:=57c57%0a%3c Every certain amount of time the actionlattice should be hashed.  This should be done so that nodes can ping other nodes and by just comparing one number, they can see if their actionlattice is identical.  If the hashsnaps don't match, then the nodes can reconcile what is different.  The hashsnaps with the most voting weight are the accepted hashsnaps.  The reason there are 5 levels is that nodes can tell if they are correct with more granularity and can compensate and contest other hashsnaps faster.  For example if it was done every hour, if lots of nodes have different hourly hashsnaps, then they would have a lot of transactions to compare.  If there is a discrepancy at 7 second hashsnaps, they can compare a much smaller amount of transactions to see which lattice has a higher weight and accept that.%0a---%0a> every certain amount of time the actionlattice should be hashed.  This should be done so that nodes can ping other nodes and by just comparing one number, they can see if their actionlattice is identical.  If the hashsnaps don't match, then the nodes can reconcile what is different.  The hashsnaps with the most voting weight are the accepted hashsnaps.  The reason there are 5 levels is that nodes can tell if they are correct with more granularity and can compensate and contest other hashsnaps faster.  For example if it was done every hour, if lots of nodes have different hourly hashsnaps, then they would have a lot of transactions to compare.  If there is a discrepancy at 7 second hashsnaps, they can compare a much smaller amount of transactions to see which lattice has a higher weight and accept that.%0a
author:1668954601=
diff:1668954601:1668954507:=430c430%0a%3c [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. When we graph the total voting weight on the actionlattice with respect to digitlength, we should see a reasonably flat, smooth, bell curve with its maximum centered around the [[#time|72 hour mark]] (currently around 146-147 digitlength) and incentives (voting weight) should be tuned to achieve this bell curve.**%0a---%0a> [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. When we graph the total voting weight on the actionlattice with respect to digitlength, we should see a reasonably flat, smooth, bell curve centered around the [[#time|72 hour mark]] (currently around 146-147 digitlength) and incentives (voting weight) should be tuned to achieve this bell curve.**%0a
author:1668954507=
diff:1668954507:1668954251:=253,254d252%0a%3c %0a%3c Targeting the [[#weightconstant|72 hour mark (and higher)]] is ideal as it pretty safely sets CPU as the fastest hardware (while also benefitting from an auxillary GPU) and also it makes you wait 3 days before sending the payment, which waiting 3 days to think about making a purchase helps one weed out unnecessary spending.%0a
author:1668954251=
diff:1668954251:1668954089:=428c428%0a%3c [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. When we graph the total voting weight on the actionlattice with respect to digitlength, we should see a reasonably flat, smooth, bell curve centered around the [[#time|72 hour mark]] (currently around 146-147 digitlength) and incentives (voting weight) should be tuned to achieve this bell curve.**%0a---%0a> [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. When we graph the total voting weight on the actionlattice with respect to digitlength, we should see a reasonably flat, smooth, bell curve centered around the [[#time|72 hour mark]] and incentives (voting weight) should be tuned to achieve this bell curve.**%0a
author:1668954089=
diff:1668954089:1668954058:=428c428%0a%3c [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. When we graph the total voting weight on the actionlattice with respect to digitlength, we should see a reasonably flat, smooth, bell curve centered around the [[#time|72 hour mark]] and incentives (voting weight) should be tuned to achieve this bell curve.**%0a---%0a> [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. When we graph the total voting weight on the actionlattice with respect to digitlength, we should see a reasonably flat, smooth, bell curve centered around the [[#time|48 hour mark]] and incentives (voting weight) should be tuned to achieve this bell curve.**%0a
author:1668954058=
diff:1668954058:1668953930:=428c428%0a%3c [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. When we graph the total voting weight on the actionlattice with respect to digitlength, we should see a reasonably flat, smooth, bell curve centered around the [[#time|48 hour mark]] and incentives (voting weight) should be tuned to achieve this bell curve.**%0a---%0a> [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. When we graph the total voting weight on the actionlattice with respect to digitlength, we should see a reasonably flat, smooth, bell curve centered around the 48 hour mark and incentives (voting weight) should be tuned to achieve this bell curve.**%0a
author:1668953930=
diff:1668953930:1668953905:=424c424%0a%3c !!!!Final equation [[#weightconstant]]%0a---%0a> !!!!Final equation%0a
author:1668953905=
diff:1668953905:1668953846:=324c324%0a%3c GPU ECM is 10x faster than CPU, which is compensated by the [[#weightconstant|weighting constant]].%0a---%0a> GPU ECM is 10x faster than CPU%0a
author:1668953846=
diff:1668953846:1668953738:=326,327c326,327%0a%3c !!!Weighting function%0a%3c %0a---%0a> !!!Weighing function%0a> %0a330c330%0a%3c Voting weight = y%0a---%0a> weight = y%0a
author:1668953738=
diff:1668953738:1668953623:=375,376d374%0a%3c %0a%3c This shows for ever ~17 digitlength increase, we have 10x the voting weight.%0a
author:1668953623=
diff:1668953623:1668953497:=426c426%0a%3c [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. When we graph the total voting weight on the actionlattice with respect to digitlength, we should see a reasonably flat, smooth, bell curve centered around the 48 hour mark and incentives (voting weight) should be tuned to achieve this bell curve.**%0a---%0a> [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. We should see a reasonably flat, smooth, bell curve centered around the 48 hour mark and incentives (voting weight) should be tuned to achieve this bell curve.**%0a
author:1668953497=
diff:1668953497:1668953255:=401,404d400%0a%3c %0a%3c 72 digitlength%0a%3c %0a%3c y = (2^(72/5))/2048 => 10.6%0a
author:1668953255=
diff:1668953255:1668953227:=420c420%0a%3c For the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits [[#test|(*)]], which is about 10x extra voting weight for every additional 50 digits, so using CPU's to factor larger numbers would be a better option [[#test|(*)]] than using GPU's for lots of small numbers.%0a---%0a> for the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits [[#test|(*)]], which is about 10x extra voting weight for every additional 50 digits, so using CPU's to factor larger numbers would be a better option [[#test|(*)]] than using GPU's for lots of small numbers.%0a
author:1668953227=
diff:1668953227:1668953114:=420c420%0a%3c for the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits [[#test|(*)]], which is about 10x extra voting weight for every additional 50 digits, so using CPU's to factor larger numbers would be a better option [[#test|(*)]] than using GPU's for lots of small numbers.%0a---%0a> for the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits [[#test|(*)]], so using CPU's to factor larger numbers would be a better option than using GPU's for lots of small numbers.%0a
author:1668953114=
diff:1668953114:1668953004:=455,458d454%0a%3c %0a%3c 105 digitlength%0a%3c %0a%3c y = (2^(105/15)/(12.7))*((2^(105/5))/2048) = 10321%0a
author:1668953004=
diff:1668953004:1668952863:=409,412d408%0a%3c %0a%3c 105 digitlength%0a%3c %0a%3c y = (2^(105/5))/2048 => 1024%0a
author:1668952863=
diff:1668952863:1668952813:=416,417d415%0a%3c for the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits [[#test|(*)]], so using CPU's to factor larger numbers would be a better option than using GPU's for lots of small numbers.%0a%3c %0a418a417,418%0a> %0a> for the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits [[#test|(*)]], so using CPU's to factor larger numbers would be a better option than using GPU's for lots of small numbers.%0a
author:1668952813=
diff:1668952813:1668952659:=416,418c416,418%0a%3c [[#test]](*)**This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. We should see a reasonably flat, smooth, bell curve centered around the 48 hour mark and incentives (voting weight) should be tuned to achieve this bell curve.**%0a%3c %0a%3c for the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits [[#test|(*)]], so using CPU's to factor larger numbers would be a better option than using GPU's for lots of small numbers.%0a---%0a> **This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. We should see a reasonably flat, smooth, bell curve centered around the 48 hour mark and incentives (voting weight) should be tuned to achieve this bell curve.**%0a> %0a> for the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits, so using CPU's to factor larger numbers would be a better option than using GPU's for lots of small numbers.%0a
author:1668952659=
diff:1668952659:1668952309:=364,365c364,365%0a%3c Now we want to normalize based on the current smallest accepted digitlength.%0a%3c %0a---%0a> now we want to normalize based on the current smallest accepted digitlength.%0a> %0a369,370d368%0a%3c %0a%3c Relative voting weight = (2^(digitlength/5))/(2^(mindigitlength/5))%0a
author:1668952309=
diff:1668952309:1668922430:=414c414%0a%3c **This is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest. We should see a reasonably flat, smooth, bell curve centered around the 48 hour mark and incentives (voting weight) should be tuned to achieve this bell curve.**%0a---%0a> (*)this is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest.%0a
author:1668922430=
diff:1668922430:1668921566:=61c61%0a%3c For every number of seconds shown below (epoch), a node would broadcast the hash of the last hashsnap hashed with all the current transaction hashes XOR'd together so that the order the transactions are in doesn't matter [[https://stackoverflow.com/questions/19342846/is-there-a-c-sharp-method-of-hash-generation-where-the-order-of-the-values-doesn|#]] [[https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes|#]] (or even just adding all the hash values up! [[https://stackoverflow.com/questions/30734848/order-independent-hash-algorithm|#]]).  Obviously if there were double spending (duplicates) the later one(s) each node would just delete on their own.%0a---%0a> For every number of seconds shown below (epoch), a node would broadcast the hash of the last hashsnap hashed with all the current transaction hashes XOR'd together so that the order the transactions are in doesn't matter [[https://stackoverflow.com/questions/19342846/is-there-a-c-sharp-method-of-hash-generation-where-the-order-of-the-values-doesn|#]] [[https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes|#]].  Obviously if there were double spending (duplicates) the later one(s) each node would just delete on their own.%0a
author:1668921566=
diff:1668921566:1668921387:=10c10%0a%3c (:Archive:[[ https://archive.ph/R5sla |Archive.is]], [[ https://web.archive.org/web/20221001154854/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice |Archive.org]],  [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|OLDArchive.org]]:)%0a---%0a> (:Archive:[[ https://archive.ph/GWJ7Y |Archive.is]], [[ https://web.archive.org/web/20221001154854/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice |Archive.org]],  [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|OLDArchive.org]]:)%0a
author:1668921387=
diff:1668921387:1668921353:=61c61%0a%3c For every number of seconds shown below (epoch), a node would broadcast the hash of the last hashsnap hashed with all the current transaction hashes XOR'd together so that the order the transactions are in doesn't matter [[https://stackoverflow.com/questions/19342846/is-there-a-c-sharp-method-of-hash-generation-where-the-order-of-the-values-doesn|#]] [[https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes|#]].  Obviously if there were double spending (duplicates) the later one(s) each node would just delete on their own.%0a---%0a> For every number of seconds shown below (epoch), a node would broadcast the hash of the last hashsnap hashed with all the current transactions hash XOR'd together so that the order the transactions are in doesn't matter [[https://stackoverflow.com/questions/19342846/is-there-a-c-sharp-method-of-hash-generation-where-the-order-of-the-values-doesn|#]] [[https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes|#]].  Obviously if there were double spending (duplicates) the later one(s) each node would just delete on their own.%0a
author:1668921353=
diff:1668921353:1668921284:=61c61%0a%3c For every number of seconds shown below (epoch), a node would broadcast the hash of the last hashsnap hashed with all the current transactions hash XOR'd together so that the order the transactions are in doesn't matter [[https://stackoverflow.com/questions/19342846/is-there-a-c-sharp-method-of-hash-generation-where-the-order-of-the-values-doesn|#]] [[https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes|#]].  Obviously if there were double spending (duplicates) the later one(s) each node would just delete on their own.%0a---%0a> For every number of seconds shown below (epoch), a node would broadcast the hash of the last hashsnap hashed with all the current transactions hash XOR'd together so that the order the transactions are in doesn't matter [[https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes|#]].  Obviously if there were double spending (duplicates) the later one(s) each node would just delete on their own.%0a
author:1668921284=
diff:1668921284:1668921247:=94c94%0a%3c !!!Nano (blocklattice)[[#nano]]%0a---%0a> !!!Nano [[#nano]]%0a
author:1668921247=
diff:1668921247:1668921169:=110c110%0a%3c In Nano they achieve double spending protection by each address having it's own blockchain.  In actionlattice there is a global "blockchain" and we achieve double spending protection by having each address only able to hold 1 bit and once it is sent the address can no longer be used (destroyed), and nodes simply reject the latter duplicate transaction(s).%0a---%0a> In Nano they achieve double spending protection by each address having it's own blockchain.  In actionlattice there is a global "blockchain" and we achieve double spending protection by having each address only able to hold 1 bit and once it is sent the address can no longer be used (destroyed).%0a
author:1668921169=
diff:1668921169:1668921134:=106c106%0a%3c In nano both parties have to sign for a transaction.  Actionlattice only the sender has to sign, just like standard blockchain. This is important because signing gives up security. Actionlattice goes above standard Blockchain security and ensures an address "breaks" after it signs and cannot be reused in order to preserve 100%25 maximum security.%0a---%0a> In nano both parties have to sign for a transaction.  Actionlattice only the sender has to sign, just kike standard blockchain. This is important because signing gives up security. Actionlattice goes above standard Blockchain security and ensures an address "breaks" after it signs and cannot be reused in order to preserve 100%25 maximum security.%0a
author:1668921134=
diff:1668921134:1668921108:=67c67%0a%3c L1H's and L2H's are not multiples of eachother to prevent nodes from having to calculate both at the same time, which would be difficult for nodes.%0a---%0a> L1H's and L2H's are not multiples of eachother to prevent nodes from having to calculate both at the same time.%0a
author:1668921108=
diff:1668921108:1668920773:=64,67d63%0a%3c %0a%3c Epoch's should be 1 behind.  So lets say we are currently sitting in epoch L1E2 right now, at the end of L1E2 your node should publish L1E1. This is because discrepancies can be fixed by each node so that consensus isn't constantly lagging.  Hashsnaps from the current epoch could be published, but more as a preliminary comparison, and 1 epoch behind is binding in the sense that the highest weighted actionlattice is the "winner" and shall be accepted by all the nodes.%0a%3c %0a%3c L1H's and L2H's are not multiples of eachother to prevent nodes from having to calculate both at the same time.%0a
author:1668920773=
diff:1668920773:1668920749:=63c63%0a%3c Each Level of epoch uses the hash of the last epoch plus all the hashes of the transactions in the current epoch.  So L1H's would only be concerned with previous L1H's, whereas L4H's would only use the hashsnap of the last L4H, and all the transactions since.  They do not rely on each other.  So a light node for example would only compare their actionlattice with L4H's for example so they don't have to constantly performing lots of calculations.%0a---%0a> Each Level of epoch uses the hash of the last epoch plus all the hashes of the transactions in the current epoch.  So L1H's would only be concerned with previous L1H's and L4H's would only use the hashsnap of the last L4H, and all the transactions since.  They do not rely on each other.  So a light node for example would only compare their actionlattice with L4H's for example so they don't have to constantly performing lots of calculations.%0a
author:1668920749=
diff:1668920749:1668920710:=63c63%0a%3c Each Level of epoch uses the hash of the last epoch plus all the hashes of the transactions in the current epoch.  So L1H's would only be concerned with previous L1H's and L4H's would only use the hashsnap of the last L4H, and all the transactions since.  They do not rely on each other.  So a light node for example would only compare their actionlattice with L4H's for example so they don't have to constantly performing lots of calculations.%0a---%0a> Each Level of epoch uses the hash of the last epoch plush all the hashes of the transactions in the current epoch.  So L1H's would only be concerned with previous L1H's and L4H's would only use the hashsnap of the last L4H, and all the transactions since.  They do not rely on eachother.  So a light node for example would only compare their actionlattice with L4H's for example so they don't have to constantly performing lots of calculations.%0a
author:1668920710=
diff:1668920710:1668920682:=73,74d72%0a%3c %0a%3c Every 60 seconds would be a new L2H epoch.  L2HE1, L2HE2, etc every 60 seconds%0a
author:1668920682=
diff:1668920682:1668920604:=69d68%0a%3c Every 7 seconds would be a new L1H epoch.  L1HE1, L1HE2, etc every 7 seconds%0a
author:1668920604=
diff:1668920604:1668920028:=55,56c55,56%0a%3c !!!Hashsnaps (snapshots/epochs)%0a%3c %0a---%0a> !!!Hashsnaps (snapshots)%0a> %0a60,63d59%0a%3c %0a%3c For every number of seconds shown below (epoch), a node would broadcast the hash of the last hashsnap hashed with all the current transactions hash XOR'd together so that the order the transactions are in doesn't matter [[https://stackoverflow.com/questions/5889238/why-is-xor-the-default-way-to-combine-hashes|#]].  Obviously if there were double spending (duplicates) the later one(s) each node would just delete on their own.%0a%3c %0a%3c Each Level of epoch uses the hash of the last epoch plush all the hashes of the transactions in the current epoch.  So L1H's would only be concerned with previous L1H's and L4H's would only use the hashsnap of the last L4H, and all the transactions since.  They do not rely on eachother.  So a light node for example would only compare their actionlattice with L4H's for example so they don't have to constantly performing lots of calculations.%0a
author:1668920028=
diff:1668920028:1668918936:=54,80d53%0a%3c %0a%3c !!!Hashsnaps (snapshots)%0a%3c %0a%3c every certain amount of time the actionlattice should be hashed.  This should be done so that nodes can ping other nodes and by just comparing one number, they can see if their actionlattice is identical.  If the hashsnaps don't match, then the nodes can reconcile what is different.  The hashsnaps with the most voting weight are the accepted hashsnaps.  The reason there are 5 levels is that nodes can tell if they are correct with more granularity and can compensate and contest other hashsnaps faster.  For example if it was done every hour, if lots of nodes have different hourly hashsnaps, then they would have a lot of transactions to compare.  If there is a discrepancy at 7 second hashsnaps, they can compare a much smaller amount of transactions to see which lattice has a higher weight and accept that.%0a%3c %0a%3c This might look like you get a confirmation every hashsnap.  Yes and no, yes in the sense that you now know the majority of nodes have your transaction saved, but also you can be watching the nodes in real time as connections, and thus confirmations are happening to your transaction(s) constantly.  So a good node would have high certainty a transaction has gone through even before the 7 second hashsnaps circulate the network.%0a%3c %0a%3c !!!!Level 1 hashsnaps (L1H)%0a%3c %0a%3c These are done every 7 seconds%0a%3c %0a%3c !!!!Level 2 hashsnaps (L2H)%0a%3c %0a%3c These are done every minute (60 seconds)%0a%3c %0a%3c !!!!Level 3 hashsnaps (L3H)%0a%3c %0a%3c These are done every 10 mins (600 seconds)%0a%3c %0a%3c !!!!Level 4 hashsnaps (L4H)%0a%3c %0a%3c These are done every hour (3600 seconds)%0a%3c %0a%3c !!!!Level 5 hashsnaps (L5H)%0a%3c %0a%3c These are done every day (86400 seconds)%0a%3c %0a
author:1668918936=
diff:1668918936:1668918858:=378c378%0a%3c for the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits, so using CPU's to factor larger numbers would be a better option than using GPU's for lots of small numbers.%0a---%0a> for the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits.%0a
author:1668918858=
diff:1668918858:1668918418:=376c376%0a%3c (*)this is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest.%0a---%0a> *this is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest.%0a
author:1668918418=
diff:1668918418:1668918285:=284c284,286%0a%3c voting weight = y = (2^(digitlength/15)/(12.7))*((2^(digitlength/5))/2048)%0a---%0a> voting weight = (weighting constant)(2^([[#time|digitlength]]/5))/2048%0a> %0a> weighting constant (aka c) = 1 for alpha, 4 for beta, 16 for gamma, and 64 for delta%0a
author:1668918285=
diff:1668918285:1668918184:=359,362d358%0a%3c %0a%3c 70 digitlength%0a%3c %0a%3c y = (2^(70/5))/2048 => 8%0a
author:1668918184=
diff:1668918184:1668917552:=374,375d373%0a%3c *this is subject to testing to make sure that cpu's get more voting weight than gpu's, but perhaps the combo can be fastest.%0a%3c %0a382,385c380,383%0a%3c weighting constant (c) = 2^(digitlength/15)/(12.6992084157)%0a%3c %0a%3c voting weight = y = (2^(digitlength/15)/(12.7))*((2^(digitlength/5))/2048)%0a%3c %0a---%0a> weighting constant (c) = 2^(digitlength/15)/(12.7)%0a> %0a> voting weight = %0a> %0a387,414d384%0a%3c %0a%3c Attach:votingweight.ods%0a%3c %0a%3c 55 digitlength%0a%3c %0a%3c y = (2^(55/15)/(12.7))*((2^(55/5))/2048) = 1%0a%3c %0a%3c 60 digitlength%0a%3c %0a%3c y = (2^(60/15)/(12.7))*((2^(60/5))/2048) = 2.52%0a%3c %0a%3c 65 digitlength%0a%3c %0a%3c y = (2^(65/15)/(12.7))*((2^(65/5))/2048) = 6.35%0a%3c %0a%3c 70 digitlength%0a%3c %0a%3c y = (2^(70/15)/(12.7))*((2^(70/5))/2048) = 16%0a%3c %0a%3c 100 digitlength%0a%3c %0a%3c y = (2^(100/15)/(12.7))*((2^(100/5))/2048) = 4096%0a%3c %0a%3c 140 digitlength%0a%3c %0a%3c y = (2^(140/15)/(12.7))*((2^(140/5))/2048) = 6658043%0a%3c %0a%3c %0a
author:1668917552=
diff:1668917552:1668916807:=326,327c326,327%0a%3c !!!!Intermediate equation%0a%3c %0a---%0a> !!!!Final equation%0a> %0a371,386d370%0a%3c %0a%3c !!!!Final equation%0a%3c %0a%3c for the final equation we need to calculate the weighting constant.  This constant is created to compensate for more parallelizable methods of factoring for smaller numbers, like GPU's using ECM.  Basically we want to double the weight every 15 digits.%0a%3c %0a%3c voting weight = (weighting constant)(2^(digitlength/5))/2048%0a%3c %0a%3c weighting constant (c) = 2^(digitlength/15)/(2^(55/15))%0a%3c %0a%3c weighting constant (c) = 2^(digitlength/15)/(12.7)%0a%3c %0a%3c voting weight = %0a%3c %0a%3c !!!!!Examples%0a%3c %0a%3c %0a
author:1668916807=
diff:1668916807:1668916072:=286,288c286%0a%3c weighting constant (aka c) = 1 for alpha, 4 for beta, 16 for gamma, and 64 for delta%0a%3c %0a%3c GPU ECM is 10x faster than CPU%0a---%0a> weighting constant (aka c) = 1 for alpha, 2 for beta, 4 for gamma, and 8 for delta%0a
author:1668916072=
diff:1668916072:1668915783:=284,286c284%0a%3c voting weight = (weighting constant)(2^([[#time|digitlength]]/5))/2048%0a%3c %0a%3c weighting constant (aka c) = 1 for alpha, 2 for beta, 4 for gamma, and 8 for delta%0a---%0a> voting weight = (2^([[#time|digitlength]]/5))/2048%0a
author:1668915783=
diff:1668915783:1668915748:=284c284%0a%3c voting weight = (2^([[#time|digitlength]]/5))/2048%0a---%0a> voting weight = (2^([[#ntf|digitlength]]/5))/2048%0a
author:1668915748=
diff:1668915748:1668915093:=283,284d282%0a%3c %0a%3c voting weight = (2^([[#ntf|digitlength]]/5))/2048%0a
author:1668915093=
diff:1668915093:1668914936:=338,341d337%0a%3c 56 digitlength%0a%3c %0a%3c y = (2^(56/5))/2048 => 1.15%0a%3c %0a345,352d340%0a%3c %0a%3c 63 digitlength%0a%3c %0a%3c y = (2^(63/5))/2048 => 3%0a%3c %0a%3c 65 digitlength%0a%3c %0a%3c y = (2^(65/5))/2048 => 4%0a
author:1668914936=
diff:1668914936:1668914783:=307,310d306%0a%3c %0a%3c 56 digitlength%0a%3c %0a%3c y = (2)^(56/5) = 2352.5%0a
author:1668914783=
diff:1668914783:1668914756:=326c326%0a%3c %25green%25**y = (2^(x/5))/2048**%25%25%0a---%0a> y = (2^(x/5))/2048%0a
author:1668914756=
diff:1668914756:1668914369:=316,348d315%0a%3c !!!!Final equation%0a%3c %0a%3c now we want to normalize based on the current smallest accepted digitlength.%0a%3c %0a%3c So currently we accept 55 digit length minimum, which has a difficulty rating of 2048.  Thus we divide everything by 2048 to find relative difficulty%0a%3c %0a%3c Relative difficulty = difficulty/min difficulty%0a%3c %0a%3c currently with 55 digitlength min, equation would be:%0a%3c %0a%3c y = (2^(x/5))/2048%0a%3c %0a%3c !!!!!Examples%0a%3c %0a%3c 55 digitlength%0a%3c %0a%3c y = (2^(55/5))/2048 => 1%0a%3c %0a%3c 60 digitlength%0a%3c %0a%3c y = (2^(60/5))/2048 => 2%0a%3c %0a%3c 80 digitlength%0a%3c %0a%3c y = (2^(80/5))/2048 => 32%0a%3c %0a%3c 100 digitlength%0a%3c %0a%3c y = (2^(100/5))/2048 => 512%0a%3c %0a%3c 140 digitlength%0a%3c %0a%3c y = (2^(140/5))/2048 => 131072%0a
author:1668914369=
diff:1668914369:1668914286:=294c294%0a%3c !!!!Initial Equation%0a---%0a> !!!!Equation%0a
author:1668914286=
diff:1668914286:1668914268:=300c300%0a%3c %25green%25**y = (2)^(x/5)**%25%25%0a---%0a> %25green%25y = (2)^(x/5)%25%25%0a
author:1668914268=
diff:1668914268:1668913818:=300,317c300%0a%3c %25green%25y = (2)^(x/5)%25%25%0a%3c %0a%3c !!!!!Examples%0a%3c %0a%3c 55 digitlength%0a%3c %0a%3c y = (2)^(55/5) = 2048%0a%3c %0a%3c 60 digitlength%0a%3c %0a%3c y = 2^(60/5) = 4096%0a%3c %0a%3c 100 digitlength%0a%3c %0a%3c y = 2^(100/5) = 1048576%0a%3c %0a%3c %0a%3c %0a---%0a> y = (1.2)^x%0a
author:1668913818=
diff:1668913818:1668913781:=288,289c288,289%0a%3c weight = y%0a%3c %0a---%0a> weight%0a> %0a292c292%0a%3c digitlength = x%0a---%0a> digitlength%0a
author:1668913781=
diff:1668913781:1668913760:=301,302d300%0a%3c %0a%3c !!!!Notes%0a
author:1668913760=
diff:1668913760:1668913110:=286,287c286,287%0a%3c !!!!output:%0a%3c %0a---%0a> *output:%0a> %0a290,291c290,291%0a%3c !!!!inputs:%0a%3c %0a---%0a> *inputs:%0a> %0a294,300c294,296%0a%3c !!!!Equation%0a%3c %0a%3c f(x) = a (1 + r)^x%0a%3c %0a%3c y = initial (1+proportion growth per digit added)^(number of digits added)%0a%3c %0a%3c y = (1.2)^x%0a---%0a> *Equation%0a> %0a> y = ab^x%0a
author:1668913110=
diff:1668913110:1668907676:=286,297d285%0a%3c *output:%0a%3c %0a%3c weight%0a%3c %0a%3c *inputs:%0a%3c %0a%3c digitlength%0a%3c %0a%3c *Equation%0a%3c %0a%3c y = ab^x%0a%3c %0a299,300d286%0a%3c %0a%3c every 5 digit length is double the weight.  So a 105 digit [[#ntf|ntf]] is twice the weight as a 100 digit ntf.%0a
author:1668907676=
diff:1668907676:1668907043:=148c148%0a%3c How 20 byte bitcoin address is made [[https://bitcoin.stackexchange.com/a/64686|#]], 25 byte total after checksum [[https://bitcoin.stackexchange.com/a/64693|#]]%0a---%0a> How 20 byte bitcoin address is made [[https://bitcoin.stackexchange.com/a/64686|#]]%0a
author:1668907043=
diff:1668907043:1668906966:=149,150d148%0a%3c %0a%3c This max datasize does not automatically go up every 2 years like the digitlength, but only increases if a vote decides it should, perhaps every 7 years.%0a
author:1668906966=
diff:1668906966:1668906254:=213,214d212%0a%3c %0a%3c The digitlength for each level goes up one rung every 2 years to compensate for moore's law, however the datasize limit does not - without a vote.  The vote can be held every 7 years or something.%0a
author:1668906254=
diff:1668906254:1668906057:=140c140%0a%3c #%25purple%25Delta 16777216 bytes (17 mb) - max 536870912 bytes (537 mb)%0a---%0a> #%25purple%25Delta 16777216 bytes (17 mb)%0a
author:1668906057=
diff:1668906057:1668905696:=144,145c144,145%0a%3c 32 byte is the smallest known signature size [[https://stackoverflow.com/a/14955292|#]]%0a%3c %0a---%0a> 32kb is the smallest known signature size [[https://stackoverflow.com/a/14955292|#]]%0a> %0a147,148d146%0a%3c %0a%3c How 20 byte bitcoin address is made [[https://bitcoin.stackexchange.com/a/64686|#]]%0a
author:1668905696=
diff:1668905696:1668905149:=145,146d144%0a%3c %0a%3c Bitcoin public keys are 33 bytes compressed and public key hashes are 20 bytes [[https://bitcoin.stackexchange.com/a/2014|#]]%0a
author:1668905149=
diff:1668905149:1668893813:=141,144d140%0a%3c %0a%3c !!!!Notes%0a%3c %0a%3c 32kb is the smallest known signature size [[https://stackoverflow.com/a/14955292|#]]%0a
author:1668893813=
diff:1668893813:1668893519:=134,140c134,140%0a%3c #%25red%25Alpha 64 bytes%0a%3c %0a%3c #%25orange%25Beta 4092 bytes (4.1 kb)%0a%3c %0a%3c #%25green%25Gamma 262144 bytes (262 kb)%0a%3c %0a%3c #%25purple%25Delta 16777216 bytes (17 mb)%0a---%0a> #%25red%25Alpha 128 bytes (0.1 kb)%0a> %0a> #%25orange%25Beta 8192 bytes (8.2 kb)%0a> %0a> #%25green%25Gamma 524288 bytes (0.5 mb)%0a> %0a> #%25purple%25Delta 33554432 bytes (33 mb)%0a
author:1668893519=
diff:1668893519:1668893467:=213c213%0a%3c This is how long it takes to factor a base-2 brilliant number at each bitlevel.  In reality it would take many attempts at factoring nearly base-2 brilliant numbers so it will probably take 10x as long as this to find one that fulfills the challenge, and the higher the bitlevel, likely the more attempts needed.%0a---%0a> This is how long it takes to factor a base-2 brilliant number at each bitlevel.  In reality it would take many attempts at factoring nearly base-2 brilliant numbers so it will probably take 10x as long as this to find one that fulfills the challenge.%0a
author:1668893467=
diff:1668893467:1668892796:=212,213d211%0a%3c %0a%3c This is how long it takes to factor a base-2 brilliant number at each bitlevel.  In reality it would take many attempts at factoring nearly base-2 brilliant numbers so it will probably take 10x as long as this to find one that fulfills the challenge.%0a
author:1668892796=
diff:1668892796:1668892747:=442,443d441%0a%3c %0a%3c Bitcoin op_return is 80 bytes but nodes can set their own limits [[https://bitcoin.stackexchange.com/questions/78572/op-return-max-bytes-clarification|#]]%0a
author:1668892747=
diff:1668892747:1668870559:=
author:1668870559=
diff:1668870559:1668870527:=134,140c134,140%0a%3c #%25red%25Alpha 128 bytes (0.1 kb)%0a%3c %0a%3c #%25orange%25Beta 8192 bytes (8.2 kb)%0a%3c %0a%3c #%25green%25Gamma 524288 bytes (0.5 mb)%0a%3c %0a%3c #%25purple%25Delta 33554432 bytes (33 mb)%0a---%0a> %25red%25 # Alpha 128 bytes (0.1 kb)%0a> %0a> %25orange%25 # Beta 8192 bytes (8.2 kb)%0a> %0a> %25green%25 # Gamma 524288 bytes (0.5 mb)%0a> %0a> %25purple%25 # Delta 33554432 bytes (33 mb)%0a
author:1668870527=
diff:1668870527:1668870504:=134,140c134,140%0a%3c %25red%25 # Alpha 128 bytes (0.1 kb)%0a%3c %0a%3c %25orange%25 # Beta 8192 bytes (8.2 kb)%0a%3c %0a%3c %25green%25 # Gamma 524288 bytes (0.5 mb)%0a%3c %0a%3c %25purple%25 # Delta 33554432 bytes (33 mb)%0a---%0a> %25red%25 #Alpha 128 bytes (0.1 kb)%0a> %0a> %25orange%25 #Beta 8192 bytes (8.2 kb)%0a> %0a> %25green%25 #Gamma 524288 bytes (0.5 mb)%0a> %0a> %25purple%25 #Delta 33554432 bytes (33 mb)%0a
author:1668870504=
diff:1668870504:1668870481:=134,140c134,140%0a%3c %25red%25 #Alpha 128 bytes (0.1 kb)%0a%3c %0a%3c %25orange%25 #Beta 8192 bytes (8.2 kb)%0a%3c %0a%3c %25green%25 #Gamma 524288 bytes (0.5 mb)%0a%3c %0a%3c %25purple%25 #Delta 33554432 bytes (33 mb)%0a---%0a> %25red%25#Alpha 128 bytes (0.1 kb)%0a> %0a> %25orange%25#Beta 8192 bytes (8.2 kb)%0a> %0a> %25green%25#Gamma 524288 bytes (0.5 mb)%0a> %0a> %25purple%25#Delta 33554432 bytes (33 mb)%0a
author:1668870481=
diff:1668870481:1668870422:=134,140c134,140%0a%3c %25red%25#Alpha 128 bytes (0.1 kb)%0a%3c %0a%3c %25orange%25#Beta 8192 bytes (8.2 kb)%0a%3c %0a%3c %25green%25#Gamma 524288 bytes (0.5 mb)%0a%3c %0a%3c %25purple%25#Delta 33554432 bytes (33 mb)%0a---%0a> Alpha 128 bytes (0.1 kb)%0a> %0a> Beta 8192 bytes (8.2 kb)%0a> %0a> Gamma 524288 bytes (0.5 mb)%0a> %0a> Delta 33554432 bytes (33 mb)%0a
author:1668870422=
diff:1668870422:1668869944:=132,140c132,138%0a%3c This is starting levels, as each bitlevel is retired and replaced so is this. Each new bitlevel doubles the size allowed of the former and every 6 bitlevels (bepoch) it goes up 64x%0a%3c %0a%3c Alpha 128 bytes (0.1 kb)%0a%3c %0a%3c Beta 8192 bytes (8.2 kb)%0a%3c %0a%3c Gamma 524288 bytes (0.5 mb)%0a%3c %0a%3c Delta 33554432 bytes (33 mb)%0a---%0a> Alpha 128 bytes%0a> %0a> Beta%0a> %0a> Gamma%0a> %0a> Delta%0a
author:1668869944=
diff:1668869944:1668827633:=129,138d128%0a%3c %0a%3c !!!Data standard bitlevels%0a%3c %0a%3c Alpha 128 bytes%0a%3c %0a%3c Beta%0a%3c %0a%3c Gamma%0a%3c %0a%3c Delta%0a
author:1668827633=
diff:1668827633:1668827488:=230,233d229%0a%3c %0a%3c Maybe 1024 bits would be reasonable which is enough for 4x 256 bit signatures.%0a%3c %0a%3c Also it depends on how difficult the number to factor is.  If it takes 1 min on an average computer to factor perhaps it would allow less data to be stored than a [[#ntf|number to factor]] that takes 1 hour on a average computer. %0a
author:1668827488=
diff:1668827488:1668826133:=226,229d225%0a%3c %0a%3c !!Data [[#data]]%0a%3c %0a%3c A certain amount of data can be stored in a transaction.  Since as many txn's as desired can be added to the Actionlattice in parallel,a size limitation does not effects number of transactions per second the network can handle, which is in theory, infinite and limited only by bandwidth and processing speed.%0a
author:1668826133=
diff:1668826133:1668826033:=62c62%0a%3c This is about the only similarity between block-lattice and actionlattice.  I wasn't aware this is what nano did prior to designing actionlattice so this confirms it is a good choice and resembles what is done in nature.  Actionlattice however will probably have each transaction to verify 3 others and you also check 7 levels down, 3^7 transactions you check which is around 2,000.  In Nano, you really only check 2.%0a---%0a> This is about the only similarity between block-lattice and actionlattice.  I wasn't aware this is what nano did prior to designing actionlattice so this confirms it is a good choice and resembles what is done in nature.  Actionlattice however will probably have each transactions verify 3 others and you also check 7 levels down, 3^7 transactions you check which is around 2,000.  In Nano, you really only check 2.%0a
author:1668826033=
diff:1668826033:1668825988:=415c415%0a%3c See [[#nano|nano comparisions]]%0a---%0a> See [[nano comparisions|#nano]]%0a
author:1668825988=
diff:1668825988:1668825929:=415,416d414%0a%3c See [[nano comparisions|#nano]]%0a%3c %0a419a418,419%0a> %0a> Nano stats with%0a
author:1668825929=
diff:1668825929:1668825883:=56c56%0a%3c !!!Nano [[#nano]]%0a---%0a> !!!Nano%0a
author:1668825883=
diff:1668825883:1668442859:=412,419d411%0a%3c %0a%3c !!!Nano%0a%3c %0a%3c Good rundown of nano [[https://www.youtube.com/watch?v=qZJyT-B9QDc|#]]%0a%3c %0a%3c Nano shares almost nothing with actionlattice besides the "lattice" name, nano calls theirs a blocklattice.  However understanding how it works and the design decisions made can help in understanding the benefits to actionlattice.%0a%3c %0a%3c Nano stats with%0a
author:1668442859=
diff:1668442859:1667976215:=392c392%0a%3c 2017 proposal [[https://bitcointalk.org/index.php?topic=2575256.0|#]] ~[[~NatureHacker]]%0a---%0a> 2017 proposal [[https://bitcointalk.org/index.php?topic=2575256.0|#]]%0a
author:1667976215=
diff:1667976215:1667976070:=437c437%0a%3c probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] probably with QT [[https://pypi.org/project/QtPy/|#]] (choose xml or json [[https://stackoverflow.com/questions/2843552/restful-interface-for-c-qt|#]]). Go and especially Rust are good [[https://qr.ae/pvBAu3|#]]%0a\ No newline at end of file%0a---%0a> probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] probably with QT (choose xml or json [[https://stackoverflow.com/questions/2843552/restful-interface-for-c-qt|#]]). Go and especially Rust are good [[https://qr.ae/pvBAu3|#]]%0a\ No newline at end of file%0a
author:1667976070=
diff:1667976070:1667976029:=437c437%0a%3c probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] probably with QT (choose xml or json [[https://stackoverflow.com/questions/2843552/restful-interface-for-c-qt|#]]). Go and especially Rust are good [[https://qr.ae/pvBAu3|#]]%0a\ No newline at end of file%0a---%0a> probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] probably with QT (choose xml or json). Go and especially Rust are good [[https://qr.ae/pvBAu3|#]]%0a\ No newline at end of file%0a
author:1667976029=
diff:1667976029:1667975992:=437c437%0a%3c probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] probably with QT (choose xml or json). Go and especially Rust are good [[https://qr.ae/pvBAu3|#]]%0a\ No newline at end of file%0a---%0a> probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] probably with QT. Go and especially Rust are good [[https://qr.ae/pvBAu3|#]]%0a\ No newline at end of file%0a
author:1667975992=
diff:1667975992:1667975922:=437c437%0a%3c probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] probably with QT. Go and especially Rust are good [[https://qr.ae/pvBAu3|#]]%0a\ No newline at end of file%0a---%0a> probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] or possibly QT. Go and especially Rust are good [[https://qr.ae/pvBAu3|#]]%0a\ No newline at end of file%0a
author:1667975922=
diff:1667975922:1667975646:=437c437%0a%3c probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] or possibly QT. Go and especially Rust are good [[https://qr.ae/pvBAu3|#]]%0a\ No newline at end of file%0a---%0a> probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] or possibly QT%0a\ No newline at end of file%0a
author:1667975646=
diff:1667975646:1667975562:=437c437%0a%3c probably should be coded as a restful [[https://en.wikipedia.org/wiki/Representational_state_transfer|#]] api in python, java, or node [[https://qr.ae/pvBAAd|#]] or possibly QT%0a\ No newline at end of file%0a---%0a> probably should be coded as a restful api in python, java, or node [[https://qr.ae/pvBAAd|#]] or possibly QT%0a\ No newline at end of file%0a
author:1667975562=
diff:1667975562:1667975505:=437c437%0a%3c probably should be coded as a restful api in python, java, or node [[https://qr.ae/pvBAAd|#]] or possibly QT%0a\ No newline at end of file%0a---%0a> probably should be coded as a restful api in python, java, or node [[https://qr.ae/pvBAAd|#]]%0a\ No newline at end of file%0a
author:1667975505=
diff:1667975505:1667804698:=435,437c435%0a%3c Lattice sieving on a GPU [[https://www.mersenneforum.org/showthread.php?t=27515|#]]%0a%3c %0a%3c probably should be coded as a restful api in python, java, or node [[https://qr.ae/pvBAAd|#]]%0a\ No newline at end of file%0a---%0a> Lattice sieving on a GPU [[https://www.mersenneforum.org/showthread.php?t=27515|#]]%0a\ No newline at end of file%0a
author:1667804698=
diff:1667804698:1667804640:=225c225%0a%3c The first contract type is pledging coins to the [[#act|miner]] of a transaction.%0a---%0a> The first contract type is pledging coins to the [[#miner|miner]] of a transaction.%0a
author:1667804640=
diff:1667804640:1667804594:=222,225d221%0a%3c %0a%3c !!Smart contracts [[#contract]]%0a%3c %0a%3c The first contract type is pledging coins to the [[#miner|miner]] of a transaction.%0a
author:1667804594=
diff:1667804594:1667618724:=214,221d213%0a%3c %0a%3c !!Cips%0a%3c %0a%3c !!!Use case%0a%3c %0a%3c Cip's don't need to have value, they vcan simply be placeholders for tokens whose value is based on something else.%0a%3c %0a%3c However we could (and probably should) allow proposing a transaction to be able to use a little [[#contract|smart contract]] to pledge an amount of Cip's to be given to the sucessful miner of your transaction.  This could buy you a fast and strong initial confirmation, which will lead to faster subsequent confirmations, and thus a faster completed transaction.%0a
author:1667618724=
diff:1667618724:1667617890:=19c19%0a%3c It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using actionlattice to craft items.  It can also be used as an accounting ledger for transferring real or fictional assets like NFT's and tokens.  It can even be used for voting, much more democratically than blockchain. AI devices will also be able to mine this.  It can also be used for [[NatureVault/Social media]] since the only bottleneck is the sync speed.%0a---%0a> It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using actionlattice to craft items.  It can also be used as an accounting ledger for transferring real or fictional assets like NFT's and tokens.  It can even be used for voting, much more democratically than blockchain. AI devices will also be able to mine this.%0a
author:1667617890=
diff:1667617890:1664964218:=17c17%0a%3c An actionlattice is a new open source method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, encode tokens and NFT's, and issue rewards (cips). It replaces the blockchain.  You can think of it like a 3D blockchain, whereas a blockchain is 1D.  We have come a long way from [[https://en.wikipedia.org/wiki/History_of_writing#Recorded_history|clay tablets]]%0a---%0a> An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, encode tokens and NFT's, and issue rewards (cips). It replaces the blockchain.  You can think of it like a 3D blockchain, whereas a blockchain is 1D.  We have come a long way from [[https://en.wikipedia.org/wiki/History_of_writing#Recorded_history|clay tablets]]%0a
author:1664964218=
diff:1664964218:1664941893:=14,15d13%0a%3c %0a%3c Bitcoin was the rough draft.  Actionlattice is the fulfilment of the technology.%0a
author:1664941893=
diff:1664941893:1664941872:=13a14,15%0a> %0a> !!test%0a
author:1664941872=
diff:1664941872:1664927853:=14,15d13%0a%3c %0a%3c !!test%0a
author:1664927853=
diff:1664927853:1664927828:=254c254%0a%3c !!!!Run GNFS on candidates to find a base-2 brilliant number%0a---%0a> !!!!Run GNFS on candidates to find a base-2 brilliant number (both factors have the same number of digits)%0a
author:1664927828=
diff:1664927828:1664916314:=252c252%0a%3c !!!!Run ECM on candidate numbers and eliminate non acceptable%0a---%0a> !!!!Run ECM on candidate numbers and eliminate any non acceptable numbers%0a
author:1664916314=
diff:1664916314:1664916076:=11a12,13%0a> (:htoc:)%0a> (:toggle init=hide id=htoc lshow='Show Table of Contents' lhide='Hide Table of Contents':)%0a
author:1664916076=
diff:1664916076:1664916054:=13c13%0a%3c (:toggle init=hide id=htoc lshow='Show Table of Contents' lhide='Hide Table of Contents':)%0a---%0a> (:toggle init=show id=htoc lshow='Show Table of Contents' lhide='Hide Table of Contents':)%0a
author:1664916054=
diff:1664916054:1664916031:=12d11%0a%3c (:htoc:)%0a
author:1664916031=
diff:1664916031:1664915992:=12c12,13%0a%3c (:toggle init=show id=htoc lshow='Show Table of Contents' lhide='Hide Table of Contents':)%0a---%0a> (:toggle init=hide id=htoc lshow='Show Table of Contents' lhide='Hide Table of Contents':)%0a> (:htoc:)%0a
author:1664915992=
diff:1664915992:1664915962:=13d12%0a%3c (:htoc:)%0a
author:1664915962=
diff:1664915962:1664914799:=12c12%0a%3c (:toggle init=hide id=htoc lshow='Show Table of Contents' lhide='Hide Table of Contents':)%0a---%0a> (:htoc:)%0a
author:1664914799=
diff:1664914799:1664897095:=12d11%0a%3c (:htoc:)%0a
author:1664897095=
diff:1664897095:1664895804:=25c25%0a%3c Attach:actionlattice.png | '''This is for a 2 bond version, 3 bond version would look a bit more complex.'''%0a---%0a> %25lframe%25Attach:actionlattice.png | This is for a 2 bond version, 3 bond version would look a bit more complex.%0a
author:1664895804=
diff:1664895804:1664895742:=17c17%0a%3c It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using actionlattice to craft items.  It can also be used as an accounting ledger for transferring real or fictional assets like NFT's and tokens.  It can even be used for voting, much more democratically than blockchain. AI devices will also be able to mine this.%0a---%0a> It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using actionlattice to craft items.  It can also be used as an accounting ledger for transferring real or fictional assets.  It can even be used for voting, much more democratically than blockchain. AI devices will also be able to mine this.%0a
author:1664895742=
diff:1664895742:1664895633:=17c17%0a%3c It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using actionlattice to craft items.  It can also be used as an accounting ledger for transferring real or fictional assets.  It can even be used for voting, much more democratically than blockchain. AI devices will also be able to mine this.%0a---%0a> It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using it to craft items.  It can also be used as an accounting ledger for transferring real or fictional assets.  It can even be used for voting, much more democratically than blockchain. AI devices will also be able to mine this.%0a
author:1664895633=
diff:1664895633:1664895564:=17c17%0a%3c It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using it to craft items.  It can also be used as an accounting ledger for transferring real or fictional assets.  It can even be used for voting, much more democratically than blockchain. AI devices will also be able to mine this.%0a---%0a> It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using it to craft items.  It can also be used as an accounting ledger for transferring real or fictional assets.%0a
author:1664895564=
diff:1664895564:1664894825:=346c346%0a%3c #Fungibility: The main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years, so basically the value will depreciate like a PC value does. I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  If we timestamped the transactions and increased the digit-length requirement of the [[#ntf|NTF]] by 5 every 2.6 years then 1 cip = 1 cip forever, but I tend to not want to make a rigid difficulty curve which would eventually break.  I would rather sacrifice value proposition for flexibility, so that the network can act as a sensor of koomey's law rather than a subject of it. Also I would rather not rely on arbitrary timestamps.%0a---%0a> #Fungibility: The main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  If we timestamped the transactions and increased the digit-length requirement of the [[#ntf|NTF]] by 5 every 2.6 years then 1 cip = 1 cip forever, but I tend to not want to make a rigid difficulty curve which would eventually break.  I would rather sacrifice value proposition for flexibility, so that the network can act as a sensor of koomey's law rather than a subject of it. Also I would rather not rely on arbitrary timestamps.%0a
author:1664894825=
diff:1664894825:1664894761:=348,349d347%0a%3c **Another way to improve this is to have different genesi lattices, Alpha for low bitlength proof, Beta for medium bitlength proof, Gamma for high bitlength proof.  so a gamma cip would always hold the same value, as would a beta or alpha cip.  The downside to this solution is there isn't infinitely variable bitlength that can be rewarded so we really wouldn't know how high a proof level could be without trying it.  So in this example alpha might start at 80 digit proof, then next year might be 82 digit proof, next year 84 digit proof etc.  So one alpha cip will always equal 1 alpha cip.  Problem is we don't know how fast we can raise that bitlevel proof requirement (which is set by each individual node) since there is no incentive for miners to go above and beyond.%0a%3c %0a350a349,350%0a> %0a> **A help previous for the above two is to have different genesi lattices, Alpha for low bitlength proof, Beta for medium bitlength proof, Gamma for high bitlength proof.  so a gamma cip would always hold the same value, as would a beta or alpha cip.  The downside to this solution is there isn't infinitely variable bitlength that can be rewarded so we really wouldn't know how high a proof level could be without trying it.  So in this example alpha might start at 80 digit proof, then next year might be 82 digit proof, next year 84 digit proof etc.  So one alpha cip will always equal 1 alpha cip.  Problem is we don't know how fast we can raise that bitlevel proof requirement (which is set by each individual node) since there is no incentive for miners to go above and beyond.%0a
author:1664894761=
diff:1664894761:1664894519:=348c348%0a%3c #Consensus: See also [[#consensus|consensus]]. It is a rolling consensus instead of a block based consensus. What this means is the nodes can watch a transaction gain more confirmations in real time (while watching for double spends) to decide when a transaction is complete, instead of waiting for arbitrary block-times to confirm it (like a blockchain). %0a---%0a> #Consensus: See also [[#consensus|consensus]]. %0a
author:1664894519=
diff:1664894519:1664894438:=47,51c47,49%0a%3c Consensus looks slightly different than Bitcoin, but it is even more rigorous. Bitcoin for one has to prevent double spending by using arbitrary timestamps. Actionlattice is more rigorous at preventing double spending (and privacy at the same time) by dictating that an address can only hold 1 bit and never be reused. Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain. In the same way nodes/miners need to verify the transactions in actionlattice and then accept the "heaviest" version (number of transactions x their bitlength weight = greatest). %0a%3c %0a%3c That said someone could attempt a double spend on two different "sides" of the lattice at once, and the "each transaction confirms 3 others and 7 levels down" wouldn't necessarily catch it immediately, but it would eventually. Actionlattice basically asks for a continuous rolling vote. Lets look at these two duplicate transactions sending to different addresses (double spend; they are trying to duplicate their cips). Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 3 transactions and it would be invalid if they vouched for a double spend. Now whichever of the two double spends gets the most "confirmations" is the winner. The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead. Also, every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified.%0a%3c %0a%3c So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend or otherwise invalid tx, and go several layers down from the tx's they are vouching for there is no double spend there either. It doesn't hurt the person making the nullified but valid transaction that was linked to the "bad" one, as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward. So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser. It would be a "rolling consensus".%0a---%0a> Consensus looks slightly different than Bitcoin, but it is even more rigorous. Bitcoin for one has to prevent double spending by using arbitrary timestamps. Actionlattice is more rigorous at preventing double spending (and privacy at the same time) by dictating that an address can only hold 1 bit and never be reused. Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain. In the same way nodes/miners need to verify the transactions in actionlattice and then accept the "heaviest" version (number of transactions x their bitlength weight = biggest). %0a> %0a> That said someone could attempt a double spend on two different "sides" of the lattice at once, and the "each transaction confirms 3 others and 7 levels down" wouldn't necessarily catch it immediately, but it would eventually. Actionlattice basically asks for a continuous rolling vote. Lets look at these two duplicate transactions sending to different addresses (double spend; they are trying to duplicate their cips). Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 3 transactions and it would be invalid if they vouched for a double spend. Now whichever of the two double spends gets the most "confirmations" is the winner. The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead. Also, every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified. So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend or otherwise invalid tx, and go several layers down from the tx's they are vouching for there is no double spend there either. It doesn't hurt the person making the nullified but valid transaction that was linked to the "bad" one, as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward. So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser. It would be a "rolling consensus".%0a
author:1664894438=
diff:1664894438:1664894355:=346c346%0a%3c #Consensus: See also [[#consensus|consensus]]. %0a---%0a> #Consensus: See also [[#consensus|consensus]]. Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by using arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 2 others and levels down" wouldn't necessarily catch it. Alright so I think I have a pretty good grasp of it.  So lets increase it to every transaction must attach to (vouch for) 4 transactions instead of 2 just to increase the robustness.  So what this does is basically ask for a continuous rolling vote.  Lets say there are two transactions sending to different addresses (double spend).  Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 4 transactions and it would be invalid if they vouched for a double spend.  Now whichever of the two double spends gets the most "confirmations" is the winner.  The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead.  Also every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified.  So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend and several layers down from the tx's they are vouching for there is no double spend either.  It doesn't hurt the person making the transaction as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward.  So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser.  Rolling consensus.%0a
author:1664894355=
diff:1664894355:1664894329:=344c344%0a%3c #Fungibility: The main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  If we timestamped the transactions and increased the digit-length requirement of the [[#ntf|NTF]] by 5 every 2.6 years then 1 cip = 1 cip forever, but I tend to not want to make a rigid difficulty curve which would eventually break.  I would rather sacrifice value proposition for flexibility, so that the network can act as a sensor of koomey's law rather than a subject of it. Also I would rather not rely on arbitrary timestamps.%0a---%0a> #Fungibility: The main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  If we timestamped the transactions and increased the digit-length requirement of the [[#nft|NTF]] by 5 every 2.6 years then 1 cip = 1 cip forever, but I tend to not want to make a rigid difficulty curve which would eventually break.  I would rather sacrifice value proposition for flexibility, so that the network can act as a sensor of koomey's law rather than a subject of it. Also I would rather not rely on arbitrary timestamps.%0a
author:1664894329=
diff:1664894329:1664893919:=344c344%0a%3c #Fungibility: The main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  If we timestamped the transactions and increased the digit-length requirement of the [[#nft|NTF]] by 5 every 2.6 years then 1 cip = 1 cip forever, but I tend to not want to make a rigid difficulty curve which would eventually break.  I would rather sacrifice value proposition for flexibility, so that the network can act as a sensor of koomey's law rather than a subject of it. Also I would rather not rely on arbitrary timestamps.%0a---%0a> #Fungibility: The main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  Using a UTXO we could peg the value of 1 cip = 1 cip forever, but I tend to want completing a higher bitlength proof to be more valuable than a small proof, which also means we can get faster initial confirmations (since they are small proofs, larger proofs can come later).%0a
author:1664893919=
diff:1664893919:1664893767:=306,309c306,309%0a%3c !!!Types of invalid transactions%0a%3c %0a%3c !!!!Sending cips that don't exist%0a%3c %0a---%0a> !!!!Types of invalid transactions%0a> %0a> !!!!!Sending cips that don't exist%0a> %0a312,313c312,313%0a%3c !!!!Duplicate transaction%0a%3c %0a---%0a> !!!!!Duplicate transaction%0a> %0a316,317c316,317%0a%3c !!!!Double spend%0a%3c %0a---%0a> !!!!!Double spend%0a> %0a320,321c320,321%0a%3c !!!!Double mine%0a%3c %0a---%0a> !!!!!Double mine%0a> %0a324,325c324,325%0a%3c !!!!Non-standard bitlevel proof%0a%3c %0a---%0a> !!!!!Non-standard bitlevel proof%0a> %0a330,331c330,331%0a%3c !!!!Invalid signatures or proof of semiprime%0a%3c %0a---%0a> !!!!!Invalid signatures or proof of semiprime%0a> %0a334,335c334,335%0a%3c !!!!Connected to an invalid transaction%0a%3c %0a---%0a> !!!!!Connected to an invalid transaction%0a> %0a338c338%0a%3c !!!!Double spend%0a---%0a> !!!!!Double spend%0a
author:1664893767=
diff:1664893767:1664893740:=25c25%0a%3c %25lframe%25Attach:actionlattice.png | This is for a 2 bond version, 3 bond version would look a bit more complex.%0a---%0a> %25cframe%25Attach:actionlattice.png | This is for a 2 bond version, 3 bond version would look a bit more complex.%0a
author:1664893740=
diff:1664893740:1664893688:=25c25%0a%3c %25cframe%25Attach:actionlattice.png | This is for a 2 bond version, 3 bond version would look a bit more complex.%0a---%0a> %25rframe%25Attach:actionlattice.png | This is for a 2 bond version, 3 bond version would look a bit more complex.%0a
author:1664893688=
diff:1664893688:1664893652:=217d216%0a%3c %0a
author:1664893652=
diff:1664893652:1664893603:=216c216%0a%3c Attach:lattigenesis.png | '''2 bond version gives a 3 transaction genesis'''%0a---%0a> %25frame%25Attach:lattigenesis.png | '''2 bond version gives a 3 transaction genesis'''%0a
author:1664893603=
diff:1664893603:1664893568:=216c216%0a%3c %25frame%25Attach:lattigenesis.png | '''2 bond version gives a 3 transaction genesis'''%0a---%0a> Attach:lattigenesis.png | '''2 bond version gives a 3 transaction genesis'''%0a
author:1664893568=
diff:1664893568:1664893396:=216,217c216%0a%3c Attach:lattigenesis.png | '''2 bond version gives a 3 transaction genesis'''%0a%3c Attach:3genesis.png | '''In the 3 bond case there would be a 4 transaction genesis.'''%0a---%0a> Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664893396=
diff:1664893396:1664893373:=216c216%0a%3c Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25width=90pct%25 Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664893373=
diff:1664893373:1664893293:=216c216%0a%3c %25width=90pct%25 Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25block cframe width=50pct%25 %25width=50pct%25 Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664893293=
diff:1664893293:1664893215:=216c216%0a%3c %25block cframe width=50pct%25 %25width=50pct%25 Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25block cframe%25 Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664893215=
diff:1664893215:1664893175:=216c216%0a%3c %25block cframe%25 Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25block cframe width=300px%25 Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664893175=
diff:1664893175:1664893136:=216c216%0a%3c %25block cframe width=300px%25 Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25block cframe width=50pct%25 Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664893136=
diff:1664893136:1664893041:=216c216%0a%3c %25block cframe width=50pct%25 Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25block width=50pct lframe%25Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664893041=
diff:1664893041:1664892972:=216c216%0a%3c %25block width=50pct lframe%25Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25width=50pct%25%25lframe%25Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664892972=
diff:1664892972:1664892800:=216c216%0a%3c %25width=50pct%25%25lframe%25Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis \ Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25width=50pct%25%25lframe%25Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664892800=
diff:1664892800:1664892774:=216c216%0a%3c %25width=50pct%25%25lframe%25Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25width=70pct%25%25lframe%25Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664892774=
diff:1664892774:1664892736:=216c216%0a%3c %25width=70pct%25%25lframe%25Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25width=80pct%25%25lframe%25Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis | Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664892736=
diff:1664892736:1664892699:=216c216%0a%3c %25width=80pct%25%25lframe%25Attach:lattigenesis.png 2 bond version gives a 3 transaction genesis | Attach:3genesis.png In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25width=90pct%25%25lframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis | Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664892699=
diff:1664892699:1664892619:=216c216%0a%3c %25width=90pct%25%25lframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis | Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25lframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis | %25lframe%25Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664892619=
diff:1664892619:1664892552:=216c216%0a%3c %25lframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis | %25lframe%25Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25lframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis %25lframe%25Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664892552=
diff:1664892552:1664892410:=216c216,218%0a%3c %25lframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis %25lframe%25Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25cframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis%0a> %0a> %25cframe%25Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664892410=
diff:1664892410:1664892347:=216,218c216,218%0a%3c %25cframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis%0a%3c %0a%3c %25cframe%25Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25lframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis%0a> %0a> %25lframe%25Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664892347=
diff:1664892347:1664892315:=216,218c216,218%0a%3c %25lframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis%0a%3c %0a%3c %25lframe%25Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> %25rframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis%0a> %0a> %25rframe%25Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a
author:1664892315=
diff:1664892315:1664892205:=216,218c216,220%0a%3c %25rframe%25Attach:lattigenesis.png | 2 bond version gives a 3 transaction genesis%0a%3c %0a%3c %25rframe%25Attach:3genesis.png | In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> Attach:lattigenesis.png%0a> %0a> In the 3 bond case there would be a 4 transaction genesis.%0a> %0a> Attach:3genesis.png%0a
author:1664892205=
diff:1664892205:1664892059:=25c25%0a%3c %25rframe%25Attach:actionlattice.png | This is for a 2 bond version, 3 bond version would look a bit more complex.%0a---%0a> Attach:actionlattice.png | This is for a 2 bond version, 3 bond version would look a bit more complex.%0a
author:1664892059=
diff:1664892059:1664891852:=25c25%0a%3c Attach:actionlattice.png | This is for a 2 bond version, 3 bond version would look a bit more complex.%0a---%0a> Attach:actionlattice.png%0a
author:1664891852=
diff:1664891852:1664891486:=228,230c228%0a%3c The nodes set the minimum difficulty they will accept, which should probably take at least 1 second to complete.  This should be raised based on basically what is the minimum difficulty proof that is present in the network.  Since miners get rewarded to re-mine old transactions at higher difficulty, the network autocompensates for moore's law.  The result of this is old rewards would slowly loose value over time, at about the rate that a PC depreciates.  That could be quite fast, value might decline with moore's law for old cips. However you can keep mining fresh new cips with high value constantly.  [[NatureVault/Digital Collectible Network]] doesn't have the value loss problem though.  Neither does Fact0rn.%0a%3c %0a%3c Value depreciation could be prevented by raising the digit-length of the [[#ntf|NTF]] by 5 every 2.6 years (koomey's law) but then the network would no longer auto regulate itself and this central planning will eventually cause the network to fail when koomey's law deviates in doubling time and the network fails to adapt properly.  I would rather trade value proposition for long term health of the network.%0a---%0a> The nodes set the minimum difficulty they will accept.  This should be raised based on basically what is the minimum difficulty proof that is present in the network.  Since miners get rewarded to re-mine old transactions at higher difficulty, the network autocompensates for moore's law.  The result of this is old rewards would slowly loose value over time.  That could be quite fast, value might decline with moore's law for old cips. However you can keep mining fresh new cips with high value constantly.  [[NatureVault/Digital Collectible Network]] doesn't have the value loss problem though.  Neither does Fact0rn.%0a
author:1664891486=
diff:1664891486:1664891455:=212c212%0a%3c The genesis, called lattigenesis, requires number of bonds + 1 transactions (in the case of 2 bonds - a trinity) to begin that cross reference (connect) to each other. Three transactions is the minimum genesis for a 2 bond system, and more could be used which would make the surface that would need to be attacked larger, and thus a larger genesis is more resistant to attack.  But using the minimum viable genesis (MVG) of a trinity for 2 bonds is preferable to keep "fake" transactions to a minimum.  Genesis transactions should not have a cipbase (no new coins should be generated).  Later transactions can just be blank with no cip movement in order to collect cipbase cips.%0a---%0a> The genesis, called lattigenesis, requires number of bonds + 1 transactions (in the case of 2 bonds - a trinity) to begin that cross reference (connect) to eachother. Three transactions is the minimum genesis for a 2 bond system, and more could be used which would make the surface that would need to be attacked larger, and thus a larger genesis is more resistant to attack.  But using the minimum viable genesis (MVG) of a trinity fir 2 bonds is preferable to keep "fake" transactions to a minimum.  Genesis transactions should not have a cipbase (no new coins should be generated).  Later transactions can just be blank with no cip movement in order to collect cipbase cips.%0a
author:1664891455=
diff:1664891455:1664891354:=212c212%0a%3c The genesis, called lattigenesis, requires number of bonds + 1 transactions (in the case of 2 bonds - a trinity) to begin that cross reference (connect) to eachother. Three transactions is the minimum genesis for a 2 bond system, and more could be used which would make the surface that would need to be attacked larger, and thus a larger genesis is more resistant to attack.  But using the minimum viable genesis (MVG) of a trinity fir 2 bonds is preferable to keep "fake" transactions to a minimum.  Genesis transactions should not have a cipbase (no new coins should be generated).  Later transactions can just be blank with no cip movement in order to collect cipbase cips.%0a---%0a> The genesis, called lattigenesis, requires number of bomds + 1 transactions (in the case of 2 bonds - a trinity) to begin that cross reference (connect) to eachother. Three transactions is the minimum genesis for a 2 bond system, and more could be used which would make the surface that would need to be attacked larger, and thus a larger genesis is more resistant to attack.  But using the minimum viable genesis (MVG) of a trinity fir 2 bonds is preferable to keep "fake" transactions to a minimum.  Genesis transactions should not have a cipbase (no new coins should be generated).  Later transactions can just be blank with no cip movement in order to collect cipbase cips.%0a
author:1664891354=
diff:1664891354:1664862889:=212c212%0a%3c The genesis, called lattigenesis, requires number of bomds + 1 transactions (in the case of 2 bonds - a trinity) to begin that cross reference (connect) to eachother. Three transactions is the minimum genesis for a 2 bond system, and more could be used which would make the surface that would need to be attacked larger, and thus a larger genesis is more resistant to attack.  But using the minimum viable genesis (MVG) of a trinity fir 2 bonds is preferable to keep "fake" transactions to a minimum.  Genesis transactions should not have a cipbase (no new coins should be generated).  Later transactions can just be blank with no cip movement in order to collect cipbase cips.%0a---%0a> The genesis, called lattigenesis, requires 3 transactions (a trinity) to begin that cross reference (connect) to eachother. Three transactions is the minimum genesis of course, and more could be used which would make the surface that would need to be attacked larger, and thus a larger genesis is more resistant to attack.  But using the minimum viable genesis (MVG) of a trinity is preferable to keep "fake" transactions to a minimum.  Genesis transactions should not have a cipbase (no new coins should be generated).  Later transactions can just be blank with no cip movement in order to collect cipbase cips.%0a
author:1664862889=
diff:1664862889:1664862875:=121c121%0a%3c !!Number to Factor (NTF) [[#ntf]]%0a---%0a> !!Number to Factor (NTF)%0a
author:1664862875=
diff:1664862875:1664862846:=120,121d119%0a%3c %0a%3c !!Number to Factor (NTF)%0a
author:1664862846=
diff:1664862846:1664862751:=192c192%0a%3c These bitlevels chosen by the miner do affect [[#consensus|consensus]] because transactions ruled invalid or connected to invalid blocks will be deleted.  They will need to be reactivated (remined) in order to add back to the lattice so they lost all the proof they provided so are incentivized to be especially careful where they connect.  The voting [[#weight|weight]] determined by the digit-length of the [[#ntf|NTF]] is what determines their voting power.%0a---%0a> These bitlevels chosen by the miner do affect [[#consensus|consensus]] because transactions ruled invalid or connected to invalid blocks will be deleted.  They will need to be reactivated (remined) in order to add back to the lattice so they lost all the proof they provided so are incentivized to be especially careful where they connect.%0a
author:1664862751=
diff:1664862751:1664862713:=230c230%0a%3c !!Voting weight [[#weight]]%0a---%0a> !!Voting weight%0a
author:1664862713=
diff:1664862713:1664862186:=229,234d228%0a%3c %0a%3c !!Voting weight%0a%3c %0a%3c !!!Weighing function%0a%3c %0a%3c Each transaction's vote is weighted by the digit-length of the NTF.%0a
author:1664862186=
diff:1664862186:1664861844:=91c91%0a%3c #Proof of Proven Sieve ([[#props|Props]]) - Completed transaction signature (CTS), number to factor (NTF), two equal digit-length factors, and nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, Miners message, and then hashed to create the new NTF).%0a---%0a> #Proof of Proven Sieve ([[#props|Props]]) - Completed transaction signature (CTS), number to factor (NTF), nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, Miners message, and then hashed to create the new NTF), and 2 factors %0a
author:1664861844=
diff:1664861844:1664860552:=91,93c91%0a%3c #Proof of Proven Sieve ([[#props|Props]]) - Completed transaction signature (CTS), number to factor (NTF), nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, Miners message, and then hashed to create the new NTF), and 2 factors %0a%3c %0a%3c Or 1 factor to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable and not require caching.%0a---%0a> #Proof of Proven Sieve ([[#props|Props]]) - number to factor (NTF), nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, Miners message, and then hashed to create the new NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable and not require caching.%0a
author:1664860552=
diff:1664860552:1664860243:=43c43%0a%3c For some context 2 bonds checking 8 layers/levels down would be 256 transactions to verify, 4 bonds checking 4 levels down would be 256 transactions. Three bonds checking 5 levels would be 243 transactions.  Three bonds checking 7 levels would be 2187 transactions to check which seems reasonable.  A reorganization (reorg) effecting over 2000 transactions would be rare.%0a---%0a> For some context 2 bonds checking 8 layers/levels down would be 256 transactions to verify, 4 bonds checking 4 levels down would be 256 transactions. Three bonds checking 5 levels would be 243 transactions.  Three bonds checking 7 levels would be 2187 transactions to check which seems reasonable.%0a
author:1664860243=
diff:1664860243:1664859059:=47,49c47,49%0a%3c Consensus looks slightly different than Bitcoin, but it is even more rigorous. Bitcoin for one has to prevent double spending by using arbitrary timestamps. Actionlattice is more rigorous at preventing double spending (and privacy at the same time) by dictating that an address can only hold 1 bit and never be reused. Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain. In the same way nodes/miners need to verify the transactions in actionlattice and then accept the "heaviest" version (number of transactions x their bitlength weight = biggest). %0a%3c %0a%3c That said someone could attempt a double spend on two different "sides" of the lattice at once, and the "each transaction confirms 3 others and 7 levels down" wouldn't necessarily catch it immediately, but it would eventually. Actionlattice basically asks for a continuous rolling vote. Lets look at these two duplicate transactions sending to different addresses (double spend; they are trying to duplicate their cips). Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 3 transactions and it would be invalid if they vouched for a double spend. Now whichever of the two double spends gets the most "confirmations" is the winner. The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead. Also, every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified. So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend or otherwise invalid tx, and go several layers down from the tx's they are vouching for there is no double spend there either. It doesn't hurt the person making the nullified but valid transaction that was linked to the "bad" one, as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward. So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser. It would be a "rolling consensus".%0a---%0a> Consensus looks slightly different than Bitcoin, but it is just as rigorous. Bitcoin for one has to prevent double spending by using arbitrary timestamps. Actionlattice is more rigorous at preventing double spending (and privacy at the same time) by dictating that an address can only hold 1 bit and never be reused. Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain. In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. %0a> %0a> That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 3 others and 7 levels down" wouldn't necessarily catch it immediately, but it would eventually. Actionlattice basically asks for a continuous rolling vote. Lets look at these two transactions sending to different addresses (double spend). Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 3 transactions and it would be invalid if they vouched for a double spend. Now whichever of the two double spends gets the most "confirmations" is the winner. The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead. Also, every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified. So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend and several layers down from the tx's they are vouching for there is no double spend either. It doesn't hurt the person making the nullified but valid transaction that was linked to the "bad" one, as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward. So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser. It would be a "rolling consensus".%0a
author:1664859059=
diff:1664859059:1664858807:=47c47%0a%3c Consensus looks slightly different than Bitcoin, but it is just as rigorous. Bitcoin for one has to prevent double spending by using arbitrary timestamps. Actionlattice is more rigorous at preventing double spending (and privacy at the same time) by dictating that an address can only hold 1 bit and never be reused. Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain. In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. %0a---%0a> Consensus looks slightly different than Bitcoin, but it is just as rigorous. Bitcoin for one has to prevent double spending by using arbitrary timestamps. Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused. Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain. In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. %0a
author:1664858807=
diff:1664858807:1664858404:=188,190c188%0a%3c If it is in the lattice and is spent, it cannot be reused.  If the network as a whole forgets it then it can be reused.%0a%3c %0a%3c These bitlevels chosen by the miner do affect [[#consensus|consensus]] because transactions ruled invalid or connected to invalid blocks will be deleted.  They will need to be reactivated (remined) in order to add back to the lattice so they lost all the proof they provided so are incentivized to be especially careful where they connect.%0a---%0a> A deadpool of used addresses could be saved so they cannot be reused, but I think we forego that and just if it is in the lattice and is spent, it cannot be reused.  If the network as a whole forgets it then it can be reused.%0a
author:1664858404=
diff:1664858404:1664857993:=21c21%0a%3c Every transaction is free to propose, and then a miner (or you - if you mine your own tx) gets paid with a reward cip if they "activate" the proposed transaction using proof of semiprime (aka proof of sieve) ([[#posi|Posi]]) and point (connect) it to three other transactions that they validate and vouch for, preferably these three other transactions are near the "surface" but whose cip genesis is deep below the surface.  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", if it is not double spent or double mined, the transaction is valid, and if it is near the surface but the cip genesis is deep from the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a---%0a> Every transaction is free to propose, and then a miner (or you - if you mine your own tx) gets paid with a reward cip if they "activate" the proposed transaction using proof of semiprime (aka proof of sieve) ([[#posi|Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface" but whose cip genesis is deep below the surface.  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface but the cip genesis is deep from the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a
author:1664857993=
diff:1664857993:1664857740:=1c1%0a%3c (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain (1D) or blockDAG (2D).  It scales to infinite free and private transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], mining pools aren't necessary for miners to get constant rewards, tx can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine. Consensus is reached by an army of ants, an atomic, democratic, vote of factoring power:)%0a---%0a> (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain (1D) or blockDAG (2D).  It scales to infinite free and private transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], mining pools aren't necessary for miners to get constant rewards, tx can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664857740=
diff:1664857740:1664857633:=310c310%0a%3c The same transaction block, was mined twice with two different proofs.  This would never be done intentionally but we still face the possibility it happens. New transactions vote for which one happened first by bonding to them.  Once there is consensus then the looser and everyone that bonded to it is deleted.  This incentivizes new transactions to vote correctly (about which is valid).%0a---%0a> The same transaction block, was mined twice with two different proofs.  This would never be done intentionally but we still face the possibility it happens. New transactions vote for which one happened first by bonding to them.  Once there is consensus then the looser and everyone that bonded to it is deleted.  This incentivizes new transactions to vote correctly (on which is valid).%0a
author:1664857633=
diff:1664857633:1664857554:=310c310%0a%3c The same transaction block, was mined twice with two different proofs.  This would never be done intentionally but we still face the possibility it happens. New transactions vote for which one happened first by bonding to them.  Once there is consensus then the looser and everyone that bonded to it is deleted.  This incentivizes new transactions to vote correctly (on which is valid).%0a---%0a> The same transaction block, was mined twice with two different proofs.  This would never be done intentionally but we still face the possibility it happens.  %0a
author:1664857554=
diff:1664857554:1664856733:=302,310c302%0a%3c Duplicate transactions are allowed as long as they contain a different (usually higher) bitlevel proof.  If they have the same bitlevel proof then the latter one would be discarded by the node and should not be built on by other transactions.  This is also dis-incentivized because the loosing cipbase reward would be lost forever, and the work done lost.%0a%3c %0a%3c !!!!!Double spend%0a%3c %0a%3c The same cipbase addresses as another transaction are sent to different addresses, attempting to duplicate the original coins.  New transactions would vote for which they thought happened first, and the one with the most votes wins, the other looses and is deleted along with all the transactions that connected to (voted for) the bad transaction.  So they are incentivized to vote correctly (which is valid and which is not).%0a%3c %0a%3c !!!!!Double mine%0a%3c %0a%3c The same transaction block, was mined twice with two different proofs.  This would never be done intentionally but we still face the possibility it happens.  %0a---%0a> Duplicate transactions are allowed as long as they contain a different (usually higher) bitlevel proof.  If they have the same bitlevel proof then the latter one would be discarded by the node and should not be built on by other transactions.%0a
author:1664856733=
diff:1664856733:1664856679:=17c17%0a%3c It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using it to craft items.  It can also be used as an accounting ledger for transferring real or fictional assets.%0a---%0a> It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using it to craft items.%0a
author:1664856679=
diff:1664856679:1664856559:=16,17d15%0a%3c %0a%3c It can be used for any purpose, free and open source.  One interesting use-case is metaverse or other games using it to craft items.%0a
author:1664856559=
diff:1664856559:1664856345:=148,158c148,158%0a%3c %25orange%25110 digit is 30 mins%0a%3c %0a%3c %25orange%25105 digit is 15 mins%0a%3c %0a%3c %25orange%25100 digit is 8 mins%0a%3c %0a%3c %25orange%2595 digit is 4 mins%0a%3c %0a%3c %25orange%2590 digits is 2 mins%0a%3c %0a%3c %25orange%25Beta: 85 digits is 1 min%0a---%0a> %25yellow%25110 digit is 30 mins%0a> %0a> %25yellow%25105 digit is 15 mins%0a> %0a> %25yellow%25100 digit is 8 mins%0a> %0a> %25yellow%2595 digit is 4 mins%0a> %0a> %25yellow%2590 digits is 2 mins%0a> %0a> %25yellow%25Beta: 85 digits is 1 min%0a
author:1664856345=
diff:1664856345:1664854931:=205,206d204%0a%3c %0a%3c The genesis seeds the crystallization of the lattice.%0a
author:1664854931=
diff:1664854931:1664854699:=228,236c228,236%0a%3c !!!!Find unconfirmed transaction%0a%3c %0a%3c !!!!Create activation block attached to transaction%0a%3c %0a%3c !!!!Iterate nonce and hash the block to give random numbers%0a%3c %0a%3c !!!!Run ECM on candidate numbers and eliminate any non acceptable numbers%0a%3c %0a%3c !!!!Run GNFS on candidates to find a base-2 brilliant number (both factors have the same number of digits)%0a---%0a> #Find unconfirmed transaction%0a> %0a> #Create activation block attached to transaction%0a> %0a> #Iterate nonce and hash the block to give random numbers%0a> %0a> #Run ECM on candidate numbers and eliminate any non acceptable numbers%0a> %0a> #Run GNFS on candidates to find a base-2 brilliant number (both factors have the same number of digits)%0a
author:1664854699=
diff:1664854699:1664854617:=89c89%0a%3c #Proof of Proven Sieve ([[#props|Props]]) - number to factor (NTF), nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, Miners message, and then hashed to create the new NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable and not require caching.%0a---%0a> #Proof of Proven Sieve ([[#props|Props]]) - number to factor (NTF), nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, Miners message, and then hashed to create the new NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a
author:1664854617=
diff:1664854617:1664854409:=99c99%0a%3c This miner can provide a proof of semiprime which can be done on any transaction of any size for the same factoring cost.  Solve a 396 bit (or higher) challenge and you get to pick where the 3 bonds (prior art transactions) are directed.%0a---%0a> This miner can provide a proof of semiprime which can be done on any transaction of any size for the same factoring cost.  Solve a 396 bit (or higher) challenge and you get to pick where the 2 bonds (prior art transactions) are directed.%0a
author:1664854409=
diff:1664854409:1664854370:=87a88,89%0a> %0a> #Proof of Sieve/semiprime ([[#posi|Posi]]) message (Posim) - anything the miner wants to write.%0a
author:1664854370=
diff:1664854370:1664853793:=91,99c91,95%0a%3c #Proof of Proven Sieve ([[#props|Props]]) - number to factor (NTF), nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, Miners message, and then hashed to create the new NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a%3c %0a%3c **Peer blocks - 3 peer blocks NTFs (PNTFs, pronounced 'pontiffs') within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These two NTFs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a%3c %0a%3c **Bitbase address (aka cipbase address) which is the Miners public address (MPA) where the bitbase is sent.%0a%3c %0a%3c **Miner message (MM) - anything the miner wants to write within say 100 characters (needs to be limited because there are no checks & balances over the size, without a set limit).%0a%3c %0a%3c The reason why all of this data was hashed into the Number to Factor (NTF) is because the factor acts as a seal preventing a Man in the middle (MITM) attack that changes the cipbase address, miner message, or peer blocks.%0a---%0a> #Proof of Proven Sieve ([[#props|Props]]) - number to factor (NTF), nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, and hashed to create the new NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a> %0a> **Peer blocks - 2 peer blocks NTFs (PNTFs, pronounced 'pontiffs') within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These two NTFs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a> %0a> **Bitbase address (aka cipbase) which is the Miners public address (MPA) where the bitbase is sent.%0a
author:1664853793=
diff:1664853793:1664852115:=93,95c93,95%0a%3c **Peer blocks - 2 peer blocks NTFs (PNTFs, pronounced 'pontiffs') within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These two NTFs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a%3c %0a%3c **Bitbase address (aka cipbase) which is the Miners public address (MPA) where the bitbase is sent.%0a---%0a> #Peer blocks - 2 peer blocks NTFs (PNTFs, pronounced 'pontiffs') within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These two NTFs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a> %0a> #Bitbase address (aka cipbase) which is the Miners public address (MPA) where the bitbase is sent.%0a
author:1664852115=
diff:1664852115:1664848375:=224,234d223%0a%3c Miner software will need:%0a%3c %0a%3c #Find unconfirmed transaction%0a%3c %0a%3c #Create activation block attached to transaction%0a%3c %0a%3c #Iterate nonce and hash the block to give random numbers%0a%3c %0a%3c #Run ECM on candidate numbers and eliminate any non acceptable numbers%0a%3c %0a%3c #Run GNFS on candidates to find a base-2 brilliant number (both factors have the same number of digits)%0a
author:1664848375=
diff:1664848375:1664848306:=219,224d218%0a%3c %0a%3c !!Software design%0a%3c %0a%3c !!!Miner%0a%3c %0a%3c !!!Node%0a
author:1664848306=
diff:1664848306:1664830482:=294,295d293%0a%3c %0a%3c !!!!!Double spend%0a
author:1664830482=
diff:1664830482:1664830234:=45,47c45%0a%3c Consensus looks slightly different than Bitcoin, but it is just as rigorous. Bitcoin for one has to prevent double spending by using arbitrary timestamps. Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused. Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain. In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. %0a%3c %0a%3c That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 3 others and 7 levels down" wouldn't necessarily catch it immediately, but it would eventually. Actionlattice basically asks for a continuous rolling vote. Lets look at these two transactions sending to different addresses (double spend). Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 3 transactions and it would be invalid if they vouched for a double spend. Now whichever of the two double spends gets the most "confirmations" is the winner. The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead. Also, every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified. So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend and several layers down from the tx's they are vouching for there is no double spend either. It doesn't hurt the person making the nullified but valid transaction that was linked to the "bad" one, as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward. So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser. It would be a "rolling consensus".%0a---%0a> Consensus looks slightly different than Bitcoin, but it is just as rigorous. Bitcoin for one has to prevent double spending by using arbitrary timestamps. Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused. Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain. In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 2 others and levels down" wouldn't necessarily catch it. Alright so I think I have a pretty good grasp of it. So lets increase it to every transaction must attach to (vouch for) 4 transactions instead of 2 just to increase the robustness. So what this does is basically ask for a continuous rolling vote. Lets say there are two transactions sending to different addresses (double spend). Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 4 transactions and it would be invalid if they vouched for a double spend. Now whichever of the two double spends gets the most "confirmations" is the winner. The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead. Also every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified. So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend and several layers down from the tx's they are vouching for there is no double spend either. It doesn't hurt the person making the transaction as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward. So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser. Rolling consensus.%0a
author:1664830234=
diff:1664830234:1664830211:=299c299%0a%3c #Consensus: See also [[#consensus|consensus]]. Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by using arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 2 others and levels down" wouldn't necessarily catch it. Alright so I think I have a pretty good grasp of it.  So lets increase it to every transaction must attach to (vouch for) 4 transactions instead of 2 just to increase the robustness.  So what this does is basically ask for a continuous rolling vote.  Lets say there are two transactions sending to different addresses (double spend).  Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 4 transactions and it would be invalid if they vouched for a double spend.  Now whichever of the two double spends gets the most "confirmations" is the winner.  The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead.  Also every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified.  So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend and several layers down from the tx's they are vouching for there is no double spend either.  It doesn't hurt the person making the transaction as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward.  So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser.  Rolling consensus.%0a---%0a> #Consensus: Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by using arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 2 others and levels down" wouldn't necessarily catch it. Alright so I think I have a pretty good grasp of it.  So lets increase it to every transaction must attach to (vouch for) 4 transactions instead of 2 just to increase the robustness.  So what this does is basically ask for a continuous rolling vote.  Lets say there are two transactions sending to different addresses (double spend).  Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 4 transactions and it would be invalid if they vouched for a double spend.  Now whichever of the two double spends gets the most "confirmations" is the winner.  The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead.  Also every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified.  So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend and several layers down from the tx's they are vouching for there is no double spend either.  It doesn't hurt the person making the transaction as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward.  So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser.  Rolling consensus.%0a
author:1664830211=
diff:1664830211:1664830194:=43c43%0a%3c !!Consensus [[#consensus]]%0a---%0a> !!Consensus%0a
author:1664830194=
diff:1664830194:1664830063:=42,45d41%0a%3c %0a%3c !!Consensus%0a%3c %0a%3c Consensus looks slightly different than Bitcoin, but it is just as rigorous. Bitcoin for one has to prevent double spending by using arbitrary timestamps. Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused. Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain. In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 2 others and levels down" wouldn't necessarily catch it. Alright so I think I have a pretty good grasp of it. So lets increase it to every transaction must attach to (vouch for) 4 transactions instead of 2 just to increase the robustness. So what this does is basically ask for a continuous rolling vote. Lets say there are two transactions sending to different addresses (double spend). Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 4 transactions and it would be invalid if they vouched for a double spend. Now whichever of the two double spends gets the most "confirmations" is the winner. The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead. Also every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified. So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend and several layers down from the tx's they are vouching for there is no double spend either. It doesn't hurt the person making the transaction as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward. So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser. Rolling consensus.%0a
author:1664830063=
diff:1664830063:1664829955:=59,60d58%0a%3c %0a%3c In Nano they achieve double spending protection by each address having it's own blockchain.  In actionlattice there is a global "blockchain" and we achieve double spending protection by having each address only able to hold 1 bit and once it is sent the address can no longer be used (destroyed).%0a
author:1664829955=
diff:1664829955:1664829841:=50c50%0a%3c This is about the only similarity between block-lattice and actionlattice.  I wasn't aware this is what nano did prior to designing actionlattice so this confirms it is a good choice and resembles what is done in nature.  Actionlattice however will probably have each transactions verify 3 others and you also check 7 levels down, 3^7 transactions you check which is around 2,000.  In Nano, you really only check 2.%0a---%0a> This is about the only similarity between block-lattice and actionlattice.  I wasn't aware this is what nano did prior to designing actionlattice so this confirms it is a good choice and resembles what is done in nature.%0a
author:1664829841=
diff:1664829841:1664829043:=41c41%0a%3c For some context 2 bonds checking 8 layers/levels down would be 256 transactions to verify, 4 bonds checking 4 levels down would be 256 transactions. Three bonds checking 5 levels would be 243 transactions.  Three bonds checking 7 levels would be 2187 transactions to check which seems reasonable.%0a---%0a> For some context 2 bonds checking 8 layers/levels down would be 256 transactions to verify, 4 bonds checking 4 levels down would be 256 transactions. 3 bonds checking 5 levels would be 243 transactions.%0a
author:1664829043=
diff:1664829043:1664828988:=198c198%0a%3c In the 3 bond case there would be a 4 transaction genesis.%0a---%0a> In the 4 bond case there would be a five transaction genesis.%0a
author:1664828988=
diff:1664828988:1664827785:=199,200d198%0a%3c %0a%3c Attach:3genesis.png%0a
author:1664827785=
diff:1664827785:1664827017:=39,41c39,41%0a%3c In the examples here we use 2 bonds per transaction but this can be any number set by the network.  The more bonds you require the faster there will be consensus/convergence but also the more time it will take each miner to activate a transaction.  Also the number of levels down the miner verifies will also add to the time.  Somewhere between 2-10 bonds would probably be ideal and over time this number can even be increased as computers get faster at verifying transactions (due to moores law). I think I would pick 3 bonds.%0a%3c %0a%3c For some context 2 bonds checking 8 layers/levels down would be 256 transactions to verify, 4 bonds checking 4 levels down would be 256 transactions. 3 bonds checking 5 levels would be 243 transactions.%0a---%0a> In the examples here we use 2 bonds per transaction but this can be any number set by the network.  The more bonds you require the faster there will be consensus/convergence but also the more time it will take each miner to activate a transaction.  Also the number of levels down the miner verifies will also add to the time.  Somewhere between 2-10 bonds would probably be ideal and over time this number can even be increased as computers get faster at verifying transactions (due to moores law). I think I would pick 4 bonds to start.%0a> %0a> For some context 2 bonds checking 7 layers/levels down would be 128 transactions to verify, 4 bonds checking 4 levels down would be 256 transactions.%0a
author:1664827017=
diff:1664827017:1664826927:=197,198d196%0a%3c %0a%3c In the 4 bond case there would be a five transaction genesis.%0a
author:1664826927=
diff:1664826927:1664826862:=41c41%0a%3c For some context 2 bonds checking 7 layers/levels down would be 128 transactions to verify, 4 bonds checking 4 levels down would be 256 transactions.%0a---%0a> For some context 2 bonds checking 7 layers down would be 128 transactions to verify, 4 bonds checking 4 levels down would be 256 transactions.%0a
author:1664826862=
diff:1664826862:1664826730:=41d40%0a%3c For some context 2 bonds checking 7 layers down would be 128 transactions to verify, 4 bonds checking 4 levels down would be 256 transactions.%0a
author:1664826730=
diff:1664826730:1664826594:=39c39%0a%3c In the examples here we use 2 bonds per transaction but this can be any number set by the network.  The more bonds you require the faster there will be consensus/convergence but also the more time it will take each miner to activate a transaction.  Also the number of levels down the miner verifies will also add to the time.  Somewhere between 2-10 bonds would probably be ideal and over time this number can even be increased as computers get faster at verifying transactions (due to moores law). I think I would pick 4 bonds to start.%0a---%0a> In the examples here we use 2 bonds per transaction but this can be any number set by the network.  The more bonds you require the faster there will be consensus/convergence but also the more time it will take each miner to activate a transaction.  Also the number of levels down the miner verifies will also add to the time.  Somewhere between 2-10 bonds would probably be ideal and over time this number can even be increased as computers get faster at verifying transactions (due to moores law).%0a
author:1664826594=
diff:1664826594:1664826334:=36,39d35%0a%3c %0a%3c !!Number of bonds%0a%3c %0a%3c In the examples here we use 2 bonds per transaction but this can be any number set by the network.  The more bonds you require the faster there will be consensus/convergence but also the more time it will take each miner to activate a transaction.  Also the number of levels down the miner verifies will also add to the time.  Somewhere between 2-10 bonds would probably be ideal and over time this number can even be increased as computers get faster at verifying transactions (due to moores law).%0a
author:1664826334=
diff:1664826334:1664826167:=284c284%0a%3c #Consensus: Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by using arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 2 others and levels down" wouldn't necessarily catch it. Alright so I think I have a pretty good grasp of it.  So lets increase it to every transaction must attach to (vouch for) 4 transactions instead of 2 just to increase the robustness.  So what this does is basically ask for a continuous rolling vote.  Lets say there are two transactions sending to different addresses (double spend).  Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 4 transactions and it would be invalid if they vouched for a double spend.  Now whichever of the two double spends gets the most "confirmations" is the winner.  The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead.  Also every transaction later that vouched for the "bad" one also gets removed (reversed) and the cipbase also nullified.  So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend and several layers down from the tx's they are vouching for there is no double spend either.  It doesn't hurt the person making the transaction as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward.  So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser.  Rolling consensus.%0a---%0a> #Consensus: Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by using arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 2 others and levels down" wouldn't necessarily catch it. Alright so I think I have a pretty good grasp of it.  So lets increase it to every transaction must attach to (vouch for) 4 transactions instead of 2 just to increase the robustness.  So what this does is basically ask for a continuous rolling vote.  Lets say there are two transactions sending to different addresses (double spend).  Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 4 transactions and it would be invalid if they vouched for a double spend.  Now whichever of the two double spends gets the most "confirmations" is the winner.  The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead.  Also every transaction later that vouched for the "bad" one also gets removed (reversed) and the coinbase also nullified.  So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend or several layers down there is no double spend.  It doesn't hurt the person making the transaction as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward.  So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser.  Rolling consensus.%0a
author:1664826167=
diff:1664826167:1664824510:=284c284%0a%3c #Consensus: Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by using arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 2 others and levels down" wouldn't necessarily catch it. Alright so I think I have a pretty good grasp of it.  So lets increase it to every transaction must attach to (vouch for) 4 transactions instead of 2 just to increase the robustness.  So what this does is basically ask for a continuous rolling vote.  Lets say there are two transactions sending to different addresses (double spend).  Now the other miners vote on which is correct by vouching for only one of them, obviously since they can only vote for 4 transactions and it would be invalid if they vouched for a double spend.  Now whichever of the two double spends gets the most "confirmations" is the winner.  The one with less confirmations gets deleted by the nodes once they feel it has no chance of pulling ahead.  Also every transaction later that vouched for the "bad" one also gets removed (reversed) and the coinbase also nullified.  So this incentivizes every miner to validate all transactions to make sure they aren't vouching for a double spend or several layers down there is no double spend.  It doesn't hurt the person making the transaction as they can just rebroadcast it with no problem, but the original miner of the tx would have lost their reward.  So I think the idea is sound. I think this works because only 1 of the double spends will win the most confirmations and the vote will keep getting more and more polarized because miners don't want to attach to what seems to be the looser.  Rolling consensus.%0a---%0a> #Consensus: Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by using arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 2 others and levels down" wouldn't necessarily catch it.%0a
author:1664824510=
diff:1664824510:1664820430:=284c284%0a%3c #Consensus: Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by using arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most transactions verified at a given bitlevel, that contains only valid transactions. That said someone could attempt a double spend on two different "sides" of the lattice at once and the "each transaction confirms 2 others and levels down" wouldn't necessarily catch it.%0a---%0a> #Consensus: Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by using arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most tratransactions verified at a given bitlevel, that contains only valid transactions.%0a
author:1664820430=
diff:1664820430:1664820190:=48,51d47%0a%3c %0a%3c !!!!Two party transactions%0a%3c %0a%3c In nano both parties have to sign for a transaction.  Actionlattice only the sender has to sign, just kike standard blockchain. This is important because signing gives up security. Actionlattice goes above standard Blockchain security and ensures an address "breaks" after it signs and cannot be reused in order to preserve 100%25 maximum security.%0a
author:1664820190=
diff:1664820190:1664819708:=41,42d40%0a%3c Nano uses a block-lattice and DAG and since the words are similar it is good to compare and contrast it with actionlattice.%0a%3c %0a44,47d41%0a%3c %0a%3c This is about the only similarity between block-lattice and actionlattice.  I wasn't aware this is what nano did prior to designing actionlattice so this confirms it is a good choice and resembles what is done in nature.%0a%3c %0a%3c How it differs: in nano you only have to verify those transactions are valid.  In actionlattice you need to verify around 7 levels down, so 128 transactions.  If any transaction below you connected to you is invalid you risk your transaction reverting as well.  So the miner of the transaction (which can be you) incentivized to validate as far down as possible because the validity of their reward counts on it.  The person who made the transaction does not need to care very much because if it does get removed it can just be added back and there is no loss, nor theft, nor double spending because of the design of actionlattice.%0a
author:1664819708=
diff:1664819708:1664819597:=40,45d39%0a%3c %0a%3c !!!!Transactions validate 2 others%0a%3c %0a%3c !!!!Individual blockchains%0a%3c %0a%3c !!!!Double spending%0a
author:1664819597=
diff:1664819597:1664725526:=36,43d35%0a%3c %0a%3c !!Comparisons%0a%3c %0a%3c !!!Nano%0a%3c %0a%3c !!!Bitlattice%0a%3c %0a%3c !!!Blockchain%0a
author:1664725526=
diff:1664725526:1664725458:=177c177%0a%3c Previously I had thought of requiring that the smallest of the two factors of the semiprime being 40%25 (0.4x) of the bitlength to mostly preclude GPU's and ECM asics but only require 1 GNFS sieve to activate the transaction.  Now however (after contemplating Fact0rn) I think I will make it both factors have to be the same number of bits.  This will mean a couple dozen GNFS' will have to be done in order to activate the transaction.  The reason for doing this is to make it if multiple people are working on the same transaction that their is a more random chance of who wins it.  Also so that we don't have to worry about GPU's being able to ECM farther or the like and I don't want to ever have to change this setting.%0a---%0a> Previously I had thought of requiring that the smallest of the two factors of the semiprime being 40%25 (0.4x) of the bitlength to mostly preclude GPU's and ECM asics but only require 1 GNFS sieve to activate the transaction.  Now however I think I will make it both factors have to be the same number of bits.  This will mean a couple dozen GNFS' will have to be done in order to activate the transaction.  The reason for doing this is to make it if multiple people are working on the same transaction that their is a more random chance of who wins it.  Also so that we don't have to worry about GPU's being able to ECM farther or the like and I don't want to ever have to change this setting.%0a
author:1664725458=
diff:1664725458:1664724895:=176,177d175%0a%3c %0a%3c Previously I had thought of requiring that the smallest of the two factors of the semiprime being 40%25 (0.4x) of the bitlength to mostly preclude GPU's and ECM asics but only require 1 GNFS sieve to activate the transaction.  Now however I think I will make it both factors have to be the same number of bits.  This will mean a couple dozen GNFS' will have to be done in order to activate the transaction.  The reason for doing this is to make it if multiple people are working on the same transaction that their is a more random chance of who wins it.  Also so that we don't have to worry about GPU's being able to ECM farther or the like and I don't want to ever have to change this setting.%0a
author:1664724895=
diff:1664724895:1664724592:=145a146,147%0a> %0a> Cipbases on the alpha lattice can be spent on the alpha lattice, cipbases on the beta lattice can be spent on the beta lattice, etc.%0a
author:1664724592=
diff:1664724592:1664724539:=145c145%0a%3c These are not hard and fast rules just rough categories of difficulty.  Light nodes would probably save delta and gamma, fast strong nodes would save all of the transactions including alpha. As the times to complete a given challenge become faster, lower bitlevel proofs can be pruned (which would need to be re-mined at a higher bitlevel to not disappear) and/or future proofs will need to be a higher bitlevel.%0a---%0a> These are not hard and fast rules just rough categories of difficulty.  Light nodes would probably save delta and gamma, fast strong nodes would save all of the transactions including alpha. As the times to complete a given challenge become faster, lower bitlevel proofs can be pruned (which would need to be remined at a higher bitlevel) and/or future proofs will need to be a higher bitlevel.%0a
author:1664724539=
diff:1664724539:1664724425:=145c145%0a%3c These are not hard and fast rules just rough categories of difficulty.  Light nodes would probably save delta and gamma, fast strong nodes would save all of the transactions including alpha. As the times to complete a given challenge become faster, lower bitlevel proofs can be pruned (which would need to be remined at a higher bitlevel) and/or future proofs will need to be a higher bitlevel.%0a---%0a> These are not hard and fast rules just rough categories of difficulty.  Light nodes would probably save delta and gamma, fast strong nodes would save all of the transactions including alpha. As the times to complete a given challenge become faster, lower bitlevel proofs can be pruned and/or future proofs will need to be a higher bitlevel.%0a
author:1664724425=
diff:1664724425:1664724386:=81c81%0a%3c !!!Time standard bitlevels (based on year 2022) [[#time]]%0a---%0a> !!!Time standard (based on year 2022) [[#time]]%0a
author:1664724386=
diff:1664724386:1664724131:=145c145,146%0a%3c These are not hard and fast rules just rough categories of difficulty.  Light nodes would probably save delta and gamma, fast strong nodes would save all of the transactions including alpha. As the times to complete a given challenge become faster, lower bitlevel proofs can be pruned and/or future proofs will need to be a higher bitlevel.%0a---%0a> Once 10%25 of the lattice is one step above the top, then the whole lattice moves up one step and all cipbases below that proof level that has now fallen off the level and need to be re-mined (on whatever level you want it to be on).  %0a> ->For example if 10%25 of the Alpha lattice is mined at 85 digit proof level, then the 55 digit proof level transactions fall off and need to be re-mined at a higher proof level.%0a
author:1664724131=
diff:1664724131:1664723874:=150c150%0a%3c A deadpool of used addresses could be saved so they cannot be reused, but I think we forego that and just if it is in the lattice and is spent, it cannot be reused.  If the network as a whole forgets it then it can be reused.%0a---%0a> A deadpool of used addresses will be saved so they cannot be reused.%0a
author:1664723874=
diff:1664723874:1664723514:=261c261%0a%3c #Consensus: Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by using arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most tratransactions verified at a given bitlevel, that contains only valid transactions.%0a---%0a> #Consensus: Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most tratransactions verified at a given bitlevel, that contains only valid transactions.%0a
author:1664723514=
diff:1664723514:1664723205:=259,262c259,262%0a%3c #Fungibility: The main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  Using a UTXO we could peg the value of 1 cip = 1 cip forever, but I tend to want completing a higher bitlength proof to be more valuable than a small proof, which also means we can get faster initial confirmations (since they are small proofs, larger proofs can come later).%0a%3c %0a%3c #Consensus: Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most tratransactions verified at a given bitlevel, that contains only valid transactions.%0a%3c %0a---%0a> #But the main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  Using a UTXO we could peg the value of 1 cip = 1 cip forever, but I tend to want completing a higher bitlength proof to be more valuable than a small proof, which also means we can get faster initial confirmations (since they are small proofs, larger proofs can come later).%0a> %0a> #Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most tratransactions verified at a given bitlevel, that contains only valid transactions.%0a> %0a265c265%0a%3c #Size: Having no transaction size limit is a downside because different nodes will have different requirements, but GRIN also uses a similar method for node settings which is more democratic and less centrally planned.%0a---%0a> #Also having no transaction size limit is a downside because different nodes will have different requirements, but GRIN also uses a similar method for node settings which is more democratic and less centrally planned.%0a
author:1664723205=
diff:1664723205:1664723162:=132,133d131%0a%3c %0a%3c This can all be on one lattice%0a
author:1664723162=
diff:1664723162:1664722536:=133,139c133,139%0a%3c Purple is the Delta difficulty%0a%3c %0a%3c Green is the Gamma difficulty%0a%3c %0a%3c Yellow is the Beta difficulty%0a%3c %0a%3c Red is the Alpha difficulty%0a---%0a> Purple is the Delta lattice%0a> %0a> Green is the Gamma lattice%0a> %0a> Yellow is the Beta lattice%0a> %0a> Red is the Alpha lattice%0a
author:1664722536=
diff:1664722536:1664722493:=144c144%0a%3c ->For example if 10%25 of the Alpha lattice is mined at 85 digit proof level, then the 55 digit proof level transactions fall off and need to be re-mined at a higher proof level.%0a---%0a> ->For example if 10%25 of the Alpha lattice is mined at 85 digit proof level, then the 55 digit proof level transactions fall off and need to be remoned at a higher proof level.%0a
author:1664722493=
diff:1664722493:1664722313:=143,144c143%0a%3c Once 10%25 of the lattice is one step above the top, then the whole lattice moves up one step and all cipbases below that proof level that has now fallen off the level and need to be re-mined (on whatever level you want it to be on).  %0a%3c ->For example if 10%25 of the Alpha lattice is mined at 85 digit proof level, then the 55 digit proof level transactions fall off and need to be remoned at a higher proof level.%0a---%0a> Once 10%25 of the lattice is one step above the top, then the whole lattice moves up one step and all cipbases below that proof level that has now fallen off the level and need to be re-mined (on whatever level you want it to be on)%0a
author:1664722313=
diff:1664722313:1664722281:=82,83d81%0a%3c %0a%3c See also [[#diff|difficulty]]%0a
author:1664722281=
diff:1664722281:1664722241:=168,169d167%0a%3c %0a%3c See also [[#time|time standard]]%0a
author:1664722241=
diff:1664722241:1664722120:=81c81%0a%3c !!!Time standard (based on year 2022) [[#time]]%0a---%0a> !!!Time standard (based on year 2022)%0a
author:1664722120=
diff:1664722120:1664721941:=144,145d143%0a%3c %0a%3c A deadpool of used addresses will be saved so they cannot be reused.%0a
author:1664721941=
diff:1664721941:1664721769:=142,143d141%0a%3c %0a%3c Cipbases on the alpha lattice can be spent on the alpha lattice, cipbases on the beta lattice can be spent on the beta lattice, etc.%0a
author:1664721769=
diff:1664721769:1664721300:=138,139d137%0a%3c %0a%3c !!!!Explanation%0a
author:1664721300=
diff:1664721300:1664720772:=131,139d130%0a%3c Purple is the Delta lattice%0a%3c %0a%3c Green is the Gamma lattice%0a%3c %0a%3c Yellow is the Beta lattice%0a%3c %0a%3c Red is the Alpha lattice%0a%3c %0a%3c Once 10%25 of the lattice is one step above the top, then the whole lattice moves up one step and all cipbases below that proof level that has now fallen off the level and need to be re-mined (on whatever level you want it to be on)%0a
author:1664720772=
diff:1664720772:1664720340:=81c81%0a%3c !!!Time standard (based on year 2022)%0a---%0a> !!!Time standard%0a
author:1664720340=
diff:1664720340:1664719999:=82,91d81%0a%3c %0a%3c %25purple%25170 digit is 4 months%0a%3c %0a%3c %25purple%25165 digit is 2 months%0a%3c %0a%3c %25purple%25160 digit is 1 month%0a%3c %0a%3c %25purple%25155 digit is 2 week%0a%3c %0a%3c %25purple%25150 digit is 1 week%0a
author:1664719999=
diff:1664719999:1664719637:=85,94c85,94%0a%3c %25green%25140 digit is 30 hour%0a%3c %0a%3c %25green%25135 digit is 15 hour%0a%3c %0a%3c %25green%25130 digit is 8 hour%0a%3c %0a%3c %25green%25125 digit is 4 hour%0a%3c %0a%3c %25green%25120 digit is 2 hour%0a%3c %0a---%0a> %25lightpurple%25140 digit is 30 hour%0a> %0a> 135 digit is 15 hour%0a> %0a> 130 digit is 8 hour%0a> %0a> 125 digit is 4 hour%0a> %0a> 120 digit is 2 hour%0a> %0a97,106c97,106%0a%3c %25yellow%25110 digit is 30 mins%0a%3c %0a%3c %25yellow%25105 digit is 15 mins%0a%3c %0a%3c %25yellow%25100 digit is 8 mins%0a%3c %0a%3c %25yellow%2595 digit is 4 mins%0a%3c %0a%3c %25yellow%2590 digits is 2 mins%0a%3c %0a---%0a> 110 digit is 30 mins%0a> %0a> 105 digit is 15 mins%0a> %0a> 100 digit is 8 mins%0a> %0a> 95 digit is 4 mins%0a> %0a> 90 digits is 2 mins%0a> %0a109,117c109,117%0a%3c %25red%2580 digits is 30 sec%0a%3c %0a%3c %25red%2575 digits is 15 seconds%0a%3c %0a%3c %25red%2570 digits is 8 seconds%0a%3c %0a%3c %25red%2565 digits is 4 seconds%0a%3c %0a%3c %25red%2560 digits is 2 seconds%0a---%0a> 80 digits is 30 sec%0a> %0a> 75 digits is 15 seconds%0a> %0a> 70 digits is 8 seconds%0a> %0a> 65 digits is 4 seconds%0a> %0a> 60 digits is 2 seconds%0a
author:1664719637=
diff:1664719637:1664719372:=85c85%0a%3c %25lightpurple%25140 digit is 30 hour%0a---%0a> 140 digit is 30 hour%0a
author:1664719372=
diff:1664719372:1664719341:=83c83%0a%3c %25purple%25Delta: 145 digit is 60 hour%0a---%0a> %25blue%25Delta: 145 digit is 60 hour%0a
author:1664719341=
diff:1664719341:1664719047:=81,93c81%0a%3c !!!Time standard%0a%3c %0a%3c %25blue%25Delta: 145 digit is 60 hour%0a%3c %0a%3c 140 digit is 30 hour%0a%3c %0a%3c 135 digit is 15 hour%0a%3c %0a%3c 130 digit is 8 hour%0a%3c %0a%3c 125 digit is 4 hour%0a%3c %0a%3c 120 digit is 2 hour%0a---%0a> !!!Time standards%0a
author:1664719047=
diff:1664719047:1664718998:=83,84c83,84%0a%3c %25green%25Gamma: 115 digit is 1 hour%0a%3c %0a---%0a> Gamma: 115 digit is 1 hour%0a> %0a95,96c95,96%0a%3c %25yellow%25Beta: 85 digits is 1 min%0a%3c %0a---%0a> Beta: 85 digits is 1 min%0a> %0a107c107%0a%3c %25red%25Alpha: 55 digits is 1 second%0a---%0a> Alpha: 55 digits is 1 second%0a
author:1664718998=
diff:1664718998:1664687809:=80,107d79%0a%3c %0a%3c !!!Time standards%0a%3c %0a%3c Gamma: 115 digit is 1 hour%0a%3c %0a%3c 110 digit is 30 mins%0a%3c %0a%3c 105 digit is 15 mins%0a%3c %0a%3c 100 digit is 8 mins%0a%3c %0a%3c 95 digit is 4 mins%0a%3c %0a%3c 90 digits is 2 mins%0a%3c %0a%3c Beta: 85 digits is 1 min%0a%3c %0a%3c 80 digits is 30 sec%0a%3c %0a%3c 75 digits is 15 seconds%0a%3c %0a%3c 70 digits is 8 seconds%0a%3c %0a%3c 65 digits is 4 seconds%0a%3c %0a%3c 60 digits is 2 seconds%0a%3c %0a%3c Alpha: 55 digits is 1 second%0a
author:1664687809=
diff:1664687809:1664687650:=189c189%0a%3c #Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid, and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most tratransactions verified at a given bitlevel, that contains only valid transactions.%0a---%0a> #Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most tratransactions verified at a given bitlevel, that contains only valid transactions.%0a
author:1664687650=
diff:1664687650:1664687261:=189,191c189,191%0a%3c #Consensus looks slightly different than Bitcoin, but it is just as rigorous.  Bitcoin for one has to prevent double spending by arbitrary timestamps.  Actionlattice is more rigorous at preventing double spending by dictating that an address can only hold 1 bit and never be reused.  Bitcoin miners/nodes still have to verify that the longest chain is valid and if not, then accept a less long but valid chain.  In the same way nodes/miners need to verify the transactions in actionlattice and then accept the most "voluminous" version (version of the lattice with the most tratransactions verified at a given bitlevel, that contains only valid transactions.%0a%3c %0a%3c **A help previous for the above two is to have different genesi lattices, Alpha for low bitlength proof, Beta for medium bitlength proof, Gamma for high bitlength proof.  so a gamma cip would always hold the same value, as would a beta or alpha cip.  The downside to this solution is there isn't infinitely variable bitlength that can be rewarded so we really wouldn't know how high a proof level could be without trying it.  So in this example alpha might start at 80 digit proof, then next year might be 82 digit proof, next year 84 digit proof etc.  So one alpha cip will always equal 1 alpha cip.  Problem is we don't know how fast we can raise that bitlevel proof requirement (which is set by each individual node) since there is no incentive for miners to go above and beyond.%0a---%0a> #Another downside is we don't force a consensus between nodes (but we could if we wanted since the lattice is fully auditable), and if we did force consensus it would probably be at the 20-min-semiprime-proof level.  Below that it will be fluid and no consensus would be forced between nodes (most likely, to allow flexibility with what nodes save and accept - it's own custom pruning method).  Bitcoin has to be a timestamp server, basically every miner includes a timestamp on each block that is not rigorously defined.  Nodes have to look and see if they accept the block because the timestamp is about what they think it should be.  Then the "longest chain" decides.  The problem is the longest chain can be wrong and then what do the nodes do?  They have to go along with it.  In actionlattice we don't need a timestamp server because nothing can be double spent by design.  So then instead of the nodes verifying that the time looks right they can verify all the transactions are correct and accept it.  People adding new transactions onto old ones means that the miners are voting they are correct.%0a> %0a> **A way around both previous downsides is to have different genesi lattices, Alpha for low bitlength proof, Beta for medium bitlength proof, Gamma for high bitlength proof.  so a gamma cip would always hold the same value, as would a beta or alpha cip.  The downside to this solution is there isn't infinitely variable bitlength that can be rewarded so we really wouldn't know how high a proof level could be without trying it.  So in this example alpha might start at 80 digit proof, then next year might be 82 digit proof, next year 84 digit proof etc.  So one alpha cip will always equal 1 alpha cip.  Problem is we don't know how fast we can raise that bitlevel proof requirement (which is set by each individual node) since there is no incentive for miners to go above and beyond.%0a
author:1664687261=
diff:1664687261:1664685268:=189c189%0a%3c #Another downside is we don't force a consensus between nodes (but we could if we wanted since the lattice is fully auditable), and if we did force consensus it would probably be at the 20-min-semiprime-proof level.  Below that it will be fluid and no consensus would be forced between nodes (most likely, to allow flexibility with what nodes save and accept - it's own custom pruning method).  Bitcoin has to be a timestamp server, basically every miner includes a timestamp on each block that is not rigorously defined.  Nodes have to look and see if they accept the block because the timestamp is about what they think it should be.  Then the "longest chain" decides.  The problem is the longest chain can be wrong and then what do the nodes do?  They have to go along with it.  In actionlattice we don't need a timestamp server because nothing can be double spent by design.  So then instead of the nodes verifying that the time looks right they can verify all the transactions are correct and accept it.  People adding new transactions onto old ones means that the miners are voting they are correct.%0a---%0a> #Another downside is we don't force a consensus between nodes (but we could if we wanted since the lattice is fully auditable), and if we did force consensus it would probably be at the 20-min-semiprime-proof level.  Below that it will be fluid and no consensus would be forced between nodes (most likely, to allow flexibility with what nodes save and accept - it's own custom pruning method).  %0a
author:1664685268=
diff:1664685268:1664685149:=213c213%0a%3c Anders post Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] [[ https://bitcointalk.org/index.php?topic=738297.msg8352090#msg8352090|#]] bitcoin can enter a time warp creating the next dark age where large of chunks of history are forgotten. [[PoH]] may be a potential solution. Actionlattice doesn't need to worry about timestamps to dictate the "earliest transaction" because every unit can only be sent once so any version of that transaction is valid.%0a---%0a> Anders post Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] [[ https://bitcointalk.org/index.php?topic=738297.msg8352090#msg8352090|#]] bitcoin can enter a time warp creating the next dark age where large of chunks of history are forgotten. [[PoH]] may be a potential solution.%0a
author:1664685149=
diff:1664685149:1664683998:=213c213%0a%3c Anders post Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] [[ https://bitcointalk.org/index.php?topic=738297.msg8352090#msg8352090|#]] bitcoin can enter a time warp creating the next dark age where large of chunks of history are forgotten. [[PoH]] may be a potential solution.%0a---%0a> Anders post Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] bitcoin can enter a time warp creating the next dark age where large of chunks of history are forgotten. [[PoH]] may be a potential solution.%0a
author:1664683998=
diff:1664683998:1664683870:=213c213%0a%3c Anders post Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] bitcoin can enter a time warp creating the next dark age where large of chunks of history are forgotten. [[PoH]] may be a potential solution.%0a---%0a> Anders post Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] bitcoin can enter a time warp creating the next dark age where large of chunks of history are forgotten.%0a
author:1664683870=
diff:1664683870:1664682937:=241,246d240%0a%3c %0a%3c Anders Rule 30 as a hash function [[https://bitcointalk.org/index.php?topic=698460.0|#]]%0a%3c %0a%3c Anders tail emission [[https://bitcointalk.org/index.php?topic=725427.0|#]]%0a%3c %0a%3c Anders bitcoin price will stabilize over time due to arbitrage [[https://bitcointalk.org/index.php?topic=737671.0|#]]%0a
author:1664682937=
diff:1664682937:1664682896:=213c213%0a%3c Anders post Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] bitcoin can enter a time warp creating the next dark age where large of chunks of history are forgotten.%0a---%0a> Anders post Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] bitcoin can enter a time warp creating the next darkage where large of chunks of history are forgotten.%0a
author:1664682896=
diff:1664682896:1664682871:=229c229%0a%3c [[NatureVault/Digital collectible network#mine]]%0a---%0a> [[NatureVault/Digital collectible currency]]%0a
author:1664682871=
diff:1664682871:1664682773:=229,231d228%0a%3c [[NatureVault/Digital collectible currency]]%0a%3c %0a%3c [[CollectBit]]%0a
author:1664682773=
diff:1664682773:1664682714:=231c231%0a%3c Fact0rn came up with the requirement to require base-2 brilliant numbers which increases randomness of winning a challenge to democratize it slightly for a 1D (traditional) blockchain. However, this only allows up to a maximum of a couple dozen miners/mining pools while staying fair.  Right now they use bitlength of the number adjustment to adjust difficulty.  What they need to do to create fairness is let the difficulty be set by moores law (gain 5 decimal digits (17-18 bits) every 2-3 years and then adjust difficulty with requiring a certain number of "leading 9's" [[ https://www.mersenneforum.org/showpost.php?p=614575&postcount=87|#]] on one or both factors to adjust the blocktime to 20 minutes for a rise or fall of blocktime (change in number of miners).%0a---%0a> Fact0rn came up with the requirement to require base-2 brilliant numbers which increases randomness of winning a challenge to democratize it slightly, but this only allows up to a maximum of a couple dozen miners/mining pools while staying fair.  Right now they use bitlength of the number adjustment to adjust difficulty.  What they need to do to create fairness is let the difficulty be set by moores law (gain 5 decimal digits (17-18 bits) every 2-3 years and then adjust difficulty with requiring a certain number of "leading 9's" [[ https://www.mersenneforum.org/showpost.php?p=614575&postcount=87|#]] on one or both factors to adjust the blocktime to 20 minutes for a rise or fall of blocktime (change in number of miners).%0a
author:1664682714=
diff:1664682714:1664682634:=231c231%0a%3c Fact0rn came up with the requirement to require base-2 brilliant numbers which increases randomness of winning a challenge to democratize it slightly, but this only allows up to a maximum of a couple dozen miners/mining pools while staying fair.  Right now they use bitlength of the number adjustment to adjust difficulty.  What they need to do to create fairness is let the difficulty be set by moores law (gain 5 decimal digits (17-18 bits) every 2-3 years and then adjust difficulty with requiring a certain number of "leading 9's" [[ https://www.mersenneforum.org/showpost.php?p=614575&postcount=87|#]] on one or both factors to adjust the blocktime to 20 minutes for a rise or fall of blocktime (change in number of miners).%0a---%0a> Fact0rn came up with the requirement to require base-2 brilliant numbers which increases randomness of winning a challenge to democratize it slightly, but this only allows up to a maximum of a couple dozen miners/mining pools while staying fair.  Right now they use bitlength of the number adjustment to adjust difficulty.  What they need to do to create fairness is let the difficulty be set by moores law (gain 5 decimal digits (17-18 bits) every 2-3 years and then adjust difficulty with requiring a certain number of "leading 9's" on one or both factors to adjust the blocktime to 20 minutes for a rise or fall of blocktime (change in number of miners).%0a
author:1664682634=
diff:1664682634:1664682391:=231,236c231%0a%3c Fact0rn came up with the requirement to require base-2 brilliant numbers which increases randomness of winning a challenge to democratize it slightly, but this only allows up to a maximum of a couple dozen miners/mining pools while staying fair.  Right now they use bitlength of the number adjustment to adjust difficulty.  What they need to do to create fairness is let the difficulty be set by moores law (gain 5 decimal digits (17-18 bits) every 2-3 years and then adjust difficulty with requiring a certain number of "leading 9's" on one or both factors to adjust the blocktime to 20 minutes for a rise or fall of blocktime (change in number of miners).%0a%3c %0a%3c Factorn integer factorization proof of work [[https://github.com/FACT0RN/FACT0RN|#]] [[https://www.mersenneforum.org/showthread.php?t=27807|#]] [[https://www.coinbase.com/blog/fact0rn-blockchain-integer-factorization-as-proof-of-work-pow|#]] initial commit to merge bitcoin code [[https://github.com/FACT0RN/FACT0RN/commit/08a870f0cce99ed5fe496a0f5f76f03aa2a65140|#]]%0a%3c %0a%3c Factorn whitepaper [[https://fact0rn.io/FACT0RN_whitepaper.pdf|#]] takes them 200 semiprimes to find a valid semiprime (has a factor of exactly half the bitlength) about 1 in 20 for reasonably strong semiprimes.  This means my finding that 1 in 300 numbers is semiprime, 1 in 6,000 numbers is a strong (base-2 brilliant) semiprime.%0a%3c %0a---%0a> Fact0rn came up with the requirement to require base-2 brilliant numbers which increases randomness of winning a challenge to democratize it slightly, but this only allows up to a maximum of a couple dozen miners/mining pools to be fair.%0a
author:1664682391=
diff:1664682391:1664682353:=236a237,240%0a> %0a> Factorn integer factorization proof of work [[https://github.com/FACT0RN/FACT0RN|#]] [[https://www.mersenneforum.org/showthread.php?t=27807|#]] [[https://www.coinbase.com/blog/fact0rn-blockchain-integer-factorization-as-proof-of-work-pow|#]] initial commit to merge bitcoin code [[https://github.com/FACT0RN/FACT0RN/commit/08a870f0cce99ed5fe496a0f5f76f03aa2a65140|#]]%0a> %0a> Factorn whitepaper [[https://fact0rn.io/FACT0RN_whitepaper.pdf|#]] takes them 200 semiprimes to find a valid semiprime (has a factor of exactly half the bitlength) about 1 in 20 for reasonably strong semiprimes.  This means my finding that 1 in 300 numbers is semiprime, 1 in 6,000 numbers is a strong (base-2 brilliant) semiprime.%0a
author:1664682353=
diff:1664682353:1664682201:=229,231d228%0a%3c !!!Fact0rn%0a%3c %0a%3c Fact0rn came up with the requirement to require base-2 brilliant numbers which increases randomness of winning a challenge to democratize it slightly, but this only allows up to a maximum of a couple dozen miners/mining pools to be fair.%0a
author:1664682201=
diff:1664682201:1664682140:=210d209%0a%3c !!!Anders%0a216,217d214%0a%3c %0a%3c !!!Nature%0a
author:1664682140=
diff:1664682140:1664681991:=208,209c208,209%0a%3c !!Prior art [[#prior]]%0a%3c %0a---%0a> !!Notes [[#note]]%0a> %0a215a216,223%0a> Strong semiprimes called base-2 brilliant numbers [[https://www.mersenneforum.org/showpost.php?p=606643&postcount=25|#]]%0a> %0a> Bitlattice tries to go 5D [[https://bitlattice.org/|#]] why??%0a> %0a> Factorn integer factorization proof of work [[https://github.com/FACT0RN/FACT0RN|#]] [[https://www.mersenneforum.org/showthread.php?t=27807|#]] [[https://www.coinbase.com/blog/fact0rn-blockchain-integer-factorization-as-proof-of-work-pow|#]] initial commit to merge bitcoin code [[https://github.com/FACT0RN/FACT0RN/commit/08a870f0cce99ed5fe496a0f5f76f03aa2a65140|#]]%0a> %0a> Factorn whitepaper [[https://fact0rn.io/FACT0RN_whitepaper.pdf|#]] takes them 200 semiprimes to find a valid semiprime (has a factor of exactly half the bitlength) about 1 in 20 for reasonably strong semiprimes.  This means my finding that 1 in 300 numbers is semiprime, 1 in 6,000 numbers is a strong (base-2 brilliant) semiprime.%0a> %0a225,234d232%0a%3c %0a%3c !!Notes [[#note]]%0a%3c %0a%3c Strong semiprimes called base-2 brilliant numbers [[https://www.mersenneforum.org/showpost.php?p=606643&postcount=25|#]]%0a%3c %0a%3c Bitlattice tries to go 5D [[https://bitlattice.org/|#]] why??%0a%3c %0a%3c Factorn integer factorization proof of work [[https://github.com/FACT0RN/FACT0RN|#]] [[https://www.mersenneforum.org/showthread.php?t=27807|#]] [[https://www.coinbase.com/blog/fact0rn-blockchain-integer-factorization-as-proof-of-work-pow|#]] initial commit to merge bitcoin code [[https://github.com/FACT0RN/FACT0RN/commit/08a870f0cce99ed5fe496a0f5f76f03aa2a65140|#]]%0a%3c %0a%3c Factorn whitepaper [[https://fact0rn.io/FACT0RN_whitepaper.pdf|#]] takes them 200 semiprimes to find a valid semiprime (has a factor of exactly half the bitlength) about 1 in 20 for reasonably strong semiprimes.  This means my finding that 1 in 300 numbers is semiprime, 1 in 6,000 numbers is a strong (base-2 brilliant) semiprime.%0a
author:1664681991=
diff:1664681991:1664681915:=210,215c210,213%0a%3c Anders 2014 proposal for integer factorization proof of work [[https://bitcointalk.org/index.php?topic=783110.0|#]]%0a%3c %0a%3c Anders post Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] bitcoin can enter a time warp creating the next darkage where large of chunks of history are forgotten.%0a%3c %0a%3c Anders also came up with unique coin ID's similar to actionlattice idea to prevent double spending [[https://bitcointalk.org/index.php?topic=781967.0|#]]%0a%3c %0a---%0a> Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] bitcoin can enter a time warp creating the next darkage where large of chunks of history are forgotten.%0a> %0a> That user Anders also came up with unique coin ID's similar to actionlattice idea to prevent double spending [[https://bitcointalk.org/index.php?topic=781967.0|#]]%0a> %0a222a221,222%0a> %0a> 2014 proposal for integer factorization proof of work [[https://bitcointalk.org/index.php?topic=783110.0|#]]%0a
author:1664681915=
diff:1664681915:1664672933:=211,212d210%0a%3c %0a%3c That user Anders also came up with unique coin ID's similar to actionlattice idea to prevent double spending [[https://bitcointalk.org/index.php?topic=781967.0|#]]%0a
author:1664672933=
diff:1664672933:1664672160:=210c210%0a%3c Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]] bitcoin can enter a time warp creating the next darkage where large of chunks of history are forgotten.%0a---%0a> Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]]%0a
author:1664672160=
diff:1664672160:1664642336:=209,210d208%0a%3c %0a%3c Block timestamps in bitcoin can be subject to attack [[https://bitcointalk.org/index.php?topic=791284.msg8922079#msg8922079|#]]%0a
author:1664642336=
diff:1664642336:1664641575:=10c10%0a%3c (:Archive:[[ https://archive.ph/GWJ7Y |Archive.is]], [[ https://web.archive.org/web/20221001154854/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice |Archive.org]],  [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|OLDArchive.org]]:)%0a---%0a> (:Archive:[[|Archive.is]], [[ https://web.archive.org/web/20221001154854/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice |Archive.org]],  [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|OLDArchive.org]]:)%0a
author:1664641575=
diff:1664641575:1664639410:=217,220d216%0a%3c %0a%3c 2014 proposal for integer factorization proof of work [[https://bitcointalk.org/index.php?topic=783110.0|#]]%0a%3c %0a%3c 2017 proposal [[https://bitcointalk.org/index.php?topic=2575256.0|#]]%0a
author:1664639410=
diff:1664639410:1664619602:=10c10%0a%3c (:Archive:[[|Archive.is]], [[ https://web.archive.org/web/20221001154854/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice |Archive.org]],  [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|OLDArchive.org]]:)%0a---%0a> (:Archive:[[|Archive.is]], [[ https://web.archive.org/web/20221001083309/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice |Archive.org]],  [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|OLDArchive.org]]:)%0a
author:1664619602=
diff:1664619602:1664619332:=148c148%0a%3c Classical computers gain about 5 bits in factoring ability per year.  Every clean logical qubit added to a quantum computer gains it 1/2 of a bit.  That means for quantum computers to keep up with classical computers for factoring, they would need to gain 10 clean logical qubits per year.  According to the 50 year history of quantum computers, that has never happened nor ever come close.  If anything we seem to be on track for 1 clean logical qubit every 3 years which means quantum computers will progress 30 times slower than classical computers when it comes to factoring large numbers. If this is true, quantum computers will literally never be a threat to GNFS or RSA.%0a---%0a> Classical computers gain about 5 bits in factoring ability per year.  Every clean logical qubit added to a quantum computer gains it 1/2 of a bit.  That means for quantum computers to keep up with classical computers for factoring, they would need to gain 10 clean logical qubits per year.  According to the 50 year history of quantum computers, that has never happened nor ever come close.  If anything we seem to be on track for 1 clean logical qubit every 3 years which means quantum computers will progress 30 times slower than classical computers when it comes to factoring large numbers. If this is true, quantum computers will literally never be a threat to us or RSA.%0a
author:1664619332=
diff:1664619332:1664618949:=142,143c142,143%0a%3c !!!Quantum computers [[#quantum]]%0a%3c %0a---%0a> !!!Quantum computers%0a> %0a148c148%0a%3c Classical computers gain about 5 bits in factoring ability per year.  Every clean logical qubit added to a quantum computer gains it 1/2 of a bit.  That means for quantum computers to keep up with classical computers for factoring, they would need to gain 10 clean logical qubits per year.  According to the 50 year history of quantum computers, that has never happened nor ever come close.  If anything we seem to be on track for 1 clean logical qubit every 3 years which means quantum computers will progress 30 times slower than classical computers when it comes to factoring large numbers. If this is true, quantum computers will literally never be a threat to us or RSA.%0a---%0a> Classical computers gain about 5 bits in factoring ability per year.  Every clean logical qubit added to a quantum computer gains it 1/2 of a bit.  That means for quantum computers to keep up with classical computers for factoring, they would need to gain 10 clean logical qubits per year.%0a
author:1664618949=
diff:1664618949:1664618641:=147,148d146%0a%3c %0a%3c Classical computers gain about 5 bits in factoring ability per year.  Every clean logical qubit added to a quantum computer gains it 1/2 of a bit.  That means for quantum computers to keep up with classical computers for factoring, they would need to gain 10 clean logical qubits per year.%0a
author:1664618641=
diff:1664618641:1664618132:=146c146%0a%3c The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.  For a quantum computer to factor a 150 digit (496 bit) number would take [[ https://www.reddit.com/r/Monero/comments/grms1c/a_holy_grail_pow_for_monero_outlined_gnfs/|994 clean logical qubits]]. Shors algorithm as of 2020 could still only factor 2 digit numbers [[https://crypto.stackexchange.com/a/59796|#]].  Quantum computers have been around for 54 years now [[https://en.wikipedia.org/wiki/Timeline_of_quantum_computing_and_communication|#]] and certainly don't have over 54 clean logical qubits (qubits that can run shor's algorithm).  [[NatureVault/TEEFs law]] states that at best 1 logical qubit will get added per year, since adding one clean logical qubit is probably twice as hard as the last added.  This places us at least a couple hundred years before quantum computers can do what a ryzen processor can do today.  And in a couple hundred years ryzens will be orders of magnitude more capable then they are today.%0a---%0a> The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.  For a quantum computer to factor a 150 digit number would take [[ https://www.reddit.com/r/Monero/comments/grms1c/a_holy_grail_pow_for_monero_outlined_gnfs/|302 clean logical qubits]]. Shors algorithm as of 2020 could still only factor 2 digit numbers [[https://crypto.stackexchange.com/a/59796|#]].  Quantum computers have been around for 54 years now [[https://en.wikipedia.org/wiki/Timeline_of_quantum_computing_and_communication|#]] and certainly don't have over 54 clean logical qubits (qubits that can run shor's algorithm).  [[NatureVault/TEEFs law]] states that at best 1 logical qubit will get added per year, since adding one clean logical qubit is probably twice as hard as the last added.  This places us at least a couple hundred years before quantum computers can do what a ryzen processor can do today.  And in a couple hundred years ryzens will be orders of magnitude more capable then they are today.%0a
author:1664618132=
diff:1664618132:1664617900:=146c146%0a%3c The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.  For a quantum computer to factor a 150 digit number would take [[ https://www.reddit.com/r/Monero/comments/grms1c/a_holy_grail_pow_for_monero_outlined_gnfs/|302 clean logical qubits]]. Shors algorithm as of 2020 could still only factor 2 digit numbers [[https://crypto.stackexchange.com/a/59796|#]].  Quantum computers have been around for 54 years now [[https://en.wikipedia.org/wiki/Timeline_of_quantum_computing_and_communication|#]] and certainly don't have over 54 clean logical qubits (qubits that can run shor's algorithm).  [[NatureVault/TEEFs law]] states that at best 1 logical qubit will get added per year, since adding one clean logical qubit is probably twice as hard as the last added.  This places us at least a couple hundred years before quantum computers can do what a ryzen processor can do today.  And in a couple hundred years ryzens will be orders of magnitude more capable then they are today.%0a---%0a> The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.  For a quantum computer to factor a 150 digit number would take [[ https://www.reddit.com/r/Monero/comments/grms1c/a_holy_grail_pow_for_monero_outlined_gnfs/|302 clean logical qubits]]. Currently in 2022 we are at under 70 clean logical qubits [[https://www.science.org/content/article/ibm-promises-1000-qubit-quantum-computer-milestone-2023|#]] notice that article has been wrong on their predictions and as far as I know 65 clean logical qubits is still the record for clean logical qubits [[https://en.wikipedia.org/wiki/Timeline_of_quantum_computing_and_communication|#]].  Shors algorithm as of 2020 could still only factor 2 digit numbers [[https://crypto.stackexchange.com/a/59796|#]].  Quantum computers have been around for 54 years now and certainly don't have over 54 clean logical qubits (qubits that can run shor's algorithm).  [[NatureVault/TEEFs law]] states that at best 1 logical qubit will get added per year, since adding one clean logical qubit is probably twice as hard as the last added.  This places us at least a couple hundred years before quantum computers can do what a ryzen processor can do today.  And in a couple hundred years ryzens will be orders of magnitude more capable then they are today.%0a
author:1664617900=
diff:1664617900:1664617630:=146c146%0a%3c The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.  For a quantum computer to factor a 150 digit number would take [[ https://www.reddit.com/r/Monero/comments/grms1c/a_holy_grail_pow_for_monero_outlined_gnfs/|302 clean logical qubits]]. Currently in 2022 we are at under 70 clean logical qubits [[https://www.science.org/content/article/ibm-promises-1000-qubit-quantum-computer-milestone-2023|#]] notice that article has been wrong on their predictions and as far as I know 65 clean logical qubits is still the record for clean logical qubits [[https://en.wikipedia.org/wiki/Timeline_of_quantum_computing_and_communication|#]].  Shors algorithm as of 2020 could still only factor 2 digit numbers [[https://crypto.stackexchange.com/a/59796|#]].  Quantum computers have been around for 54 years now and certainly don't have over 54 clean logical qubits (qubits that can run shor's algorithm).  [[NatureVault/TEEFs law]] states that at best 1 logical qubit will get added per year, since adding one clean logical qubit is probably twice as hard as the last added.  This places us at least a couple hundred years before quantum computers can do what a ryzen processor can do today.  And in a couple hundred years ryzens will be orders of magnitude more capable then they are today.%0a---%0a> The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.  For a quantum computer to factor a 150 digit number would take [[ https://www.reddit.com/r/Monero/comments/grms1c/a_holy_grail_pow_for_monero_outlined_gnfs/|302 clean logical qubits]]. Currently in 2022 we are at under 70 clean logical qubits [[https://www.science.org/content/article/ibm-promises-1000-qubit-quantum-computer-milestone-2023|#]] notice that article has been wrong on their predictions and as far as I know 65 clean logical qubits is still the record for clean logical qubits [[https://en.wikipedia.org/wiki/Timeline_of_quantum_computing_and_communication|#]].  Shors algorithm as of 2020 could still only factor 2 digit numbers [[https://crypto.stackexchange.com/a/59796|#]]%0a
author:1664617630=
diff:1664617630:1664616508:=146c146%0a%3c The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.  For a quantum computer to factor a 150 digit number would take [[ https://www.reddit.com/r/Monero/comments/grms1c/a_holy_grail_pow_for_monero_outlined_gnfs/|302 clean logical qubits]]. Currently in 2022 we are at under 70 clean logical qubits [[https://www.science.org/content/article/ibm-promises-1000-qubit-quantum-computer-milestone-2023|#]] notice that article has been wrong on their predictions and as far as I know 65 clean logical qubits is still the record for clean logical qubits [[https://en.wikipedia.org/wiki/Timeline_of_quantum_computing_and_communication|#]].  Shors algorithm as of 2020 could still only factor 2 digit numbers [[https://crypto.stackexchange.com/a/59796|#]]%0a---%0a> The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.  For a quantum computer to factor a 150 digit number would take %0a
author:1664616508=
diff:1664616508:1664615397:=146c146%0a%3c The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.  For a quantum computer to factor a 150 digit number would take %0a---%0a> The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.%0a
author:1664615397=
diff:1664615397:1664614959:=196c196%0a%3c I started shifting into ASIC resistance by hashing the entire blockchain like in [[blockvault]] (which still is a good concept for saving useful data) and then later making my own algorithm, basically [[yespower#fork|forking Yescrypt]] and/or [[Monero fork|RandomX]] and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  I was also interested in [[proportional reward]] from [[staticcoin]]s like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it [[ https://www.reddit.com/r/Monero/comments/grms1c/comment/fs03cis/?utm_source=share&utm_medium=web2x&context=3| can't really work in a 1D blockchain]].%0a---%0a> I started shifting into ASIC resistance by hashing the entire blockchain like in [[blockvault]] (which still is a good concept for saving useful data) and then later making my own algorithm, basically [[yespower#fork|forking Yescrypt]] and/or [[Monero fork|RandomX]] and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  I was also interested in [[proportional reward]] from [[staticcoin]]s like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a
author:1664614959=
diff:1664614959:1664614578:=166,171d165%0a%3c %0a%3c !!!!!Non-standard bitlevel proof%0a%3c %0a%3c The [[#diff|difficulty]] aka 'bitlevel proof' is standardized to certain 'activation levels'.  These are 5 digit levels which is around every 17-18 bits.%0a%3c %0a%3c If the miner proposes an NTF that is not a multiple of 5 decimal digits, it should be discarded or the reward rounded down to the nearest accepted bitlevel and thus standard cip type (aka cip397)%0a
author:1664614578=
diff:1664614578:1664614315:=162,165d161%0a%3c %0a%3c !!!!!Duplicate transaction%0a%3c %0a%3c Duplicate transactions are allowed as long as they contain a different (usually higher) bitlevel proof.  If they have the same bitlevel proof then the latter one would be discarded by the node and should not be built on by other transactions.%0a
author:1664614315=
diff:1664614315:1664614258:=15c15%0a%3c An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, encode tokens and NFT's, and issue rewards (cips). It replaces the blockchain.  You can think of it like a 3D blockchain, whereas a blockchain is 1D.  We have come a long way from [[https://en.wikipedia.org/wiki/History_of_writing#Recorded_history|clay tablets]]%0a---%0a> An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issue rewards (cips).  It replaces the blockchain.  You can think of it like a 3D blockchain, whereas a blockchain is 1D.  We have come a long way from [[https://en.wikipedia.org/wiki/History_of_writing#Recorded_history|clay tablets]]%0a
author:1664614258=
diff:1664614258:1664614201:=42c42%0a%3c #Signatures (proves private key ownership) for the addresses (SPAs) for each bit (cip) being sent.%0a---%0a> #Signatures (proves private key ownership) for the addresses for each bit (cip) being sent.%0a
author:1664614201=
diff:1664614201:1664614129:=40,43c40,43%0a%3c #"Sending Public Addresses" (SPA's) of each bit (cip) being sent.%0a%3c %0a%3c #Signatures (proves private key ownership) for the addresses for each bit (cip) being sent.%0a%3c %0a---%0a> #"Sending Public Addresses" (SPA's) of each bit (cip) being sent%0a> %0a> #Signatures (proves private key ownership) for the addresses for each bit (cip) being sent%0a> %0a46c46%0a%3c #Internal Message (IM) which can be anything, including encoding tokens and NFT's.%0a---%0a> #Internal Message (IM) which can be anything%0a
author:1664614129=
diff:1664614129:1664613800:=15c15%0a%3c An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issue rewards (cips).  It replaces the blockchain.  You can think of it like a 3D blockchain, whereas a blockchain is 1D.  We have come a long way from [[https://en.wikipedia.org/wiki/History_of_writing#Recorded_history|clay tablets]]%0a---%0a> An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issue rewards (cips).  It replaces the blockchain.  You can think of it like a 3D blockchain, whereas a blockchain is 1D.%0a
author:1664613800=
diff:1664613800:1664613290:=33c33%0a%3c Mining any size transaction will require a certain (and probably the same) amount of proof of semiprime, lets say a 20 minute target.  This is set by each individual node and thus a pseudo-consenus would form about what is currently acceptable.  Perhaps a target of a few seconds can act as an initial confirmation and later a 20 min proof would be important to get all the nodes to accept it. In fact, there could be 2 lattices; alpha and beta.  The alpha fork could have few second confirmations for point of sale (pos) applications and then within 20 mins or so it would be confirmed on the beta network for more confidence. Perhaps there are even more networks for even higher proof levels the transactions could be added to.  There probably will be a new cross compatible [[#genesis|genesis fork]] everytime another level of [[#diff|difficulty]] is reached by at least 1 miner.%0a---%0a> Mining any size transaction will require a certain (and probably the same) amount of proof of semiprime, lets say a 20 minute target.  This is set by each individual node and thus a pseudo-consenus would form about what is currently acceptable.  Perhaps a target of a few seconds can act as an initial confirmation and later a 20 min proof would be important to get all the nodes to accept it. In fact, there could be 2 lattices; alpha and beta.  The alpha fork could have few second confirmations for point of sale (pos) applications and then within 20 mins or so it would be confirmed on the beta network for more confidence. Perhaps there are even more networks for even higher proof levels the transactions could be added to.%0a
author:1664613290=
diff:1664613290:1664613113:=10c10%0a%3c (:Archive:[[|Archive.is]], [[ https://web.archive.org/web/20221001083309/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice |Archive.org]],  [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|OLDArchive.org]]:)%0a---%0a> (:Archive:[[|Archive.is]], [[https://web.archive.org/web/20220929004452/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|Archive.org]],  [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|OLDArchive.org]]:)%0a
author:1664613113=
diff:1664613113:1664613094:=181c181%0a%3c #Also having no transaction size limit is a downside because different nodes will have different requirements, but GRIN also uses a similar method for node settings which is more democratic and less centrally planned.%0a---%0a> Also having no transaction size limit is a downside because different nodes will have different requirements, but GRIN also uses a similar method for node settings which is more democratic and less centrally planned.%0a
author:1664613094=
diff:1664613094:1664613062:=179c179%0a%3c **A way around both previous downsides is to have different genesi lattices, Alpha for low bitlength proof, Beta for medium bitlength proof, Gamma for high bitlength proof.  so a gamma cip would always hold the same value, as would a beta or alpha cip.  The downside to this solution is there isn't infinitely variable bitlength that can be rewarded so we really wouldn't know how high a proof level could be without trying it.  So in this example alpha might start at 80 digit proof, then next year might be 82 digit proof, next year 84 digit proof etc.  So one alpha cip will always equal 1 alpha cip.  Problem is we don't know how fast we can raise that bitlevel proof requirement (which is set by each individual node) since there is no incentive for miners to go above and beyond.%0a---%0a> ##Another way around both previous downsides is to have different genesi lattices, Alpha for low bitlength proof, Beta for medium bitlength proof, Gamma for high bitlength proof.  so a gamma cip would always hold the same value, as would a beta or alpha cip.  The downside to this solution is there isn't infinitely variable bitlength that can be rewarded so we really wouldn't know how high a proof level could be without trying it.  So in this example alpha might start at 80 digit proof, then next year might be 82 digit proof, next year 84 digit proof etc.  So one alpha cip will always equal 1 alpha cip.  Problem is we don't know how fast we can raise that bitlevel proof requirement (which is set by each individual node) since there is no incentive for miners to go above and beyond.%0a
author:1664613062=
diff:1664613062:1664612895:=175,179c175,177%0a%3c #But the main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  Using a UTXO we could peg the value of 1 cip = 1 cip forever, but I tend to want completing a higher bitlength proof to be more valuable than a small proof, which also means we can get faster initial confirmations (since they are small proofs, larger proofs can come later).%0a%3c %0a%3c #Another downside is we don't force a consensus between nodes (but we could if we wanted since the lattice is fully auditable), and if we did force consensus it would probably be at the 20-min-semiprime-proof level.  Below that it will be fluid and no consensus would be forced between nodes (most likely, to allow flexibility with what nodes save and accept - it's own custom pruning method).  %0a%3c %0a%3c ##Another way around both previous downsides is to have different genesi lattices, Alpha for low bitlength proof, Beta for medium bitlength proof, Gamma for high bitlength proof.  so a gamma cip would always hold the same value, as would a beta or alpha cip.  The downside to this solution is there isn't infinitely variable bitlength that can be rewarded so we really wouldn't know how high a proof level could be without trying it.  So in this example alpha might start at 80 digit proof, then next year might be 82 digit proof, next year 84 digit proof etc.  So one alpha cip will always equal 1 alpha cip.  Problem is we don't know how fast we can raise that bitlevel proof requirement (which is set by each individual node) since there is no incentive for miners to go above and beyond.%0a---%0a> But the main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  Using a UTXO we could peg the value of 1 cip = 1 cip forever, but I tend to want completing a higher bitlength proof to be more valuable than a small proof, which also means we can get faster initial confirmations (since they are small proofs, larger proofs can come later).%0a> %0a> Another downside is we don't force a consensus between nodes (but we could if we wanted since the lattice is fully auditable), and if we did force consensus it would probably be at the 20-min-semiprime-proof level.  Below that it will be fluid and no consensus would be forced between nodes (most likely, to allow flexibility with what nodes save and accept - it's own custom pruning method).  Another way around this problem is to have different genesi lattices, Alpha for low bitlength proof, Beta for medium bitlength proof, Gamma for high bitlength proof.  so a gamma cip would always hold the same value, as would a beta or alpha cip.  The downside to this solution is there isn't infinitely variable bitlength that can be rewarded so we really wouldn't know how high a proof level could be without trying it.  So in this example alpha might start at 80 digit proof, then next year might be 82 digit proof, next year 84 digit proof etc.  So one alpha cip will always equal 1 alpha cip.  Problem is we don't know how fast we can raise that bitlevel proof requirement (which is set by each individual node) since there is no incentive for miners to go above and beyond.%0a
author:1664612895=
diff:1664612895:1664612645:=157,160c157,160%0a%3c !!!!Types of invalid transactions%0a%3c %0a%3c !!!!!Sending cips that don't exist%0a%3c %0a---%0a> !!!Types of invalid transactions%0a> %0a> !!!!Sending cips that don't exist%0a> %0a163,164c163,164%0a%3c !!!!!Invalid signatures or proof of semiprime%0a%3c %0a---%0a> !!!!Invalid signatures or proof of semiprime%0a> %0a167c167%0a%3c !!!!!Connected to an invalid transaction%0a---%0a> !!!!Connected to an invalid transaction%0a
author:1664612645=
diff:1664612645:1664612251:=60c60%0a%3c This miner can provide a proof of semiprime which can be done on any transaction of any size for the same factoring cost.  Solve a 396 bit (or higher) challenge and you get to pick where the 2 bonds (prior art transactions) are directed.%0a---%0a> This miner can provide a proof of semiprime can be done on any transaction of any size for the same cost.  Solve a 396 bit (or higher) challenge and you get to pick where the 2 bonds (prior art transactions) are directed.%0a
author:1664612251=
diff:1664612251:1664612028:=56c56%0a%3c #Peer blocks - 2 peer blocks NTFs (PNTFs, pronounced 'pontiffs') within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These two NTFs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a---%0a> #Peer blocks - 2 peer blocks NTFs within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These two PMsigs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a
author:1664612028=
diff:1664612028:1664611934:=56c56%0a%3c #Peer blocks - 2 peer blocks NTFs within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These two PMsigs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a---%0a> #Peer blocks - 2 peer blocks Msig (PMsig) within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These two PMsigs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a
author:1664611934=
diff:1664611934:1664611807:=54,55c54,55%0a%3c #Proof of Proven Sieve ([[#props|Props]]) - number to factor (NTF), nonce (that was concatenated with the CTS, peer blocks NTFs, cipbase address, and hashed to create the new NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a%3c %0a---%0a> #Proof of Proven Sieve ([[#props|Props]]) - number to factor (NTF), nonce (that was concatenated with the CTS and peer blocks Msig's and cipbase address and hashed to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a> %0a58a59,62%0a> %0a> #Miners signature (Msig) - one who found the Props signs the entire "block" (the transaction and everything they added to it) using the private key of the cipbase.%0a> %0a> ##Alternatively if people think its best not to have to prove the cipbase is spendable, then Msig can be removed and just reference NTF's of the transactions instead.%0a
author:1664611807=
diff:1664611807:1664611653:=27c27%0a%3c All a cryptocurrency would need is an actionlattice.  Also a UTXO may be used, and will be helpful because of pruning.  The UTXO would simply carry a list of addresses with balance of 1 cip, and used addresses (that contain 0 cips) and these cannot be reused (this is done to maintain privacy and security since every cip is only signed for once and then it is destroyed).  That said UTXO omission could be a feature as it would mean transactions keep needing to be re-mined at current difficulty to not be purged (and effectively reversed).%0a---%0a> All a cryptocurrency would need is an actionlattice.  Also a UTXO may be used, and will be helpful because of pruning.  The UTXO would simply carry a list of addresses with balance of 1 cip, and used addresses (that contain 0 cips) and these cannot be reused (this is done to maintain privacy).  That said UTXO omission could be a feature as it would mean transactions keep needing to be re-mined at current difficulty to not be purged (and effectively reversed).%0a
author:1664611653=
diff:1664611653:1664611216:=48c48%0a%3c #Completed transaction signature (CTS) - Signs over the whole transaction using one (or more) of the SPA's done by the sender.  This prevents man in the middle (MITM) attack.%0a---%0a> #Completed transaction signature (CTS) - Signs over the whole transaction done by the sender.  This prevents man in the middle (MITM) attack.%0a
author:1664611216=
diff:1664611216:1664611127:=25c25%0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original, probably with a new recognized cip every [[#diff|5 decimal digits {17-18 bits}]] of proof level.  The original transaction and cip is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot receive another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a---%0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original, probably with a new recognized cip every [[#dff|5 decimal digits ~17-18 bits]] of proof level.  The original transaction and cip is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot receive another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a
author:1664611127=
diff:1664611127:1664611060:=25c25%0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original, probably with a new recognized cip every [[#dff|5 decimal digits ~17-18 bits]] of proof level.  The original transaction and cip is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot receive another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a---%0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original, probably with a new recognized cip every [[#dff|5 decimal digits {17-18 bits}]] of proof level.  The original transaction and cip is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot receive another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a
author:1664611060=
diff:1664611060:1664610624:=25c25%0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original, probably with a new recognized cip every [[#dff|5 decimal digits {17-18 bits}]] of proof level.  The original transaction and cip is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot receive another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a---%0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original, probably with a new recognized cip every 5 decimal digits {17-18 bits} of proof level.  The original transaction and cip is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot receive another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a
author:1664610624=
diff:1664610624:1664610499:=37,38c37,38%0a%3c !!Process [[#process]]%0a%3c !!!Transactor side - create "transaction block" [[#transaction]]%0a---%0a> !!Process%0a> !!!Transactor side - create "transaction block"%0a
author:1664610499=
diff:1664610499:1664610414:=19,20c19,20%0a%3c Every transaction is free to propose, and then a miner (or you - if you mine your own tx) gets paid with a reward cip if they "activate" the proposed transaction using proof of semiprime (aka proof of sieve) ([[#posi|Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface" but whose cip genesis is deep below the surface.  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface but the cip genesis is deep from the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a%3c %0a---%0a> Every transaction is free to propose, and then a miner (or you - if you mine your own tx) gets paid with a reward cip if they "activate" the proposed transaction using proof of semiprime (aka proof of sieve) ([[Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface" but whose cip genesis is deep below the surface.  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface but the cip genesis is deep from the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a> %0a25,26c25,26%0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original, probably with a new recognized cip every 5 decimal digits {17-18 bits} of proof level.  The original transaction and cip is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot receive another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a%3c %0a---%0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original, probably with a new recognized cip every 5 decimal digits {17-18 bits} of proof level.  The original transaction and cip is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot recieve another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a> %0a29c29%0a%3c Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without proof of semiprime [[#posi|Posi]].  If it is broadcast to the network with no proof, then a miner would need to activate and connect it wherever they want in the lattice (they will probably selfishly connect it to their own transactions to add confirmations).%0a---%0a> Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without [[proof of semiprime]] [[Posi]].  If it is broadcast to the network with no proof, then a miner would need to activate and connect it wherever they want in the lattice (they will probably selfishly connect it to their own transactions to add confirmations).%0a
author:1664610414=
diff:1664610414:1664610364:=52c52%0a%3c #Proof of Sieve/semiprime ([[#posi|Posi]]) message (Posim) - anything the miner wants to write.%0a---%0a> #Proof of Sieve/semiprime (Posi) message (Posim) - anything the miner wants to write.%0a
author:1664610364=
diff:1664610364:1664610334:=84,85d83%0a%3c %0a%3c !!!Notes%0a
author:1664610334=
diff:1664610334:1664610291:=81c81%0a%3c !!Proof of Semiprime/sieve (Posi) [[#posi]]%0a---%0a> !!Proof of Semiprime/sieve%0a
author:1664610291=
diff:1664610291:1664610196:=54c54%0a%3c #Proof of Proven Sieve ([[#props|Props]]) - number to factor (NTF), nonce (that was concatenated with the CTS and peer blocks Msig's and cipbase address and hashed to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a---%0a> #Proof of Proven Sieve (Props) - number to factor (NTF), nonce (that was concatenated with the CTS and peer blocks Msig's and cipbase address and hashed to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a
author:1664610196=
diff:1664610196:1664610139:=95,97c95%0a%3c !!Proof of proven sieve/semiprime (Props) [[#props]]%0a%3c %0a%3c See also [[#act|transaction activation]]%0a---%0a> !!Proof of proven sieve (Props) [[#props]]%0a
author:1664610139=
diff:1664610139:1664610112:=50c50%0a%3c !!!Miner's side - "activation" of transaction block [[#act]]%0a---%0a> !!!Miner's side - "activation" of transaction block%0a
author:1664610112=
diff:1664610112:1664609934:=95c95%0a%3c !!Proof of proven sieve (Props) [[#props]]%0a---%0a> !!Proof of proven sieve (Props)%0a
author:1664609934=
diff:1664609934:1664609614:=54,55c54,55%0a%3c #Proof of Proven Sieve (Props) - number to factor (NTF), nonce (that was concatenated with the CTS and peer blocks Msig's and cipbase address and hashed to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a%3c %0a---%0a> #Proof of Proven Sieve (Props) - number to factor (NTF), nonce (that was concatenated with the CTS and peer blocks Msig's and hashed to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a> %0a60,62c60%0a%3c #Miners signature (Msig) - one who found the Props signs the entire "block" (the transaction and everything they added to it) using the private key of the cipbase.%0a%3c %0a%3c ##Alternatively if people think its best not to have to prove the cipbase is spendable, then Msig can be removed and just reference NTF's of the transactions instead.%0a---%0a> #Miners signature (Msig) - one who found the Props signs the entire "block" (the transaction and everything they added to it).%0a
author:1664609614=
diff:1664609614:1664609297:=54,56c54,56%0a%3c #Proof of Proven Sieve (Props) - number to factor (NTF), nonce (that was concatenated with the CTS and peer blocks Msig's and hashed to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a%3c %0a%3c #Peer blocks - 2 peer blocks Msig (PMsig) within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).  These two PMsigs need to be a part of the hash for generating the NTF's in order to prevent a man in the middle attack where someone would steal your NTF and factors and use their own PMsigs and their own Msig to steal the reward.%0a---%0a> #Proof of Proven Sieve (Props) - number to factor (NTF), nonce (that was concatenated with the CTS and hashed to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a> %0a> #Peer blocks - 2 peer blocks Msig within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).%0a
author:1664609297=
diff:1664609297:1664609250:=92,93d91%0a%3c %0a%3c !!Proof of proven sieve (Props)%0a
author:1664609250=
diff:1664609250:1664608957:=79c79%0a%3c !!Proof of Semiprime/sieve%0a---%0a> !!Proof of Semiprime%0a
author:1664608957=
diff:1664608957:1664608564:=56c56%0a%3c #Peer blocks - 2 peer blocks Msig within the last epoch (nodes may have set their own requirement for how old of transactions that they will allow new transactions to connect to) that you confirm are correct (if you are wrong about their validity your transaction may become voided).%0a---%0a> #Peer blocks - 2 peer blocks Msig within the last epoch that you confirm are correct (if you are wrong about their validity your transaction may become voided).%0a
author:1664608564=
diff:1664608564:1664608526:=52c52%0a%3c #Proof of Sieve/semiprime (Posi) message (Posim) - anything the miner wants to write.%0a---%0a> #Proof of Sieve (Posi) message (Posim) - anything the miner wants to write.%0a
author:1664608526=
diff:1664608526:1664608448:=19c19%0a%3c Every transaction is free to propose, and then a miner (or you - if you mine your own tx) gets paid with a reward cip if they "activate" the proposed transaction using proof of semiprime (aka proof of sieve) ([[Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface" but whose cip genesis is deep below the surface.  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface but the cip genesis is deep from the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a---%0a> Every transaction is free to propose, and then a miner (or you - if you mine your own tx) gets paid with a reward cip if they "activate" the proposed transaction using proof of semiprime ([[Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface" but whose cip genesis is deep below the surface.  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface but the cip genesis is deep from the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a
author:1664608448=
diff:1664608448:1664608350:=58,59c58,59%0a%3c #Bitbase address (aka cipbase) which is the Miners public address (MPA) where the bitbase is sent.%0a%3c %0a---%0a> #Bitbase address which is the Miners public address (MPA) where the bitbase is sent, 1 bit for 10 kb or whatever it is.%0a> %0a64c64%0a%3c Now another miner can also do the same exact challenge and add the same transaction to the lattice however the challenge has to be harder, say a 400 bit number instead of 396.  This means multiple miners can mine the same transactions, they are all in the lattice but since each transaction is a non-reversible change (since by definition each address can only hold 1 bit, no more no less, once it sends its bit (cip) it can never receive another, its worn out.  this solves the double spending problem.  Each address is one and done.  It either doesn't exist, holds a bit, or is spent.  So a transaction from one specific address to another can only ever happen once and never be reversed.  We solve double spending to not allow any address to make more than one transaction ever.  And we achieve this by allowing infinite addresses.  That also gives privacy.%0a---%0a> Now another miner can also do the same exact challenge and add the same transaction to the lattice however the challenge has to be harder, say a 400 bit mumber instead of 396.  This means multiple miners can mine the same transactions, they are all in the lattice but since each transaction is a non-reversible change (since by definition each address can only hold 1 bit, no more no less, once it sends its bit it can never recieve another, its worn out.  this solves the double spending problem.  Each address is one and done.  It either doesn't exist, holds a bit, or is spent.  So a transaction from one specific address to another can only ever happen once and never be reversed.  We solve double spending to not allow any address to make more than one transaction ever.  And we achieve this by allowing infinite addresses.  That also gives privacy.%0a
author:1664608350=
diff:1664608350:1664608235:=42,44c42,44%0a%3c #Signatures (proves private key ownership) for the addresses for each bit (cip) being sent%0a%3c %0a%3c #"Receiving Public Addresses" (RPA's) - One brand new address for each bit (cip) being received.%0a---%0a> #Signatures (proves private key ownership) for the addresses for each bit being sent%0a> %0a> #"Receiving Public Addresses" (RPA's) - One brand new address for each bit being received.%0a
author:1664608235=
diff:1664608235:1664608019:=54c54%0a%3c #Proof of Proven Sieve (Props) - number to factor (NTF), nonce (that was concatenated with the CTS and hashed to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying). If two factors are given NTF would not need to be declared and recorded because it can just be assumed by multiplying the factors together, but it might be worth the space to save the NTF to make it more human understandable.%0a---%0a> #Proof of Proven Sieve (Props) - number to factor (NTF), nonce (that was concatenated with the CTS and hashed to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying).%0a
author:1664608019=
diff:1664608019:1664607675:=52c52%0a%3c #Proof of Sieve (Posi) message (Posim) - anything the miner wants to write.%0a---%0a> #Proof of Sieve (Posi) message - anything the miner wants to write.%0a
author:1664607675=
diff:1664607675:1664606988:=33c33%0a%3c Mining any size transaction will require a certain (and probably the same) amount of proof of semiprime, lets say a 20 minute target.  This is set by each individual node and thus a pseudo-consenus would form about what is currently acceptable.  Perhaps a target of a few seconds can act as an initial confirmation and later a 20 min proof would be important to get all the nodes to accept it. In fact, there could be 2 lattices; alpha and beta.  The alpha fork could have few second confirmations for point of sale (pos) applications and then within 20 mins or so it would be confirmed on the beta network for more confidence. Perhaps there are even more networks for even higher proof levels the transactions could be added to.%0a---%0a> Mining any size transaction will require a certain amount of proof of semiprime, lets say a 20 minute target.  This is set by the nodes.  Perhaps a target of a few seconds can act as an initial confirmation and later a 20 min proof would be important to get all the nodes to accept it. In fact, there could be 2 lattices; alpha and beta.  The alpha fork could have few second confirmations for point of sale (pos) applications and then within 20 mins or so it would be confirmed on the beta network for more confidence. Perhaps there are even more networks for even higher proof levels the transactions could be added to.%0a
author:1664606988=
diff:1664606988:1664606914:=17c17%0a%3c The smallest (and only) unit of account is the cip (dust - like a satoshi). The name is a convolution of "bit", "semiprime" maybe "cipher" or "sip".%0a---%0a> The smallest (and only) unit of account is the cip (dust). The name is a convolution of "bit", "semiprime" maybe "cipher" or "sip".%0a
author:1664606914=
diff:1664606914:1664575994:=25c25%0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original, probably with a new recognized cip every 5 decimal digits {17-18 bits} of proof level.  The original transaction and cip is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot recieve another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a---%0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original.  The original is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot recieve another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a
author:1664575994=
diff:1664575994:1664575614:=173c173%0a%3c Another downside is we don't force a consensus between nodes (but we could if we wanted since the lattice is fully auditable), and if we did force consensus it would probably be at the 20-min-semiprime-proof level.  Below that it will be fluid and no consensus would be forced between nodes (most likely, to allow flexibility with what nodes save and accept - it's own custom pruning method).  Another way around this problem is to have different genesi lattices, Alpha for low bitlength proof, Beta for medium bitlength proof, Gamma for high bitlength proof.  so a gamma cip would always hold the same value, as would a beta or alpha cip.  The downside to this solution is there isn't infinitely variable bitlength that can be rewarded so we really wouldn't know how high a proof level could be without trying it.  So in this example alpha might start at 80 digit proof, then next year might be 82 digit proof, next year 84 digit proof etc.  So one alpha cip will always equal 1 alpha cip.  Problem is we don't know how fast we can raise that bitlevel proof requirement (which is set by each individual node) since there is no incentive for miners to go above and beyond.%0a---%0a> Another downside is we don't force a consensus between nodes (but we could if we wanted since the lattice is fully auditable), and if we did force consensus it would probably be at the 20-min-semiprime-proof level.  Below that it will be fluid and no consensus would be forced between nodes (most likely, to allow flexibility with what nodes save and accept - it's own custom pruning method).%0a
author:1664575614=
diff:1664575614:1664575519:=98,103d97%0a%3c !!Difficulty [[#diff]]%0a%3c %0a%3c Moore's law shows that every 5 more decimal digits you double the difficulty [[https://mersenneforum.org/showthread.php?t=19171&highlight=Moore|#]] [[https://mersenneforum.org/showthread.php?t=23078|#]] or 17-18 bits [[https://www.mersenneforum.org/showpost.php?p=606655&postcount=28|#]], which may happen every 3 years.  So the ease of factoring a 110 digit today will be what its like to mine a 115 digit number 3 years from now.%0a%3c %0a%3c The nodes set the minimum difficulty they will accept.  This should be raised based on basically what is the minimum difficulty proof that is present in the network.  Since miners get rewarded to re-mine old transactions at higher difficulty, the network autocompensates for moore's law.  The result of this is old rewards would slowly loose value over time.  That could be quite fast, value might decline with moore's law for old cips. However you can keep mining fresh new cips with high value constantly.  [[NatureVault/Digital Collectible Network]] doesn't have the value loss problem though.  Neither does Fact0rn.%0a%3c %0a165a160,165%0a> %0a> !!Difficulty [[#diff]]%0a> %0a> Moore's law shows that every 5 more decimal digits you double the difficulty [[https://mersenneforum.org/showthread.php?t=19171&highlight=Moore|#]] [[https://mersenneforum.org/showthread.php?t=23078|#]] or 17-18 bits [[https://www.mersenneforum.org/showpost.php?p=606655&postcount=28|#]], which may happen every 3 years.  So the ease of factoring a 110 digit today will be what its like to mine a 115 digit number 3 years from now.%0a> %0a> The nodes set the minimum difficulty they will accept.  This should be raised based on basically what is the minimum difficulty proof that is present in the network.  Since miners get rewarded to re-mine old transactions at higher difficulty, the network autocompensates for moore's law.  The result of this is old rewards would slowly loose value over time.  That could be quite fast, value might decline with moore's law for old cips. However you can keep mining fresh new cips with high value constantly.  [[NatureVault/Digital Collectible Network]] doesn't have the value loss problem though.  Neither does Fact0rn.%0a
author:1664575519=
diff:1664575519:1664575481:=160,166d159%0a%3c %0a%3c !!Difficulty [[#diff]]%0a%3c %0a%3c Moore's law shows that every 5 more decimal digits you double the difficulty [[https://mersenneforum.org/showthread.php?t=19171&highlight=Moore|#]] [[https://mersenneforum.org/showthread.php?t=23078|#]] or 17-18 bits [[https://www.mersenneforum.org/showpost.php?p=606655&postcount=28|#]], which may happen every 3 years.  So the ease of factoring a 110 digit today will be what its like to mine a 115 digit number 3 years from now.%0a%3c %0a%3c The nodes set the minimum difficulty they will accept.  This should be raised based on basically what is the minimum difficulty proof that is present in the network.  Since miners get rewarded to re-mine old transactions at higher difficulty, the network autocompensates for moore's law.  The result of this is old rewards would slowly loose value over time.  That could be quite fast, value might decline with moore's law for old cips. However you can keep mining fresh new cips with high value constantly.  [[NatureVault/Digital Collectible Network]] doesn't have the value loss problem though.  Neither does Fact0rn.%0a%3c %0a175a169,175%0a> %0a> !!Difficulty [[#diff]]%0a> %0a> Moore's law shows that every 5 more decimal digits you double the difficulty [[https://mersenneforum.org/showthread.php?t=19171&highlight=Moore|#]] [[https://mersenneforum.org/showthread.php?t=23078|#]] or 17-18 bits [[https://www.mersenneforum.org/showpost.php?p=606655&postcount=28|#]], which may happen every 3 years.  So the ease of factoring a 110 digit today will be what its like to mine a 115 digit number 3 years from now.%0a> %0a> The nodes set the minimum difficulty they will accept.  This should be raised based on basically what is the minimum difficulty proof that is present in the network.  Since miners get rewarded to re-mine old transactions at higher difficulty, the network autocompensates for moore's law.  The result of this is old rewards would slowly loose value over time.  That could be quite fast, value might decline with moore's law for old cips. However you can keep mining fresh new cips with high value constantly.  [[NatureVault/Digital Collectible Network]] doesn't have the value loss problem though.  Neither does Fact0rn.%0a> %0a
author:1664575481=
diff:1664575481:1664574609:=168d167%0a%3c Also having no transaction size limit is a downside because different nodes will have different requirements, but GRIN also uses a similar method for node settings which is more democratic and less centrally planned.%0a
author:1664574609=
diff:1664574609:1664574561:=179c179%0a%3c I started shifting into ASIC resistance by hashing the entire blockchain like in [[blockvault]] (which still is a good concept for saving useful data) and then later making my own algorithm, basically [[yespower#fork|forking Yescrypt]] and/or [[Monero fork|RandomX]] and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  I was also interested in [[proportional reward]] from [[staticcoin]]s like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a---%0a> I started shifting into ASIC resistance by hashing the entire blockchain like in [[blockvault]] (which still is a useful concept) and then later making my own algorithm, basically [[yespower#fork|forking Yescrypt]] and/or [[Monero fork|RandomX]] and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  I was also interested in [[proportional reward]] from [[staticcoin]]s like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a
author:1664574561=
diff:1664574561:1664574493:=179c179%0a%3c I started shifting into ASIC resistance by hashing the entire blockchain like in [[blockvault]] (which still is a useful concept) and then later making my own algorithm, basically [[yespower#fork|forking Yescrypt]] and/or [[Monero fork|RandomX]] and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  I was also interested in [[proportional reward]] from [[staticcoin]]s like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a---%0a> I started shifting into ASIC resistance by hashing the entire blockchain like in [[blockvault]] (which still is a useful concept) and then later making my own algorithm, basically [[yespower#fork|forking Yescrypt]] and/or [[randomx|RandomX]] and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  I was also interested in [[proportional reward]] from [[staticcoin]]s like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a
author:1664574493=
diff:1664574493:1664573585:=179c179%0a%3c I started shifting into ASIC resistance by hashing the entire blockchain like in [[blockvault]] (which still is a useful concept) and then later making my own algorithm, basically [[yespower#fork|forking Yescrypt]] and/or [[randomx|RandomX]] and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  I was also interested in [[proportional reward]] from [[staticcoin]]s like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a---%0a> I started shifting into ASIC resistance by making my own algorithm, basically forking Yescrypt and/or RandomX and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning [[Yespower#fork]].  I was also interested in [[proportional reward]] from [[staticcoin]]s like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a
author:1664573585=
diff:1664573585:1664573463:=181c181%0a%3c Then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would make it a 3D blockchain.  This 3D blockchain design, actionlattice, also provides a proportional reward for miners which is awesome.  Its funny and fitting that all the limitations that 1D blockchain has (51%25 attack, unfair reward, mining pools, asics, etc) can be overcome by moving into 3D.  We do live in a 3D world after all.%0a---%0a> Then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would make it a 3D blockchain.  This 3D blockchain design, actionlattice, also provides a proportional reward for miners which is awesome.  Its funny and fitting that all the limitations that 1D blockchain has can be overcome by moving into 3D.  We do live in a 3D world after all.%0a
author:1664573463=
diff:1664573463:1664573445:=128c128%0a%3c !!!GPU%0a---%0a> !!GPU%0a
author:1664573445=
diff:1664573445:1664573087:=127,130d126%0a%3c %0a%3c !!GPU%0a%3c %0a%3c Gpu's can ECM a number looking for factors up to around 0.37x of the bitlength of the number in the same time it takes a CPU to use GNFS to find all factors.  What this means is that the stength of factors required would mean that there should be no factors smaller than 0.37x of the bitlength.  Preferably 0.4x. the farther we go over around 0.32x requirement the more "useless" sieves we will have to do due to finding decently strong semiprimes but they are not strong enough.  Due to risks of ECM asics though my current thought is require semistrong semiprimes with factors no smaller than 0.47x of the bitlength.  If you put the requirement at around 0.37x then you can balance GPU's with CPU's if you want something like that otherwise at around 0.4x and above GPU can ECM up to 0.34-0.37x and then pass it to the CPU in order to do the GNFS sieve and find the factors.%0a
author:1664573087=
diff:1664573087:1664572754:=127,132d126%0a%3c %0a%3c !!!Quantum computers%0a%3c %0a%3c Quantum computers can do 2 things against something like actionlattice.  First they can potentially crack keys, reverse the private key from the public key.  I believe such a process would use grover's algorithm which isn't exceptionally fast so that provides some security.  Also we can use quantum resistant addresses which is no problem (although it would bloat transaction size for us especially).%0a%3c %0a%3c The next attack is unique to GNFS crypto and that is shor's algorithm which is very fast at factoring large numbers.  The main defense we have against that is the democratization of mining.  One quantum computer cannot factor hundreds or thousands of numbers in parallel and so it wouldn't be able to attack the network if other small miners are also confirming transactions.  Also miners can even mine their transactions offline before they propose them to the network further eliminating quantum as the only things that will win cips.  The best part about actionlattice is that it allows quantum computers to mine but by design prevents them from taking over.%0a
author:1664572754=
diff:1664572754:1664572687:=171c171%0a%3c Then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would make it a 3D blockchain.  This 3D blockchain design, actionlattice, also provides a proportional reward for miners which is awesome.  Its funny and fitting that all the limitations that 1D blockchain has can be overcome by moving into 3D.  We do live in a 3D world after all.%0a---%0a> Then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would make it a 3D blockchain.  This 3D blockchain design, actionlattice, also provides a proportional reward for miners which is awesome.%0a
author:1664572687=
diff:1664572687:1664572664:=169c169%0a%3c I started shifting into ASIC resistance by making my own algorithm, basically forking Yescrypt and/or RandomX and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning [[Yespower#fork]].  I was also interested in [[proportional reward]] from [[staticcoin]]s like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a---%0a> I started shifting into ASIC resistance by making my own algorithm, basically forking Yescrypt and/or RandomX and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning [[Yespower#fork]].  I was also interested in [[proportional reward]] from [[staticcoins]] like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a
author:1664572664=
diff:1664572664:1664572527:=169,171c169,171%0a%3c I started shifting into ASIC resistance by making my own algorithm, basically forking Yescrypt and/or RandomX and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning [[Yespower#fork]].  I was also interested in [[proportional reward]] from [[staticcoins]] like [[Ergon]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a%3c %0a%3c Then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would make it a 3D blockchain.  This 3D blockchain design, actionlattice, also provides a proportional reward for miners which is awesome.%0a---%0a> I started shifting into ASIC resistance by making my own algorithm, basically forking Yescrypt and/or RandomX and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning [[Yespower#fork]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a> %0a> Then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would make it a 3D blockchain.%0a
author:1664572527=
diff:1664572527:1664572370:=169c169%0a%3c I started shifting into ASIC resistance by making my own algorithm, basically forking Yescrypt and/or RandomX and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning [[Yespower#fork]].  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a---%0a> I started shifting into ASIC resistance by making my own algorithm, basically forking Yescrypt and/or RandomX and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a
author:1664572370=
diff:1664572370:1664571978:=173,177c173%0a%3c Doing research further on mersennes forum I also ran into Fact0rn post and how they wanted to use factoring in a 1D blockchain.  I explained to them why it wouldn't work as designed in their discord and here [[https://www.mersenneforum.org/showpost.php?p=614575&postcount=87|#]] and offered them my help and potential solutions.  That said their requirement of "strong semiprimes" actually was an improvement for 1D blockchain over my "semistrong semiprimes" and realizing why their solution was better led me to my advice on how to make it better still (in the link above). %0a%3c %0a%3c I chose semistrong semiprimes because in my collectbit database people can submit individual proofs to mine and I wanted every GNFS sieve, after ECM, to yield a solution - therefore proving GNFS was done but not requiring extra effort after that.%0a%3c %0a%3c I still think 3D blockchain is the best current implementation for GNFS solely because multiple people can submit proofs at the same time and even back in time slightly (allowing mining offline).  Also the 3D method will inherently scale to much much greater transactions per second (TPS) than a 1D or 2D can achieve.%0a---%0a> Doing research further on mersennes forum I also ran into Fact0rn post and how they wanted to use factoring in a 1D blockchain.  I explained to them why it wouldn't work as designed in their discord and here [[https://www.mersenneforum.org/showpost.php?p=614575&postcount=87|#]] and offered them my help and potential solutions.  I still think 3D blockchain is the best current implementation for GNFS solely because multiple people can submit proofs at the same time and even back in time slightly (allowing mining offline).%0a
author:1664571978=
diff:1664571978:1664571893:=171c171%0a%3c Then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would make it a 3D blockchain.%0a---%0a> Then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would be a 3D blockchain.%0a
author:1664571893=
diff:1664571893:1664571861:=169c169%0a%3c I started shifting into ASIC resistance by making my own algorithm, basically forking Yescrypt and/or RandomX and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  But always in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a---%0a> I started shifting into ASIC resistance by making my own algorithm, basically forking Yescrypt and/or RandomX and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  But akways in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a
author:1664571861=
diff:1664571861:1664571479:=168,173c168%0a%3c Inspiration for this idea came mostly from my work on [[CollectBit]] and [[NatureVault/Digital collectible network]].  I hit a wall not knowing what to do next. %0a%3c I started shifting into ASIC resistance by making my own algorithm, basically forking Yescrypt and/or RandomX and making the memory requirement scale with moores law to make ASICs prohibitively expensive to keep redesigning.  But akways in the back of my mind I knew GNFS was the holy grail for asic resistance but it can't really work in a 1D blockchain.%0a%3c %0a%3c Then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would be a 3D blockchain.%0a%3c %0a%3c Doing research further on mersennes forum I also ran into Fact0rn post and how they wanted to use factoring in a 1D blockchain.  I explained to them why it wouldn't work as designed in their discord and here [[https://www.mersenneforum.org/showpost.php?p=614575&postcount=87|#]] and offered them my help and potential solutions.  I still think 3D blockchain is the best current implementation for GNFS solely because multiple people can submit proofs at the same time and even back in time slightly (allowing mining offline).%0a---%0a> Inspiration for this idea came mostly from my work on [[CollectBit]] and [[NatureVault/Digital collectible network]].  I hit a wall not knowing what to do next then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would be a 3D blockchain.%0a
author:1664571479=
diff:1664571479:1664556597:=165,168d164%0a%3c %0a%3c !!Inspiration%0a%3c %0a%3c Inspiration for this idea came mostly from my work on [[CollectBit]] and [[NatureVault/Digital collectible network]].  I hit a wall not knowing what to do next then learning about Kaspa and their blockDAG got me thinking.  I noticed their system was basically a 2D blockchain and can reward people for coming up with solutions at the same time as others.  I thought the logical conclusion would be every transaction would be its own block but was unsure of how that could work scalably and why it would be important to do.  After a day or so of thinking I figured I could make transactions like water molecules that bond to other transactions and these bonds confirm previous transactions.  Only then did I realize that would be a 3D blockchain.%0a
author:1664556597=
diff:1664556597:1664556215:=1c1%0a%3c (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain (1D) or blockDAG (2D).  It scales to infinite free and private transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], mining pools aren't necessary for miners to get constant rewards, tx can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain (1D) or blockDAG (2D).  It scales to infinite free transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], mining pools aren't necessary for miners to get constant rewards, tx can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664556215=
diff:1664556215:1664556074:=44c44%0a%3c #"Receiving Public Addresses" (RPA's) - One brand new address for each bit being received.%0a---%0a> #"Receiving Public Addresses" (RPA's) - One address for each bit being received.%0a
author:1664556074=
diff:1664556074:1664556036:=54c54%0a%3c #Proof of Proven Sieve (Props) - number to factor (NTF), nonce (that was concatenated with the CTS and hashed to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying).%0a---%0a> #Proof of Proven Sieve (Props) - number to factor (NTF), nonce (that was concatenated with the CTS to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying).%0a
author:1664556036=
diff:1664556036:1664555986:=54c54%0a%3c #Proof of Proven Sieve (Props) - number to factor (NTF), nonce (that was concatenated with the CTS to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying).%0a---%0a> #Proof of Proven Sieve (Props) - number to factor NTF (based on CTS), nonce (that was concatenated with the CTS to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying).%0a
author:1664555986=
diff:1664555986:1664555672:=54c54%0a%3c #Proof of Proven Sieve (Props) - number to factor NTF (based on CTS), nonce (that was concatenated with the CTS to create the NTF), and 2 factors (or 1 to save space? To verify validity, multiplication might be faster than division, so listing both factors might be wise since lots of nodes are going to be spending lots of time verifying).%0a---%0a> #Proof of Proven Sieve (Props) - number to factor (based on hashing CTS), nonce, and 2 factors.%0a
author:1664555672=
diff:1664555672:1664555650:=48c48%0a%3c #Completed transaction signature (CTS) - Signs over the whole transaction done by the sender.  This prevents man in the middle (MITM) attack.%0a---%0a> #Completed transaction signature - Signs over the whole transaction done by the sender.  This prevents man in the middle (MITM) attack.%0a
author:1664555650=
diff:1664555650:1664555591:=54c54%0a%3c #Proof of Proven Sieve (Props) - number to factor (based on hashing CTS), nonce, and 2 factors.%0a---%0a> #Proof of Proven Sieve (Props) - number to factor, nonce, and 2 factors.%0a
author:1664555591=
diff:1664555591:1664555405:=52,57c52,57%0a%3c #Proof of Sieve (Posi) message - anything the miner wants to write.%0a%3c %0a%3c #Proof of Proven Sieve (Props) - number to factor, nonce, and 2 factors.%0a%3c %0a%3c #Peer blocks - 2 peer blocks Msig within the last epoch that you confirm are correct (if you are wrong about their validity your transaction may become voided).%0a%3c %0a---%0a> #Proof of Sieve (Posi) message - %0a> %0a> #Proof of Proven Sieve (Props) - number to factor, nonce, and 2 factors%0a> %0a> #Peer blocks - 2 peer blocks Msig within the last epoch that you confirm are correct (if you are wrong about their validity your transaction may become voided)%0a> %0a60c60%0a%3c #Miners signature (Msig) - one who found the Props signs the entire "block" (the transaction and everything they added to it).%0a---%0a> #Miners signature (Msig) - one who found the Props signs the entire "block" (the transaction and everything they added to it)%0a
author:1664555405=
diff:1664555405:1664555319:=40c40%0a%3c #"Sending Public Addresses" (SPA's) of each bit (cip) being sent%0a---%0a> #"Sending Public Addresses" (SPA's) of each bit being sent%0a
author:1664555319=
diff:1664555319:1664555247:=35c35%0a%3c Each transaction contains public addresses and signatures for each of the cips being sent and the public addresses for each cip to be received to, a cipbase address where a new cip is created and given to, and a message field that can be used for iterating nonces and including messages like love letters or encoding Tokens or NFT's like [[Ravencoin]] or Bitcoin's colored coins.%0a---%0a> Each transaction contains public addresses and signatures for each of the cips being sent and the public addresses for each cip to be received to, a cipbase address where a new cip is created and given to, and a message field that an be used for iterating nonces and including messages like love letters or encoding Tokens or NFT's like [[Ravencoin]] or Bitcoin's colored coins.%0a
author:1664555247=
diff:1664555247:1664555039:=35c35%0a%3c Each transaction contains public addresses and signatures for each of the cips being sent and the public addresses for each cip to be received to, a cipbase address where a new cip is created and given to, and a message field that an be used for iterating nonces and including messages like love letters or encoding Tokens or NFT's like [[Ravencoin]] or Bitcoin's colored coins.%0a---%0a> Each transaction contains public addresses and signatures for each of the cips being sent and the public addresses for each cip to be received to, a cipbase address where a new cip is created and given to, and a message field that an be used for iterating nonces and including messages.%0a
author:1664555039=
diff:1664555039:1664553017:=33c33%0a%3c Mining any size transaction will require a certain amount of proof of semiprime, lets say a 20 minute target.  This is set by the nodes.  Perhaps a target of a few seconds can act as an initial confirmation and later a 20 min proof would be important to get all the nodes to accept it. In fact, there could be 2 lattices; alpha and beta.  The alpha fork could have few second confirmations for point of sale (pos) applications and then within 20 mins or so it would be confirmed on the beta network for more confidence. Perhaps there are even more networks for even higher proof levels the transactions could be added to.%0a---%0a> Mining any size transaction will require a certain amount of proof of semiprime, lets say a 20 minute target.  This is set by the nodes.  Perhaps a target of a few seconds can act as an initial confirmation and later a 20 min proof would be important to get all the nodes to accept it.%0a
author:1664553017=
diff:1664553017:1664552917:=130c130%0a%3c Greatest common denominator (GCD) can be run reasonably quickly (seconds-minutes) on a candidate number to see if it is of a special form where SNFS can be run faster than GNFS [[https://www.mersenneforum.org/showpost.php?p=614588&postcount=16|#]] [[https://www.mersenneforum.org/showpost.php?p=614600&postcount=17|#]].  The only question is how common are these numbers where looking for SNFS-able numbers and bypassing GNFS would be viable.  One workaround to prevent this is to have the nodes simply reject any special forms, which can be somewhat easily checked - and known even faster after the number is factored (since the possible 'greatest common denominator' is now simply checked to match the factors).%0a---%0a> Greatest common denominator (GCD) can be run reasonably quickly (seconds-minutes) on a candidate number to see if it is of a special form where SNFS can be run faster than GNFS [[https://www.mersenneforum.org/showpost.php?p=614588&postcount=16|#]].  The only question is how common are these numbers where looking for SNFS-able numbers and bypassing GNFS would be viable.  One workaround to prevent this is to have the nodes simply reject any special forms, which can be somewhat easily checked - and known even faster after the number is factored (since the possible 'greatest common denominator' is now simply checked to match the factors).%0a
author:1664552917=
diff:1664552917:1664552777:=130c130%0a%3c Greatest common denominator (GCD) can be run reasonably quickly (seconds-minutes) on a candidate number to see if it is of a special form where SNFS can be run faster than GNFS [[https://www.mersenneforum.org/showpost.php?p=614588&postcount=16|#]].  The only question is how common are these numbers where looking for SNFS-able numbers and bypassing GNFS would be viable.  One workaround to prevent this is to have the nodes simply reject any special forms, which can be somewhat easily checked - and known even faster after the number is factored (since the possible 'greatest common denominator' is now simply checked to match the factors).%0a---%0a> Greatest common denominator (GCD) can be run reasonably quickly (seconds-minutes) on a candidate number to see if it is of a special form where SNFS can be run faster than GNFS [[https://www.mersenneforum.org/showpost.php?p=614588&postcount=16|#]].  The only question is how common are these numbers where looking for SNFS-able numbers and bypassing GNFS would be viable.  One workaround to prevent this is to have the nodes simply reject any special forms, which can be somewhat easily checked - I suppose known even faster after the number is factored.%0a
author:1664552777=
diff:1664552777:1664552726:=130c130%0a%3c Greatest common denominator (GCD) can be run reasonably quickly (seconds-minutes) on a candidate number to see if it is of a special form where SNFS can be run faster than GNFS [[https://www.mersenneforum.org/showpost.php?p=614588&postcount=16|#]].  The only question is how common are these numbers where looking for SNFS-able numbers and bypassing GNFS would be viable.  One workaround to prevent this is to have the nodes simply reject any special forms, which can be somewhat easily checked - I suppose known even faster after the number is factored.%0a---%0a> Greatest common denominator (GCD) can be run reasonably quickly on a candidate number to see if it is of a special form where SNFS can be run faster than GNFS [[https://www.mersenneforum.org/showpost.php?p=614588&postcount=16|#]].  The only question is how common are these numbers where looking for SNFS-able numbers and bypassing GNFS would be viable.  One workaround to prevent this is to have the nodes simply reject any special forms, which can be somewhat easily checked - I suppose known even faster after the number is factored.%0a
author:1664552726=
diff:1664552726:1664552705:=130c130%0a%3c Greatest common denominator (GCD) can be run reasonably quickly on a candidate number to see if it is of a special form where SNFS can be run faster than GNFS [[https://www.mersenneforum.org/showpost.php?p=614588&postcount=16|#]].  The only question is how common are these numbers where looking for SNFS-able numbers and bypassing GNFS would be viable.  One workaround to prevent this is to have the nodes simply reject any special forms, which can be somewhat easily checked - I suppose known even faster after the number is factored.%0a---%0a> Greatest common denominator (GCD) can be run reasonably quickly on a candidate number to see if is of a special form where SNFS can be run faster than GNFS [[https://www.mersenneforum.org/showpost.php?p=614588&postcount=16|#]].  The only question is how common are these numbers where looking for SNFS-able numbers and bypassing GNFS would be viable.  One workaround to prevent this is to have the nodes simply reject any special forms, which can be somewhat easily checked - I suppose known even faster after the number is factored.%0a
author:1664552705=
diff:1664552705:1664552467:=127,130d126%0a%3c %0a%3c !!!SNFS%0a%3c %0a%3c Greatest common denominator (GCD) can be run reasonably quickly on a candidate number to see if is of a special form where SNFS can be run faster than GNFS [[https://www.mersenneforum.org/showpost.php?p=614588&postcount=16|#]].  The only question is how common are these numbers where looking for SNFS-able numbers and bypassing GNFS would be viable.  One workaround to prevent this is to have the nodes simply reject any special forms, which can be somewhat easily checked - I suppose known even faster after the number is factored.%0a
author:1664552467=
diff:1664552467:1664521975:=94c94%0a%3c The genesis, called lattigenesis, requires 3 transactions (a trinity) to begin that cross reference (connect) to eachother. Three transactions is the minimum genesis of course, and more could be used which would make the surface that would need to be attacked larger, and thus a larger genesis is more resistant to attack.  But using the minimum viable genesis (MVG) of a trinity is preferable to keep "fake" transactions to a minimum.  Genesis transactions should not have a cipbase (no new coins should be generated).  Later transactions can just be blank with no cip movement in order to collect cipbase cips.%0a---%0a> The genesis, called lattigenesis, requires 3 transactions (a trinity) to begin that cross reference (connect) to eachother.%0a
author:1664521975=
diff:1664521975:1664518655:=1c1%0a%3c (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain (1D) or blockDAG (2D).  It scales to infinite free transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], mining pools aren't necessary for miners to get constant rewards, tx can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain (1D) or blockDAG (2D).  It scales to infinite free transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664518655=
diff:1664518655:1664516989:=168c168%0a%3c Factorn integer factorization proof of work [[https://github.com/FACT0RN/FACT0RN|#]] [[https://www.mersenneforum.org/showthread.php?t=27807|#]] [[https://www.coinbase.com/blog/fact0rn-blockchain-integer-factorization-as-proof-of-work-pow|#]] initial commit to merge bitcoin code [[https://github.com/FACT0RN/FACT0RN/commit/08a870f0cce99ed5fe496a0f5f76f03aa2a65140|#]]%0a---%0a> Factorn integer factorization proof of work [[https://github.com/FACT0RN/FACT0RN|#]] [[https://www.mersenneforum.org/showthread.php?t=27807|#]] [[https://www.coinbase.com/blog/fact0rn-blockchain-integer-factorization-as-proof-of-work-pow|#]]%0a
author:1664516989=
diff:1664516989:1664516974:=50c50%0a%3c !!!Miner's side - "activation" of transaction block%0a---%0a> !!!Miner's side - "activation" of transaction"%0a
author:1664516974=
diff:1664516974:1664516955:=38c38%0a%3c !!!Transactor side - create "transaction block"%0a---%0a> !!!Transactor side - Transaction block%0a
author:1664516955=
diff:1664516955:1664516937:=38c38%0a%3c !!!Transactor side - Transaction block%0a---%0a> !!!Transactor side%0a
author:1664516937=
diff:1664516937:1664516808:=50c50%0a%3c !!!Miner's side - "activation" of transaction"%0a---%0a> !!!Miner's side%0a
author:1664516808=
diff:1664516808:1664516798:=1c1%0a%3c (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain (1D) or blockDAG (2D).  It scales to infinite free transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain (ID) or blockDAG (2D).  It scales to infinite free transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664516798=
diff:1664516798:1664516625:=1c1%0a%3c (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain (ID) or blockDAG (2D).  It scales to infinite free transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite free transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664516625=
diff:1664516625:1664516616:=150c150%0a%3c But the main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  Using a UTXO we could peg the value of 1 cip = 1 cip forever, but I tend to want completing a higher bitlength proof to be more valuable than a small proof, which also means we can get faster initial confirmations (since they are small proofs, larger proofs can come later).%0a---%0a> But the main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  Using a UTXO we could peg the value of 1 cip= 1 cip forever, but I tend to want completing a higher bitlength proof to be more valuable than a small proof, which also means we can get faster initial confirmations (since they are small proofs, larger proofs can come later).%0a
author:1664516616=
diff:1664516616:1664516546:=152c152%0a%3c Another downside is we don't force a consensus between nodes (but we could if we wanted since the lattice is fully auditable), and if we did force consensus it would probably be at the 20-min-semiprime-proof level.  Below that it will be fluid and no consensus would be forced between nodes (most likely, to allow flexibility with what nodes save and accept - it's own custom pruning method).%0a---%0a> Another downside is we don't force a consensus between nodes (but we could if we wanted since the lattice is fully auditable), and if we did force consensus it would probably be at the 20-min-semiprime-proof level.  Below that it will be fluid and no consensus would be forced between nodes (most likely, to allow flexibility with what nodes save and accept).%0a
author:1664516546=
diff:1664516546:1664516429:=150c150%0a%3c But the main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.  Using a UTXO we could peg the value of 1 cip= 1 cip forever, but I tend to want completing a higher bitlength proof to be more valuable than a small proof, which also means we can get faster initial confirmations (since they are small proofs, larger proofs can come later).%0a---%0a> But the main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.%0a
author:1664516429=
diff:1664516429:1664516116:=146,154d145%0a%3c !!Downsides%0a%3c %0a%3c Basically everything written is upsides so upsides don't need a section.%0a%3c %0a%3c But the main downside I can see so far is the value of certain bitlength cips will decrease over time, perhaps at a rate of moore's law, so halving in value every 3 years.  I guess this kinda makes sense because a CPU cycle today is as good as half a CPU cycle in 3 years for now.  So perhaps this is the natural order of things.%0a%3c %0a%3c Another downside is we don't force a consensus between nodes (but we could if we wanted since the lattice is fully auditable), and if we did force consensus it would probably be at the 20-min-semiprime-proof level.  Below that it will be fluid and no consensus would be forced between nodes (most likely, to allow flexibility with what nodes save and accept).%0a%3c %0a%3c %0a
author:1664516116=
diff:1664516116:1664516003:=1c1%0a%3c (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite free transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664516003=
diff:1664516003:1664515987:=1c1%0a%3c (:Summary:A 3D lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664515987=
diff:1664515987:1664495815:=15c15%0a%3c An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issue rewards (cips).  It replaces the blockchain.  You can think of it like a 3D blockchain, whereas a blockchain is 1D.%0a---%0a> An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issue rewards (cips).  It replaces the blockchain.%0a
author:1664495815=
diff:1664495815:1664494664:=124c124%0a%3c An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million each (this isn't just a one-time development cost), and it also would only work for one specific bitlength number without physical reconfiguration, in the case of the SHARK paper it was designed for 1024 bit numbers.  More discussion here: [[https://www.reddit.com/r/Monero/comments/grms1c/comment/fs0ofio/?utm_source=share&utm_medium=web2x&context=3|#]]%0a---%0a> An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million each (this isn't just a one-time development cost), and it also would only work for one specific bitlength number without physical reconfiguration, in the case of the SHARK paper it was designed for 1024 bit numbers.%0a
author:1664494664=
diff:1664494664:1664494541:=124c124%0a%3c An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million each (this isn't just a one-time development cost), and it also would only work for one specific bitlength number without physical reconfiguration, in the case of the SHARK paper it was designed for 1024 bit numbers.%0a---%0a> An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million, and it also would only work for one specific bitlength number without physical reconfiguration, in the case of the SHARK paper it was designed for 1024 bit numbers.%0a
author:1664494541=
diff:1664494541:1664494466:=124c124%0a%3c An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million, and it also would only work for one specific bitlength number without physical reconfiguration, in the case of the SHARK paper it was designed for 1024 bit numbers.%0a---%0a> An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million, and it also would only work for one specific bitlength number, in the case of the SHARK paper it was designed for 1024 bit numbers.%0a
author:1664494466=
diff:1664494466:1664494454:=124c124%0a%3c An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million, and it also would only work for one specific bitlength number, in the case of the SHARK paper it was designed for 1024 bit numbers.%0a---%0a> An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million, and it also would only work for one specific bitlength number, in the case of the SHARK paper it was designed for 1024 bit mumbers.%0a
author:1664494454=
diff:1664494454:1664494293:=124c124%0a%3c An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million, and it also would only work for one specific bitlength number, in the case of the SHARK paper it was designed for 1024 bit mumbers.%0a---%0a> An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million, and it also would only work for one specific bitlength number, in the case of the apper it was designed for 1024 bit mumbers.%0a
author:1664494293=
diff:1664494293:1664493745:=124c124%0a%3c An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.  At current consumer technology levels the SHARK would achieve a 2-3x speedup over consumer CPU's and of course would cost 200 million, and it also would only work for one specific bitlength number, in the case of the apper it was designed for 1024 bit mumbers.%0a---%0a> An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.%0a
author:1664493745=
diff:1664493745:1664493702:=125,126d124%0a%3c %0a%3c There is a proposed ECM ASIC which means we need to go up probably to 0.47x bitlength for smallest factor to try to avoid these [[https://cr.yp.to/conferences/2006-sharcs/www.ruhr-uni-bochum.de/itsc/tanja/SHARCS/talks/ecm_paper.pdf|#]] but currently it only works up to 200 bits, which is like a 70 digit number or less than that.%0a
author:1664493702=
diff:1664493702:1664493671:=171a172,173%0a> %0a> ECM ASIC which means we need to go up probably to 0.47x bitlength to try to avoid these [[https://cr.yp.to/conferences/2006-sharcs/www.ruhr-uni-bochum.de/itsc/tanja/SHARCS/talks/ecm_paper.pdf|#]] but currently it only works up to 200 bits, which is like a 70 digit number or less than that.%0a
author:1664493671=
diff:1664493671:1664493443:=124,125c124%0a%3c An ASIC has been proposed, called a SHARK [[https://www.hyperelliptic.org/tanja/SHARCS/talks/shark_paper.pdf|#]].  the SHARK is a hardware arrangement that works for only one specific bitlength of number.  So if one was created it could only have a small and temporary niche in our network.  Estimated cost is 200 million estimated, it has never been attempted.%0a%3c %0a---%0a> An ASIC has been proposed, called a SHARK%0a
author:1664493443=
diff:1664493443:1664493321:=172c172%0a%3c ECM ASIC which means we need to go up probably to 0.47x bitlength to try to avoid these [[https://cr.yp.to/conferences/2006-sharcs/www.ruhr-uni-bochum.de/itsc/tanja/SHARCS/talks/ecm_paper.pdf|#]] but currently it only works up to 200 bits, which is like a 70 digit number or less than that.%0a---%0a> ECM ASIC which means we need to go up probably to 0.47x bitlength to try to avoid these [[https://cr.yp.to/conferences/2006-sharcs/www.ruhr-uni-bochum.de/itsc/tanja/SHARCS/talks/ecm_paper.pdf|#]]%0a
author:1664493321=
diff:1664493321:1664492819:=171,172d170%0a%3c %0a%3c ECM ASIC which means we need to go up probably to 0.47x bitlength to try to avoid these [[https://cr.yp.to/conferences/2006-sharcs/www.ruhr-uni-bochum.de/itsc/tanja/SHARCS/talks/ecm_paper.pdf|#]]%0a
author:1664492819=
diff:1664492819:1664474586:=121,124d120%0a%3c %0a%3c !!!ASIC%0a%3c %0a%3c An ASIC has been proposed, called a SHARK%0a
author:1664474586=
diff:1664474586:1664474493:=154c154%0a%3c Factorn whitepaper [[https://fact0rn.io/FACT0RN_whitepaper.pdf|#]] takes them 200 semiprimes to find a valid semiprime (has a factor of exactly half the bitlength) about 1 in 20 for reasonably strong semiprimes.  This means my finding that 1 in 300 numbers is semiprime, 1 in 6,000 numbers is a strong (base-2 brilliant) semiprime.%0a---%0a> Factorn whitepaper [[https://fact0rn.io/FACT0RN_whitepaper.pdf|#]] takes them 200 semiprimes to find a valid semiprime (has a factor of exactly half the bitlength).  This means my finding that 1 in 300 numbers is semiprime, 1 in 60,000 numbers is a strong (base-2 brilliant) semiprime.%0a
author:1664474493=
diff:1664474493:1664474470:=
author:1664474470=
diff:1664474470:1664441127:=146c146%0a%3c !!Notes [[#note]]%0a---%0a> !!Notes%0a
author:1664441127=
diff:1664441127:1664440642:=154c154%0a%3c Factorn whitepaper [[https://fact0rn.io/FACT0RN_whitepaper.pdf|#]] takes them 200 semiprimes to find a valid semiprime (has a factor of exactly half the bitlength).  This means my finding that 1 in 300 numbers is semiprime, 1 in 60,000 numbers is a strong (base-2 brilliant) semiprime.%0a---%0a> Factorn whitepaper [[https://fact0rn.io/FACT0RN_whitepaper.pdf|#]]%0a
author:1664440642=
diff:1664440642:1664440517:=141c141%0a%3c Moore's law shows that every 5 more decimal digits you double the difficulty [[https://mersenneforum.org/showthread.php?t=19171&highlight=Moore|#]] [[https://mersenneforum.org/showthread.php?t=23078|#]] or 17-18 bits [[https://www.mersenneforum.org/showpost.php?p=606655&postcount=28|#]], which may happen every 3 years.  So the ease of factoring a 110 digit today will be what its like to mine a 115 digit number 3 years from now.%0a---%0a> Moore's law shows that every 5 more decimal digits you double the difficulty [[https://mersenneforum.org/showthread.php?t=19171&highlight=Moore|#]] [[https://mersenneforum.org/showthread.php?t=23078|#]], which may happen every 3 years.  So the ease of factoring a 110 digit today will be what its like to mine a 115 digit number 3 years from now.%0a
author:1664440517=
diff:1664440517:1664440103:=147,148d146%0a%3c %0a%3c Strong semiprimes called base-2 brilliant numbers [[https://www.mersenneforum.org/showpost.php?p=606643&postcount=25|#]]%0a
author:1664440103=
diff:1664440103:1664439987:=141c141%0a%3c Moore's law shows that every 5 more decimal digits you double the difficulty [[https://mersenneforum.org/showthread.php?t=19171&highlight=Moore|#]] [[https://mersenneforum.org/showthread.php?t=23078|#]], which may happen every 3 years.  So the ease of factoring a 110 digit today will be what its like to mine a 115 digit number 3 years from now.%0a---%0a> Moore's law shows that every 5 more decimal digits you double the difficulty, which may happen every 3 years.  So the ease of factoring a 110 digit today will be what its like to mine a 115 digit number 3 years from now.%0a
author:1664439987=
diff:1664439987:1664439826:=140,141d139%0a%3c %0a%3c Moore's law shows that every 5 more decimal digits you double the difficulty, which may happen every 3 years.  So the ease of factoring a 110 digit today will be what its like to mine a 115 digit number 3 years from now.%0a
author:1664439826=
diff:1664439826:1664433472:=139,143d138%0a%3c !!Difficulty [[#diff]]%0a%3c %0a%3c The nodes set the minimum difficulty they will accept.  This should be raised based on basically what is the minimum difficulty proof that is present in the network.  Since miners get rewarded to re-mine old transactions at higher difficulty, the network autocompensates for moore's law.  The result of this is old rewards would slowly loose value over time.  That could be quite fast, value might decline with moore's law for old cips. However you can keep mining fresh new cips with high value constantly.  [[NatureVault/Digital Collectible Network]] doesn't have the value loss problem though.  Neither does Fact0rn.%0a%3c %0a%3c %0a
author:1664433472=
diff:1664433472:1664426290:=150,153d149%0a%3c %0a%3c Toppling the blockchain [[https://www.naturehacker.org/2021/01/toppling-blockchain-prime-factorization.html|#]]%0a%3c %0a%3c Bitcoin vs DCC [[https://www.naturehacker.org/2021/01/bitcoin-vs-digital-collectible-currency.html|#]]%0a
author:1664426290=
diff:1664426290:1664420830:=140,141d139%0a%3c %0a%3c Bitlattice tries to go 5D [[https://bitlattice.org/|#]] why??%0a
author:1664420830=
diff:1664420830:1664420659:=121,124d120%0a%3c %0a%3c !!!Node collusion%0a%3c %0a%3c Anyone can be a node.  The people who want to know if a transaction is confirmed would either rely on their own node, or a trusted node to see if their transaction was confirmed.  Eventually over time the nodes should reach consensus on the ledger, as everything can be verified and nodes that condone fraudulent transactions would be eliminated from the network of nodes.%0a
author:1664420659=
diff:1664420659:1664420553:=134c134%0a%3c There is a reason why each transaction can only be connected to two others and not more, because 2 gives good functionality while not overcomplicating how many transactions are checked.  Each node would want to check the validity of several layers down from the transaction to make sure the transactions it is confirming are valid.  If you go down 1 level you verify the two transactions it is confirming are valid. Two levels down you are verifying 4 transactions.  Three levels verifies 8 transactions and so on, each node needs to verify 2^n transactions for every new transaction, where n is the number of levels you go down.  Nodes might be set for n=7 default which is 128 transactions.  Lighter nodes can set this lower, but each node should be transparent of their setting so people connecting to them or merchants using their services can know how sure they are.  If any transaction is invalid, all transactions that are connected to them are also rendered invalid and all are removed from the ledger of the node and no longer exist.%0a---%0a> There is a reason why each transaction can only be connected to two others and not more, because 2 gives good functionality while not overcomplicating how many transactions are checked.  Each node would want to check the validity of several layers down from the transaction to make sure the transactions it is confirming are valid.  If you go down 1 level you verify the two transactions it is confirming are valid. Two levels down you are verifying 4 transactions.  Three levels verifies 8 transactions and so on, each node needs to verify 2^n transactions for every new transaction, where n is the number of levels you go down.  Nodes might be set for n=7 default which is 128 transactions.  Lighter nodes can set this lower, but each node should be transparent of their setting so people connecting to them or merchants using their services can know how sure they are.%0a
author:1664420553=
diff:1664420553:1664420258:=1c1%0a%3c (:Summary:A lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, is immune to traditional 51%25 [[#attacks|attacks]], can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, is immune to traditional 51%25 attacks, can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664420258=
diff:1664420258:1664420171:=134c134%0a%3c There is a reason why each transaction can only be connected to two others and not more, because 2 gives good functionality while not overcomplicating how many transactions are checked.  Each node would want to check the validity of several layers down from the transaction to make sure the transactions it is confirming are valid.  If you go down 1 level you verify the two transactions it is confirming are valid. Two levels down you are verifying 4 transactions.  Three levels verifies 8 transactions and so on, each node needs to verify 2^n transactions for every new transaction, where n is the number of levels you go down.  Nodes might be set for n=7 default which is 128 transactions.  Lighter nodes can set this lower, but each node should be transparent of their setting so people connecting to them or merchants using their services can know how sure they are.%0a---%0a> There is a reason why each transaction can only be connected to two others and notmore, because 2 gives good functionality while not overcomplicating how many transactions are checked.  Each node would want to check the validity of several layers down from the transaction to make sure the transactions it is confirming are valid.  If you go down 1 level you verify the two transactions it is confirming are valid. Two levels down you are verifying 4 transactions.  Three levels verifies 8 transactions and so on, each node needs to verify 2^n transactions for every new transaction, where n is the number of levels you go down.  Nodes might be set for n=7 default which is 128 transactions.  Lighter nodes can set this lower, but each node should be transparent of their setting so people connecting to them or merchants using their services can know how sure they are.%0a
author:1664420171=
diff:1664420171:1664419414:=120,134c120%0a%3c A tumor attack is similar to how a traditional 51%25 attack works, but it does not cause a hardfork like it does in a blockchain.  Basically a bad miner starts confirming their own transactions with more fraudulent transactions.  Basically nodes would need to figure this out and excise the tumor of fraudulent transactions (and any transactions connected to them above them) from their ledger.  This way the confirmations don't matter.  However if this attack is done quickly after a transaction, some nodes might be fooled into saying the transaction was confirmed if they were not checking validity.  Nodes must be checking validity before adding transactions to their ledger.%0a%3c %0a%3c !!!Types of invalid transactions%0a%3c %0a%3c !!!!Sending cips that don't exist%0a%3c %0a%3c Cips are all created in a cipbase transaction.  So when adding a new transaction to the ledger a node must validate that the cipbase transaction exists that gave a cip to the address that is now trying to send it.  Maintaining a UTXO may help make this process quicker.  It will take a long time to check if a huge transaction sending say 1000 cips all check out, and this is why nodes can rightfully limit the transaction size they are willing to save.%0a%3c %0a%3c !!!!Invalid signatures or proof of semiprime%0a%3c %0a%3c Basic stuff here, make sure the signatures match the addresses, make sure the proof of semiprime is valid, etc.%0a%3c %0a%3c !!!!Connected to an invalid transaction%0a%3c %0a%3c There is a reason why each transaction can only be connected to two others and notmore, because 2 gives good functionality while not overcomplicating how many transactions are checked.  Each node would want to check the validity of several layers down from the transaction to make sure the transactions it is confirming are valid.  If you go down 1 level you verify the two transactions it is confirming are valid. Two levels down you are verifying 4 transactions.  Three levels verifies 8 transactions and so on, each node needs to verify 2^n transactions for every new transaction, where n is the number of levels you go down.  Nodes might be set for n=7 default which is 128 transactions.  Lighter nodes can set this lower, but each node should be transparent of their setting so people connecting to them or merchants using their services can know how sure they are.%0a---%0a> A tumor attack is similar to how a traditional 51%25 attack works, but it does not cause a hardfork like it does in a blockchain.  Basically a bad miner starts confirming their own transactions with more fraudulent transactions.  Basically nodes would need to figure this out and excise the tumor of fraudulent transactions (and any transactions connected to them above them) from their ledger.  This way the confirmations don't matter.  However if done quickly after a transaction, some nodes might be fooled into saying the transaction was confirmed if they were not checking validity.  Nodes must be checking validity before adding transactions to their ledger.%0a
author:1664419414=
diff:1664419414:1664419391:=100c100%0a%3c !!!Opsonization [[https://en.wikipedia.org/wiki/Antibody_opsonization|#]] AKA 99.9%25 attack hard fork%0a---%0a> !!!Opsonization [[https://en.wikipedia.org/wiki/Antibody_opsonization|#]] AKA 99.9%25 attack%0a
author:1664419391=
diff:1664419391:1664418664:=102,103d101%0a%3c A fully successful opsonization attack causes a destructive hardfork in the network.  But new [[#genesis|genesi]] can be created and rebuild the network if it happens.  These new genesi can later be reconnected together as the threat subsides.%0a%3c %0a114,120c112,115%0a%3c Even in the case of a successful opsonization attack that totally nullifies the surface with fraudulent transactions, someone can create a new [[#genesis|genesis]] (hardfork) by creating 3 crosslinking transactions and all the old good transactions can be re-mined onto this new genesis.  Preferably many of these new genesi would be created so that the attacker would have to attack them all at once.%0a%3c %0a%3c !!!Tumor attack soft fork%0a%3c %0a%3c A tumor attack causes a benign softfork in the network.%0a%3c %0a%3c A tumor attack is similar to how a traditional 51%25 attack works, but it does not cause a hardfork like it does in a blockchain.  Basically a bad miner starts confirming their own transactions with more fraudulent transactions.  Basically nodes would need to figure this out and excise the tumor of fraudulent transactions (and any transactions connected to them above them) from their ledger.  This way the confirmations don't matter.  However if done quickly after a transaction, some nodes might be fooled into saying the transaction was confirmed if they were not checking validity.  Nodes must be checking validity before adding transactions to their ledger.%0a---%0a> Even in the case of a successful opsonization attack that totally nullifies the surface with fraudulent transactions, someone can create a new [[#genesis|genesis]] by creating 3 crosslinking transactions and all the old good transactions can be re-mined onto this new genesis.  Preferably many of these new genesi would be created so that the attacker would have to attack them all at once.%0a> %0a> %0a> %0a
author:1664418664=
diff:1664418664:1664418426:=108c108%0a%3c Now practically speaking you might get less rigorous miners to confirm some of your fradulent transactions if they aren't willing to check the validity of everything, but this should never happen, a miner should always check validity of the transactions it is connecting to, but some may decide not to, leading to the downfall of the network.  Miners not being rigorous would make them "bad" and a part of the attack.  "Good" miners will always check validity.  Only very few good miners are needed to nullify an attack and have the network recover.%0a---%0a> Now practically speaking you might get less rigorous miners to confirm some of your fradulent transactions if they aren't willing to check the validity of everything, but this should never happen, a miner should always check validity of the transactions it is connecting to, but some may decide not to, leading to the downfall of the network.%0a
author:1664418426=
diff:1664418426:1664418393:=98c98%0a%3c !!Attacks [[#attacks]]%0a---%0a> !!Attacks%0a
author:1664418393=
diff:1664418393:1664418355:=92c92%0a%3c !!Genesis [[#genesis]]%0a---%0a> !!Genesis%0a
author:1664418355=
diff:1664418355:1664418049:=104,105d103%0a%3c Surface area to volume is 3/R [[https://van.physics.illinois.edu/ask/listing/791|#]]  So surface area is directly proportional to volume.  This means that as the size of the actionlattice grows, so does the difficulty in performing the opsonization attack.%0a%3c %0a112c110%0a%3c Even in the case of a successful opsonization attack that totally nullifies the surface with fraudulent transactions, someone can create a new [[#genesis|genesis]] by creating 3 crosslinking transactions and all the old good transactions can be re-mined onto this new genesis.  Preferably many of these new genesi would be created so that the attacker would have to attack them all at once.%0a---%0a> Surface area to volume is 3/R [[https://van.physics.illinois.edu/ask/listing/791|#]]  So surface area is directly proportional to volume.  This means that as the size of the actionlattice grows, so does the difficulty in performing the opsonization attack.%0a
author:1664418049=
diff:1664418049:1664415831:=97,112d96%0a%3c %0a%3c !!Attacks%0a%3c %0a%3c !!!Opsonization [[https://en.wikipedia.org/wiki/Antibody_opsonization|#]] AKA 99.9%25 attack%0a%3c %0a%3c Opsonization in this context means cover the entire surface of the actionlattice with fraudulent transactions in order to force new transactions to confirm fraudulent ones.%0a%3c %0a%3c The reason this is nicknamed the "99.9%25" attack is because you would literally need to flood the lattice with enough transactions to literally cover the entire surface, except for 1 single transaction.  Since a new transaction needs 2 old transactions to connect, you would literally have to connect to all other transactions in the lattice except one in order to force new transactions to confirm the fradulent ones.  %0a%3c %0a%3c Now practically speaking you might get less rigorous miners to confirm some of your fradulent transactions if they aren't willing to check the validity of everything, but this should never happen, a miner should always check validity of the transactions it is connecting to, but some may decide not to, leading to the downfall of the network.%0a%3c %0a%3c If the 99.9%25 attack only achieves 99.8%25 for example (fudging numbers here for illustration) then new transactions can find the "hole" and connect only to the good transactions and this would create what amounts to a "genetic bottleneck" and basically would grow out through this opening and slowly move out of the prison created by the opsonization attack.%0a%3c %0a%3c Surface area to volume is 3/R [[https://van.physics.illinois.edu/ask/listing/791|#]]  So surface area is directly proportional to volume.  This means that as the size of the actionlattice grows, so does the difficulty in performing the opsonization attack.%0a%3c %0a%3c %0a
author:1664415831=
diff:1664415831:1664415728:=1c1%0a%3c (:Summary:A lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, is immune to traditional 51%25 attacks, can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never dominate, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, is immune to traditional 51%25 attacks, can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never be viable, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664415728=
diff:1664415728:1664415657:=15c15%0a%3c An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issue rewards (cips).  It replaces the blockchain.%0a---%0a> An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issue coins.  It replaces the blockchain.%0a
author:1664415657=
diff:1664415657:1664415578:=116,118c116%0a%3c What length numbers do people ECM the most [[https://www.mersenneforum.org/showthread.php?t=25115|#]]%0a%3c %0a%3c Lattice sieving on a GPU [[https://www.mersenneforum.org/showthread.php?t=27515|#]]%0a\ No newline at end of file%0a---%0a> What length numbers do people ECM the most [[https://www.mersenneforum.org/showthread.php?t=25115|#]]%0a\ No newline at end of file%0a
author:1664415578=
diff:1664415578:1664415486:=114,116c114%0a%3c Simple explanation of GNFS [[https://www.mersenneforum.org/showthread.php?t=26984|#]] [[https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.219.2389&rep=rep1&type=pdf|#]]%0a%3c %0a%3c What length numbers do people ECM the most [[https://www.mersenneforum.org/showthread.php?t=25115|#]]%0a\ No newline at end of file%0a---%0a> Simple explanation of GNFS [[https://www.mersenneforum.org/showthread.php?t=26984|#]] [[https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.219.2389&rep=rep1&type=pdf|#]]%0a\ No newline at end of file%0a
author:1664415486=
diff:1664415486:1664415410:=113,114d112%0a%3c %0a%3c Simple explanation of GNFS [[https://www.mersenneforum.org/showthread.php?t=26984|#]] [[https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.219.2389&rep=rep1&type=pdf|#]]  %0a\ No newline at end of file%0a
author:1664415410=
diff:1664415410:1664415320:=111,112d110%0a%3c %0a%3c Resuming factoring [[https://www.mersenneforum.org/showthread.php?t=26664|#]]%0a
author:1664415320=
diff:1664415320:1664415205:=109,110d108%0a%3c %0a%3c ECM depth on 150 digit number [[https://www.mersenneforum.org/showthread.php?t=26707|#]]%0a
author:1664415205=
diff:1664415205:1664414690:=107,108d106%0a%3c %0a%3c Matrix vector multiplication on GPU [[https://www.mersenneforum.org/showthread.php?t=24862|#]] also [[oPoW]] uses this.%0a
author:1664414690=
diff:1664414690:1664413208:=100,106c100%0a%3c Factorn integer factorization proof of work [[https://github.com/FACT0RN/FACT0RN|#]] [[https://www.mersenneforum.org/showthread.php?t=27807|#]] [[https://www.coinbase.com/blog/fact0rn-blockchain-integer-factorization-as-proof-of-work-pow|#]]%0a%3c %0a%3c Factorn whitepaper [[https://fact0rn.io/FACT0RN_whitepaper.pdf|#]]%0a%3c %0a%3c Original mersennes proposal [[https://www.mersenneforum.org/showthread.php?t=26659|#]]%0a%3c %0a%3c Original proposal to Monero [[https://www.reddit.com/r/Monero/comments/grms1c/a_holy_grail_pow_for_monero_outlined_gnfs/|#]]%0a---%0a> Factorn integer factorization proof of work [[https://github.com/FACT0RN/FACT0RN|#]] [[https://www.mersenneforum.org/showthread.php?t=27807|#]]%0a
author:1664413208=
diff:1664413208:1664413169:=1c1%0a%3c (:Summary:A lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, is immune to traditional 51%25 attacks, can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never be viable, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, is immune to 51%25 attacks, can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never be viable, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664413169=
diff:1664413169:1664413107:=1c1%0a%3c (:Summary:A lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, is immune to 51%25 attacks, can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never be viable, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never be viable, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664413107=
diff:1664413107:1664410608:=10c10%0a%3c (:Archive:[[|Archive.is]], [[https://web.archive.org/web/20220929004452/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|Archive.org]],  [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|OLDArchive.org]]:)%0a---%0a> (:Archive:[[|Archive.is]], [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|Archive.org]]:)%0a
author:1664410608=
diff:1664410608:1664409396:=98,100d97%0a%3c !!Notes%0a%3c %0a%3c Factorn integer factorization proof of work [[https://github.com/FACT0RN/FACT0RN|#]] [[https://www.mersenneforum.org/showthread.php?t=27807|#]]%0a
author:1664409396=
diff:1664409396:1664409045:=35c35%0a%3c Each transaction contains public addresses and signatures for each of the cips being sent and the public addresses for each cip to be received to, a cipbase address where a new cip is created and given to, and a message field that an be used for iterating nonces and including messages.%0a---%0a> Each transaction contains public addresses and signatures for each of the bits being sent and the public addresses for each bit to be received to, a bitbase address where a new bit is created and given to, and a message field that an be used for iterating nonces and including messages.%0a
author:1664409045=
diff:1664409045:1664408783:=27,29c27,29%0a%3c All a cryptocurrency would need is an actionlattice.  Also a UTXO may be used, and will be helpful because of pruning.  The UTXO would simply carry a list of addresses with balance of 1 cip, and used addresses (that contain 0 cips) and these cannot be reused (this is done to maintain privacy).  That said UTXO omission could be a feature as it would mean transactions keep needing to be re-mined at current difficulty to not be purged (and effectively reversed).%0a%3c %0a%3c Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without [[proof of semiprime]] [[Posi]].  If it is broadcast to the network with no proof, then a miner would need to activate and connect it wherever they want in the lattice (they will probably selfishly connect it to their own transactions to add confirmations).%0a---%0a> All a cryptocurrency would need is an actionlattice.  Also a UTXO is probably needed, and will be helpful because of pruning.  The UTXO would simply carry a list of addresses with balance of 1 bit, and used addresses (that contain 0 bits) and these cannot be reused (this is done to maintain privacy).  That said UTXO omission could be a feature as it would mean transactions keep need to be re-mined at current difficulty to not be purged (and effectively reversed).%0a> %0a> Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without [[proof of semiprime]] [[Posi]].%0a
author:1664408783=
diff:1664408783:1664408499:=31,34c31,34%0a%3c Each transaction can send cips from one public key to another.  Each public key can hold only 1 cip.  Think of each cip as a "bit".  Each bit is immutable and cannot be split or added to.  Each bit (cip) has one public and private key.%0a%3c %0a%3c Mining any size transaction will require a certain amount of proof of semiprime, lets say a 20 minute target.  This is set by the nodes.  Perhaps a target of a few seconds can act as an initial confirmation and later a 20 min proof would be important to get all the nodes to accept it.%0a%3c %0a---%0a> Each transaction can send coins from one public key to another.  Each public key can hold only 1 cip.  Think of each coin as a "bit".  Each bit is immutable and cannot be split or added to.  Each bit has one public and private key.%0a> %0a> Mining any size transaction will require a certain amount of proof of sieve, lets say a 20 minute target.  This is set by the nodes.%0a> %0a36d35%0a%3c %0a
author:1664408499=
diff:1664408499:1664408367:=25c25%0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original.  The original is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot recieve another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" the miner receives as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a---%0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original.  The original is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot recieve another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" you receive as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a
author:1664408367=
diff:1664408367:1664408040:=25c25%0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original.  The original is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot recieve another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cip" you receive as a reward is.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a---%0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original.  The original is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot recieve another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cips" you receive as a reward are.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a
author:1664408040=
diff:1664408040:1664407927:=17c17%0a%3c The smallest (and only) unit of account is the cip (dust). The name is a convolution of "bit", "semiprime" maybe "cipher" or "sip".%0a---%0a> The smallest (and only) unit of account is the cip (dust). The name is a convolution of "bit", "semiprime" maybe "cipher"%0a
author:1664407927=
diff:1664407927:1664407815:=1c1%0a%3c (:Summary:A lattice of individual cross-confirming transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never be viable, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A lattice of individual transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never be viable, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a
author:1664407815=
diff:1664407815:1664407453:=48c48%0a%3c ----%0a---%0a> -----%0a
author:1664407453=
diff:1664407453:1664407253:=76,77d75%0a%3c %0a%3c Since you don't want the transactions your transaction is connected to to dissapear due to node pruning, you are going to want your transaction to be connected to small transactions that have a high proof level.  Transactions closest to the surface will have the most up-to-date proof level so are good candidates to connect to.  One nice thing is that if the transaction size is acceptable to most of the nodes now, chances are it will continue to be in the future because as hard drives grow due to moores law, storage capacity increases and likely nodes will allow bigger transactions over time because they can and it supports the network.%0a
author:1664407253=
diff:1664407253:1664407088:=75d74%0a%3c However nodes can prune their lattice to only include transactions under a certain size or that have a sufficient proof of semiprime.  Say the Posi starts at 120 digit number factorization, when the node moves to require 130 digit all the 120 digit proven transactions need to be remined at 130 digit proof.  Every re-mining to increase the proof level produces a new cip, and a higher value cip in fact.%0a
author:1664407088=
diff:1664407088:1664406895:=70,73d69%0a%3c %0a%3c !!!Node considerations%0a%3c %0a%3c The actionlattice can be thought of like a database where each transaction is a new line.  Just like a blockchain, an actionlattice is append-only.%0a
author:1664406895=
diff:1664406895:1664406622:=82,83d81%0a%3c %0a%3c SNFS numbers should not be allowed [[https://www.mersenneforum.org/showthread.php?t=26852|#]]%0a
author:1664406622=
diff:1664406622:1664405961:=75,81d74%0a%3c Prime factorization on optical (photonic) computers [[https://iopscience.iop.org/article/10.1143/JJAP.48.09LA02/meta|#]]%0a%3c %0a%3c Quantum computers would need to use shor's algorithm.%0a%3c %0a%3c CPU's are favored for challenges with over roughly 140 digits.%0a%3c %0a%3c GPU's can ECM up to around 140 digits.%0a
author:1664405961=
diff:1664405961:1664405871:=77c77%0a%3c The genesis, called lattigenesis, requires 3 transactions (a trinity) to begin that cross reference (connect) to eachother.%0a---%0a> The genesis, called lattigenesis, requires 3 transactions (a trinity) to begin that cross connect to eachother.%0a
author:1664405871=
diff:1664405871:1664405614:=77c77%0a%3c The genesis, called lattigenesis, requires 3 transactions (a trinity) to begin that cross connect to eachother.%0a---%0a> The genesis, called lattigenesis, requires 3 transactions to begin that cross connect to eachother.%0a
author:1664405614=
diff:1664405614:1664405271:=1c1%0a%3c (:Summary:A lattice of individual transactions that can be mined offline as a replacement to a blockchain or blockDAG.  It scales to infinite transactions per second, can get initial confirmation within a few seconds, reward is proportional, CPU dominated, ASICs will never be viable, and also resists GPU and Quantum computer takeover while allowing them to mine.:)%0a---%0a> (:Summary:A lattice of individual transactions that can be mined offline as a replacement to a blockchain or blockDAG:)%0a
author:1664405271=
diff:1664405271:1664404483:=1c1%0a%3c (:Summary:A lattice of individual transactions that can be mined offline as a replacement to a blockchain or blockDAG:)%0a---%0a> (:Summary:A Lattice of individually mined transactions as a replacement to a blockchain or blockDAG:)%0a
author:1664404483=
diff:1664404483:1664404267:=27c27%0a%3c All a cryptocurrency would need is an actionlattice.  Also a UTXO is probably needed, and will be helpful because of pruning.  The UTXO would simply carry a list of addresses with balance of 1 bit, and used addresses (that contain 0 bits) and these cannot be reused (this is done to maintain privacy).  That said UTXO omission could be a feature as it would mean transactions keep need to be re-mined at current difficulty to not be purged (and effectively reversed).%0a---%0a> All a cryptocurrency would need is an actionlattice.  Also a UTXO is probably needed, and will be helpful because of pruning.  The UTXO would simply carry a list of addresses with balance of 1 bit, and used addresses (that contain 0 bits) and these cannot be reused (this is done to maintain privacy).%0a
author:1664404267=
diff:1664404267:1664404143:=76,77d75%0a%3c %0a%3c The genesis, called lattigenesis, requires 3 transactions to begin that cross connect to eachother.%0a
author:1664404143=
diff:1664404143:1664404094:=19c19%0a%3c Every transaction is free to propose, and then a miner (or you - if you mine your own tx) gets paid with a reward cip if they "activate" the proposed transaction using proof of semiprime ([[Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface" but whose cip genesis is deep below the surface.  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface but the cip genesis is deep from the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a---%0a> Every transaction is free to propose and a miner (or you - if you mine your own tx) gets paid with a reward cip if they "activate" the proposed transaction using proof of semiprime ([[Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface" but whose cip genesis is deep below the surface.  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface but the cip genesis is deep from the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a
author:1664404094=
diff:1664404094:1664399064:=17c17%0a%3c The smallest (and only) unit of account is the cip (dust). The name is a convolution of "bit", "semiprime" maybe "cipher"%0a---%0a> The smallest (and only) unit is the cip (dust). The name is a convolution of "bit", "semiprime" maybe "cipher"%0a
author:1664399064=
diff:1664399064:1664398112:=74,77d73%0a%3c %0a%3c !!Genesis%0a%3c %0a%3c Attach:lattigenesis.png%0a
author:1664398112=
diff:1664398112:1664397982:=10c10%0a%3c (:Archive:[[|Archive.is]], [[https://web.archive.org/web/20220928204808/https://www.naturevault.org/wiki/pmwiki.php/CryptoProjects/Actionlattice|Archive.org]]:)%0a---%0a> (:Archive:[[|Archive.is]], [[|Archive.org]]:)%0a
author:1664397982=
diff:1664397982:1664396128:=25c25%0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later (basically any transaction can be re-mined just as long as it has a higher bitlevel proof than the original.  The original is kept and not deleted unless its proof level falls below the nodes requirement) which works because cips cannot be double spent by definition, addresses are throwaway and cannot hold more than 1 cip and once they send it they cannot recieve another cip ever again.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cips" you receive as a reward are.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a---%0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cips" you receive as a reward are.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a
author:1664396128=
diff:1664396128:1664396099:=15c15%0a%3c An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issue coins.  It replaces the blockchain.%0a---%0a> An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issues coins.  It replaces the blockchain.%0a
author:1664396099=
diff:1664396099:1664396056:=36,38c36,38%0a%3c !!Process%0a%3c !!!Transactor side%0a%3c %0a---%0a> %0a> Transactor side%0a> %0a49,50c49,50%0a%3c !!!Miner's side%0a%3c %0a---%0a> Miner's side%0a> %0a65c65%0a%3c !!!Node settings%0a---%0a> Node settings%0a
author:1664396056=
diff:1664396056:1664395420:=73c73%0a%3c See [[NatureVault/Digital Collectible Network#mine]]%0a---%0a> [[NatureVault/Digital Collectible Network#mine]]%0a
author:1664395420=
diff:1664395420:1664394846:=70,73d69%0a%3c %0a%3c !!Proof of Semiprime%0a%3c %0a%3c [[NatureVault/Digital Collectible Network#mine]]%0a
author:1664394846=
diff:1664394846:1664394821:=17c17%0a%3c The smallest (and only) unit is the cip (dust). The name is a convolution of "bit", "semiprime" maybe "cipher"%0a---%0a> The smallest (and only) unit is the cip. The name is a convolution of "bit", "semiprime" maybe "cipher"%0a
author:1664394821=
diff:1664394821:1664394776:=2c2%0a%3c (:Published:9/28/2022:)%0a---%0a> (:Published:9/27/2022:)%0a
author:1664394776=
diff:1664394776:1664394653:=1,2c1,3%0a%3c (:Summary:A Lattice of individually mined transactions as a replacement to a blockchain or blockDAG:)%0a%3c (:Published:9/27/2022:)%0a---%0a> (:nogroupheader:)%0a> (:Summary::)%0a> (:Published::)%0a
author:1664394653=
diff:1664394653:1664394436:=18c18%0a%3c The smallest (and only) unit is the cip. The name is a convolution of "bit", "semiprime" maybe "cipher"%0a---%0a> The smallest (and only) unit is the cip. A convolution of "bit", "semiprime" maybe "cipher"%0a
author:1664394436=
diff:1664394436:1664392769:=24,25d23%0a%3c Attach:actionlattice.png%0a%3c %0a32c30%0a%3c Each transaction can send coins from one public key to another.  Each public key can hold only 1 cip.  Think of each coin as a "bit".  Each bit is immutable and cannot be split or added to.  Each bit has one public and private key.%0a---%0a> Each transaction can send coins from one public key to another.  Each public key can hold only 1 coin.  Think of each coin as a "bit".  Each bit is immutable and cannot be split or added to.  Each bit has one public and private key.%0a
author:1664392769=
diff:1664392769:1664383639:=18c18%0a%3c The smallest (and only) unit is the cip. A convolution of "bit", "semiprime" maybe "cipher"%0a---%0a> The smallest (and only) unit is the cip.%0a
author:1664383639=
diff:1664383639:1664383086:=18,21c18,19%0a%3c The smallest (and only) unit is the cip.%0a%3c %0a%3c Every transaction is free to propose and a miner (or you - if you mine your own tx) gets paid with a reward cip if they "activate" the proposed transaction using proof of semiprime ([[Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface" but whose cip genesis is deep below the surface.  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface but the cip genesis is deep from the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a%3c %0a---%0a> Every transaction is free to propose and a miner (or you - if you mine your own tx) gets paid with reward if they "activate" the proposed transaction using proof of semiprime ([[Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface".  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a> %0a24c22%0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397 bit - cip397's) , some 140 (463 bit - cip463's).  More proof can be added to the transaction later.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "cips" you receive as a reward are.  Some merchants may accept only cip463's, and others may accept cip397's as well, but assign a lesser value to them.%0a---%0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397bits) , some 140 (463bits).  More proof can be added to the transaction later.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "bits" you receive as a reward are.  Some merchants may accept only 463bits, and others may accept 397bits as well, but assign a lesser value to them.%0a
author:1664383086=
diff:1664383086:1664383028:=18c18%0a%3c Every transaction is free to propose and a miner (or you - if you mine your own tx) gets paid with reward if they "activate" the proposed transaction using proof of semiprime ([[Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface".  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a---%0a> Every transaction is free and a miner (or you - if you mine your own tx) gets paid with reward if they "activate" it using proof of semiprime ([[Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface".  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a
author:1664383028=
diff:1664383028:1664382749:=19,20d18%0a%3c %0a%3c The mining reward for activating a transaction would mature by whether your transaction is confirmed by others linking their transactions to yours.  Some consensus on how "well connected" your transaction needs to be (how deep from the surface) in order for your mining reward to be valid.  I suppose you can try to spend them immediately and it is up to each miner whether they build on a transaction whose genesis isn't deep from the surface.  I suppose it would take a while for your spending transaction to be confirmed before miners feel it is valid.%0a
author:1664382749=
diff:1664382749:1664382686:=16c16%0a%3c An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issues coins.  It replaces the blockchain.%0a---%0a> An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issues coins.%0a
author:1664382686=
diff:1664382686:1664382447:=18,20c18,20%0a%3c Every transaction is free and a miner (or you - if you mine your own tx) gets paid with reward if they "activate" it using proof of semiprime ([[Posi]]) and point (connect) it to two other transactions that they validate and vouch for, preferably these two other transactions are near the "surface".  Next, other new activated transactions will point (connect) to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface.  The surface is just the layer of unconfirmed transactions on the edge of the lattice.%0a%3c %0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397bits) , some 140 (463bits).  More proof can be added to the transaction later.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "bits" you receive as a reward are.  Some merchants may accept only 463bits, and others may accept 397bits as well, but assign a lesser value to them.%0a---%0a> Every transaction is free and a miner (or you - if you mine your own tx) gets paid with reward if they "activate" it using proof of semiprime ([[Posi]]) and connect it to two other transactions that they validate, preferably these two other transactions are near the "surface".  Next more activated transactions will point to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface.  The surface is just the layer of unconfirmed transactions.%0a> %0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397bits) , some 140 (463bits).  More proof can be added to the transaction later.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "bits" you receive as a reward are.%0a
author:1664382447=
diff:1664382447:1664382328:=18c18%0a%3c Every transaction is free and a miner (or you - if you mine your own tx) gets paid with reward if they "activate" it using proof of semiprime ([[Posi]]) and connect it to two other transactions that they validate, preferably these two other transactions are near the "surface".  Next more activated transactions will point to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface.  The surface is just the layer of unconfirmed transactions.%0a---%0a> Every transaction is free and a miner (or you if you mine your own tx) gets paid with reward if they "activate" it using proof of semiprime ([[Posi]]) and connect it to two other transactions that they validate, preferably these two other transactions are near the "surface".  Next more activated transactions will point to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface.  The surface is just the layer of unconfirmed transactions.%0a
author:1664382328=
diff:1664382328:1664381873:=20,22c20,22%0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers (397bits) , some 140 (463bits).  More proof can be added to the transaction later.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.  The more proof you the miner provides, the more valuable the "bits" you receive as a reward are.%0a%3c %0a%3c All a cryptocurrency would need is an actionlattice.  Also a UTXO is probably needed, and will be helpful because of pruning.  The UTXO would simply carry a list of addresses with balance of 1 bit, and used addresses (that contain 0 bits) and these cannot be reused (this is done to maintain privacy).%0a---%0a> In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers, some 150.  More proof can be added to the transaction later.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.%0a> %0a> All a cryptocurrency would need is an actionlattice.  Also a UTXO is probably needed, and will be helpful because of pruning.  The UTXO would simply carry a list of addresses with balance of 1 bit, and used addresses (that contain 0 bits) which cannot be reused.%0a
author:1664381873=
diff:1664381873:1664381332:=18,20c18%0a%3c Every transaction is free and a miner (or you if you mine your own tx) gets paid with reward if they "activate" it using proof of semiprime ([[Posi]]) and connect it to two other transactions that they validate, preferably these two other transactions are near the "surface".  Next more activated transactions will point to yours which "confirms" yours.  Some factors that will help decide whether they confirm yours or not is if it fits in the majority of nodes "max transaction size", and if it is near the surface.  The surface is just the layer of unconfirmed transactions.%0a%3c %0a%3c In addition to setting the max transaction size they record, nodes also decide how much proof (bitlength) is needed to activate a transaction.  Some nodes might accept 120 digit numbers, some 150.  More proof can be added to the transaction later.  So "fast" nodes will accept small proofs and thus transactions can be initially confirmed quickly and then as more proof gets added slower nodes will recognize the transactions.%0a---%0a> Every transaction is free and a miner (or you if you mine your own tx) gets paid with reward if they "confirm" it using proof of semiprime ([[Posi]]).  One factor that will help decide whether they confirm it or not is if it fits in the majority of nodes "max transaction size". Nodes also decide how much proof (bitlength) is needed.  Some nodes might accept 120 digit numbers, some 150.  More proof can be added to the transaction later.%0a
author:1664381332=
diff:1664381332:1664381262:=16c16%0a%3c An actionlattice is a new method to create, order, and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issues coins.%0a---%0a> An actionlattice is a new method to create and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issues coins.%0a
author:1664381262=
diff:1664381262:1664380683:=14,15c14,15%0a%3c See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]], [[NatureVault/Solvum]], [[NatureVault/Quantum]], [[Dustyplasma]]%0a%3c %0a---%0a> See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]], [[NatureVault/Solvum]], [[NatureVault/Quantum]]%0a> %0a20,21c20,21%0a%3c All a cryptocurrency would need is an actionlattice.  Also a UTXO is probably needed, and will be helpful because of pruning.  The UTXO would simply carry a list of addresses with balance of 1 bit, and used addresses (that contain 0 bits) which cannot be reused.%0a%3c %0a---%0a> All a cryptocurrency would need is an actionlattice.  Even a UTXO is not needed, but may be helpful in the case of pruning.  The UTXO would simply carry a list of addresses with balance of 1 bit, and used addresses (that contain 0 bits) that cannot be reused.%0a> %0a23a24,25%0a> Each transaction "costs" a certain amount regardless of how many kilobytes large it is.%0a> %0a36c38%0a%3c #"Receiving Public Addresses" (RPA's) - One address for each bit being received.%0a---%0a> #"Recieving Public Addresses" (RPA's) - One address for each bit being received.%0a
author:1664380683=
diff:1664380683:1664380176:=18,20c18%0a%3c Every transaction is free and a miner (or you if you mine your own tx) gets paid with reward if they "confirm" it using proof of semiprime ([[Posi]]).  One factor that will help decide whether they confirm it or not is if it fits in the majority of nodes "max transaction size". Nodes also decide how much proof (bitlength) is needed.  Some nodes might accept 120 digit numbers, some 150.  More proof can be added to the transaction later.%0a%3c %0a%3c All a cryptocurrency would need is an actionlattice.  Even a UTXO is not needed, but may be helpful in the case of pruning.  The UTXO would simply carry a list of addresses with balance of 1 bit, and used addresses (that contain 0 bits) that cannot be reused.%0a---%0a> All a cryptocurrency would need is an actionlattice.  Even a UTXO is not needed.%0a
author:1664380176=
diff:1664380176:1664347653:=16c16%0a%3c An actionlattice is a new method to create and store transactions, prove work, confirm transaction validity, prevent double spending, maintain privacy, and issues coins.%0a---%0a> An actionlattice is a new method to create and store transactions, prove work, confirm transaction validity, maintains privacy, and issues coins.%0a
author:1664347653=
diff:1664347653:1664346484:=22,23c22,23%0a%3c Each transaction "costs" a certain amount regardless of how many kilobytes large it is.%0a%3c %0a---%0a> Each transaction "costs" a certain amount depending on how many kilobytes large it is.%0a> %0a26,27c26,27%0a%3c Mining any size transaction will require a certain amount of proof of sieve, lets say a 20 minute target.  This is set by the nodes.%0a%3c %0a---%0a> Mining a 10 kb transaction will require a certain amount of proof of sieve, lets say a 20 minute target. 20kb might require a 30 min target, etc.%0a> %0a32,33c32,33%0a%3c #"Sending Public Addresses" (SPA's) of each bit being sent%0a%3c %0a---%0a> #"Sending Public Addresses" (SPA's) of each bit bieng sent%0a> %0a36,37c36,37%0a%3c #"Recieving Public Addresses" (RPA's) - One address for each bit being received.%0a%3c %0a---%0a> #"Recieving Public Addresses" (RPA's) - One address for each bit being recieved.%0a> %0a57c57%0a%3c ----%0a---%0a> %0a
author:1664346484=
diff:1664346484:1664345413:=54,57c54,55%0a%3c This miner can provide a proof of semiprime can be done on any transaction of any size for the same cost.  Solve a 396 bit (or higher) challenge and you get to pick where the 2 bonds (prior art transactions) are directed.%0a%3c %0a%3c Now another miner can also do the same exact challenge and add the same transaction to the lattice however the challenge has to be harder, say a 400 bit mumber instead of 396.  This means multiple miners can mine the same transactions, they are all in the lattice but since each transaction is a non-reversible change (since by definition each address can only hold 1 bit, no more no less, once it sends its bit it can never recieve another, its worn out.  this solves the double spending problem.  Each address is one and done.  It either doesn't exist, holds a bit, or is spent.  So a transaction from one specific address to another can only ever happen once and never be reversed.  We solve double spending to not allow any address to make more than one transaction ever.  And we achieve this by allowing infinite addresses.  That also gives privacy.%0a%3c %0a---%0a> Now the proof of %0a> %0a60,62c58,60%0a%3c #Max transaction size of transactions you save (not everyone has to save every transaction). Set to 0 for no pruning.%0a%3c %0a%3c #Minimum factored number bitlength you will accept (I would suggest 120 (396 bits) digits as of now) this should be increased over time, but not too fast as to create orphans of old transactions.%0a---%0a> #Max transaction size of transactions you save (not everyone has to save every tranasaction). Set to 0 for no pruning.%0a> %0a> #Minimum factored number bitlength you will accept%0a
author:1664345413=
diff:1664345413:1664344787:=53,61d52%0a%3c %0a%3c Now the proof of %0a%3c %0a%3c Node settings%0a%3c %0a%3c #Max transaction size of transactions you save (not everyone has to save every tranasaction). Set to 0 for no pruning.%0a%3c %0a%3c #Minimum factored number bitlength you will accept%0a%3c %0a
author:1664344787=
diff:1664344787:1664344529:=20c20%0a%3c Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without [[proof of semiprime]] [[Posi]].%0a---%0a> Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without [[proof of sieve]] [[Posi]].%0a
author:1664344529=
diff:1664344529:1664344335:=30,31d29%0a%3c Transactor side%0a%3c %0a36,37c34,35%0a%3c #"Recieving Public Addresses" (RPA's) - One address for each bit being recieved.%0a%3c %0a---%0a> #"Recieving Public Addresses" (RPA's) - %0a> %0a41,42d38%0a%3c -----%0a%3c Miner's side%0a
author:1664344335=
diff:1664344335:1664343742:=34,35c34,35%0a%3c #"Recieving Public Addresses" (RPA's) - %0a%3c %0a---%0a> #"Recieving Public Addresses" (RPA's) - this includes the bitbase receiving address %0a> %0a38,48c38,42%0a%3c #Completed transaction signature - Signs over the whole transaction done by the sender.  This prevents man in the middle (MITM) attack.%0a%3c %0a%3c #Proof of Sieve (Posi) message - %0a%3c %0a%3c #Proof of Proven Sieve (Props) - number to factor, nonce, and 2 factors%0a%3c %0a%3c #Peer blocks - 2 peer blocks Msig within the last epoch that you confirm are correct (if you are wrong about their validity your transaction may become voided)%0a%3c %0a%3c #Bitbase address which is the Miners public address (MPA) where the bitbase is sent, 1 bit for 10 kb or whatever it is.%0a%3c %0a%3c #Miners signature (Msig) - one who found the Props signs the entire "block" (the transaction and everything they added to it)%0a---%0a> #Completed transaction signature - Done by the sender.  This prevents man in the middle (MITM) attack.%0a> %0a> #Proof of Sieve (Posi) message - this can be a nonce to iterate to find a viable proof.%0a> %0a> #Proof of Proven Sieve (Props)%0a\ No newline at end of file%0a
author:1664343742=
diff:1664343742:1664342583:=20,21c20,21%0a%3c Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without [[proof of sieve]] [[Posi]].%0a%3c %0a---%0a> Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without [[proof of sieve]] [[PoSi]].%0a> %0a26,42c26%0a%3c Mining a 10 kb transaction will require a certain amount of proof of sieve, lets say a 20 minute target. 20kb might require a 30 min target, etc.%0a%3c %0a%3c Each transaction contains public addresses and signatures for each of the bits being sent and the public addresses for each bit to be received to, a bitbase address where a new bit is created and given to, and a message field that an be used for iterating nonces and including messages.%0a%3c %0a%3c #"Sending Public Addresses" (SPA's) of each bit bieng sent%0a%3c %0a%3c #Signatures (proves private key ownership) for the addresses for each bit being sent%0a%3c %0a%3c #"Recieving Public Addresses" (RPA's) - this includes the bitbase receiving address %0a%3c %0a%3c #Internal Message (IM) which can be anything%0a%3c %0a%3c #Completed transaction signature - Done by the sender.  This prevents man in the middle (MITM) attack.%0a%3c %0a%3c #Proof of Sieve (Posi) message - this can be a nonce to iterate to find a viable proof.%0a%3c %0a%3c #Proof of Proven Sieve (Props)%0a\ No newline at end of file%0a---%0a> Mining a 1 kb transaction will require a certain amount of proof of sieve, lets say%0a\ No newline at end of file%0a
author:1664342583=
diff:1664342583:1664342371:=20,26c20%0a%3c Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without [[proof of sieve]] [[PoSi]].%0a%3c %0a%3c Each transaction "costs" a certain amount depending on how many kilobytes large it is.%0a%3c %0a%3c Each transaction can send coins from one public key to another.  Each public key can hold only 1 coin.  Think of each coin as a "bit".  Each bit is immutable and cannot be split or added to.  Each bit has one public and private key.%0a%3c %0a%3c Mining a 1 kb transaction will require a certain amount of proof of sieve, lets say%0a\ No newline at end of file%0a---%0a> Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without [[proof of sieve]] [[PoSi]].%0a\ No newline at end of file%0a
author:1664342371=
diff:1664342371:1664342334:=
author:1664342334=
diff:1664342334:1664341894:=18,20c18%0a%3c All a cryptocurrency would need is an actionlattice.  Even a UTXO is not needed.%0a%3c %0a%3c Each transaction is it's very own "block" and stands alone.  It can be broadcast with or without [[proof of sieve]] [[PoSi]].%0a\ No newline at end of file%0a---%0a> All a cryptocurrency would need is an actionlattice.  Even a UTXO is not needed.%0a\ No newline at end of file%0a
author:1664341894=
diff:1664341894:1664341693:=16,18c16%0a%3c An actionlattice is a new method to create and store transactions, prove work, confirm transaction validity, maintains privacy, and issues coins.%0a%3c %0a%3c All a cryptocurrency would need is an actionlattice.  Even a UTXO is not needed.%0a\ No newline at end of file%0a---%0a> An actionlattice is a new method to create and store transactions, prove work, confirm transaction validity, and issue coins.%0a\ No newline at end of file%0a
author:1664341693=
diff:1664341693:1664341680:=16c16%0a%3c An actionlattice is a new method to create and store transactions, prove work, confirm transaction validity, and issue coins.%0a\ No newline at end of file%0a---%0a> An Actionlattice is a new method to create and store transactions, prove work, confirm transaction validity, and issue coins.%0a\ No newline at end of file%0a
author:1664341680=
diff:1664341680:1664341652:=14c14%0a%3c See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]], [[NatureVault/Solvum]], [[NatureVault/Quantum]]%0a---%0a> See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]]%0a
author:1664341652=
diff:1664341652:1664341577:=14,16c14%0a%3c See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]]%0a%3c %0a%3c An Actionlattice is a new method to create and store transactions, prove work, confirm transaction validity, and issue coins.%0a\ No newline at end of file%0a---%0a> See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]]%0a\ No newline at end of file%0a
author:1664341577=
diff:1664341577:1664341553:=14c14%0a%3c See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[BlockDAG]]%0a\ No newline at end of file%0a---%0a> See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[%0a\ No newline at end of file%0a
author:1664341553=
diff:1664341553:1664341526:=14c14%0a%3c See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]], [[%0a\ No newline at end of file%0a---%0a> See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]]%0a\ No newline at end of file%0a
author:1664341526=
diff:1664341526:1664341422:=14c14%0a%3c See also [[Blocklattice]], [[CollectBit]], [[NatureVault/Digital Collectible Network]]%0a\ No newline at end of file%0a---%0a> See also [[Blocklattice]]%0a\ No newline at end of file%0a
author:1664341422=
diff:1664341422:1664341422:=1,14d0%0a%3c (:nogroupheader:)%0a%3c (:Summary::)%0a%3c (:Published::)%0a%3c (:Author:[[~GiverofMemory]]:)%0a%3c (:License:[[https://en.m.wikipedia.org/wiki/Res_communis|Site License]]:)%0a%3c (:Update::)%0a%3c (:Maintainer:[[~GiverofMemory]]:)%0a%3c (:Creator:[[]]:)%0a%3c (:Categories:[[!Cryptics]]:)%0a%3c (:Also:none:)%0a%3c (:Archive:[[|Archive.is]], [[|Archive.org]]:)%0a%3c (:Download:[[{$FullName}?action=print|URL]],[[https://www.web2pdfconvert.com/|PDF from URL]]:)%0a%3c %0a%3c See also [[Blocklattice]]%0a\ No newline at end of file%0a
